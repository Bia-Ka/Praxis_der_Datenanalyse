<!DOCTYPE html>
<html  lang="de-De">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Praxis der Datenanalyse</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Eine Einführung in moderne Statistik für Praktiker">
  <meta name="generator" content="bookdown 0.2.3 and GitBook 2.6.7">

  <meta property="og:title" content="Praxis der Datenanalyse" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="cover.jpg" />
  <meta property="og:description" content="Eine Einführung in moderne Statistik für Praktiker" />
  <meta name="github-repo" content="sebastiansauer/Praxis_der_Datenanalyse" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Praxis der Datenanalyse" />
  
  <meta name="twitter:description" content="Eine Einführung in moderne Statistik für Praktiker" />
  <meta name="twitter:image" content="cover.jpg" />

<meta name="author" content="Sebastian Sauer, Matthias Gehrke, Karsten Lübke, Oliver Gansser">


<meta name="date" content="2017-04-23">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="inferenz-in-der-linearen-regression.html">
<link rel="next" href="vertiefungen-zum-regressionmodell.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

true

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Praxis der Datenanalyse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modellgute-bei-regressionsmodellen" class="section level2">
<h2><span class="header-section-number">11.6</span> Modellgüte bei Regressionsmodellen</h2>
<p>In einem Regressionsmodell lautet die grundlegenden Überlegung zur Modellgüte so:</p>
<blockquote>
<p>Wie groß ist der Unterschied zwischen Vorhersage und Wirklichkeit?</p>
</blockquote>
<p>Die Größe des Unterschieds (Differenz, “Delta”) zwischen vorhergesagten (geschätzten) Wert und Wirklichkeit, bezeichnet man als <em>Fehler</em>, <em>Residuum</em> oder Vohersagefehler, häufig mit <span class="math inline">\(\epsilon\)</span> (griechisch e wie “error”) abgekürzt.</p>
<p>Graphisch kann man das gut veranschaulichen:</p>
<p><img src="071_Regression_files/figure-html/resids-plot-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Betrachten Sie die beiden Plots. Die rote Linie gibt die vorhergesagten (geschätzten) Werte wieder; die Punkte die beobachteten (“echten”) Werte. Je länger die blauen Linien, desto größer die Vorhersagefehler.</p>
<blockquote>
<p>Je kürzer die typische “Abweichungslinie”, desto besser die Vohersage.</p>
</blockquote>
<p>Sagt mein Modell voraus, dass Ihre Schuhgröße 49 ist, aber in Wahrheit liegt sie bei 39, so werden Sie dieses Modell als schlecht beurteilen.</p>
<p>Leider ist es nicht immer einfach zu sagen, wie groß der Fehler sein muss, damit das Modell als “schlecht” gilt. Man kann argumentieren, dass es keine wissenschaftliche Frage sei, wie viel “viel” oder “genug” ist <span class="citation">(Briggs <a href="#ref-uncertainty">2016</a>)</span>. Das ist zwar plausibel, hilft aber nicht, wenn ich eine Entscheidung treffen muss. Stellen Sie sich vor: Ich zwinge Sie mit der Pistole auf der Brust, meine Schuhgröße zu schätzen.</p>
<p>Eine einfache Lösung ist, das beste Modell unter mehreren Kandidaten zu wählen.</p>
<p>Ein anderer Ansatz ist, die Vorhersage in Bezug zu einem Kriterium zu setzen. Dieses “andere Kriterium” könnte sein “einfach raten”. Oder, etwas intelligenter, Sie schätzen meine Schuhgröße auf einen Wert, der eine gewisse Plausibiliät hat, also z.B. die durchschnittliche Schuhgröße des deutschen Mannes. Auf dieser Basis kann man dann quantifizieren, ob und wieviel besser man als dieses Referenzkriterium ist.</p>
<div id="mittlere-quadratfehler" class="section level3">
<h3><span class="header-section-number">11.6.1</span> Mittlere Quadratfehler</h3>
<p>Eine der häufigsten Gütekennzahlen ist der <em>mittlere quadrierte Fehler</em> (engl. “mean squared error”, MSE), wobei Fehler wieder als Differenz zwischen Vorhersage (<code>pred</code>) und beobachtete Wirklichkeit (<code>obs</code>, <code>y</code>) definiert ist. Dieser berechnet für jede Beobachtung den Fehler, quadriert diesen Fehler und bilden dann den Mittelwert dieser “Quadratfehler”, also einen <em>mittleren Quadratfehler</em>. Die englische Abkürzung <em>MSE</em> ist auch im Deutschen gebräuchlich.</p>
<p><span class="math display">\[ MSE = \frac{1}{n} \sum{(pred - obs)^2} \]</span></p>
<p>Konzeptionell ist dieses Maß an die Varianz angelehnt. Zieht man aus diesem Maß die Wurzel, so erhält man den sog. <em>root mean square error</em> (RMSE), welchen man sich als die Standardabweichung der Vorhesagefehler vorstellen kann. In Pseudo-R-Syntax:</p>
<pre class="pseudo"><code>RMSE &lt;- sqrt(mean((df$pred - df$obs)^2))</code></pre>
<p>Der RMSE hat die selben Einheiten wie die zu schätzende Variable, also z.B. Schuhgrößen-Nummern.</p>
<p>Übrigens: Der RMSE hat eine Reihe von wünschenswerten statistischen Eigenschaften, über die wir uns hier ausschweigen</p>
</div>
<div id="r-quadrat-r2" class="section level3">
<h3><span class="header-section-number">11.6.2</span> R-Quadrat (<span class="math inline">\(R^2\)</span>)</h3>
<p><span class="math inline">\(R^2\)</span>, auch Bestimmtheitsmaß oder Determinationskoeffizient genannt, gibt die Vorhersagegüte im Verhältnis zu einem “Nullmodell” an. Das Nullmodell hier würde sagen, wenn es sprechen könnte: “Keine Ahnung, was ich schätzen soll, mich interessieren auch keine Prädiktoren, ich schätzen einfach immer den Mittelwert der Grundgesamtheit!”.</p>
<p>Damit gibt <span class="math inline">\(R^2\)</span> an, wie gut unsere Vorhersagen im Verhältnis zu den Vorhersagen des Nullmodells sind. Ein <span class="math inline">\(R^2\)</span> von 25% (0.25) hieße, dass unser Vorhersagefehler 25% <em>kleiner</em> ist als der der Nullmodells. Ein <span class="math inline">\(R^2\)</span> von 100% (1) heißt also, dass wir den kompletten Fehler reduziert haben (Null Fehler übrig) - eine perfekte Vorhersage. Etwas formaler, kann man <span class="math inline">\(R^2\)</span> so definieren:</p>
<p><span class="math display">\[ R^2 = 1 - (\frac{Nullmodellfehler - Vorhersagefehler}{Nullmodellfehler})\]</span></p>
<p>Präziser, in R-Syntax:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">R2 &lt;-<span class="st"> </span><span class="dv">1</span> -<span class="st"> </span><span class="kw">sum</span>((df$pred -<span class="st"> </span>df$obs)^<span class="dv">2</span>) /<span class="st"> </span><span class="kw">sum</span>((<span class="kw">mean</span>(df$obs) -<span class="st"> </span>df$obs)^<span class="dv">2</span>)</code></pre></div>
<p>Praktischerweise gibt es einige R-Pakete, die diese Berechnung für uns besorgen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)
<span class="kw">postResample</span>(<span class="dt">obs =</span> obs, <span class="dt">pred =</span> pred)</code></pre></div>
<p>Hier steht<code>obs</code> für beobachtete Werte und <code>pred</code> für die vorhergesagten Werte. Dieser Befehl gibt sowohl RMSE als auch <span class="math inline">\(R^2\)</span> wieder.</p>
</div>
<div id="likelihood-and-friends" class="section level3">
<h3><span class="header-section-number">11.6.3</span> Likelihood and Friends</h3>
<p>Der <em>Likelihood</em> <span class="math inline">\(L\)</span> beantwortet folgende Frage:</p>
<blockquote>
<p>Angenommen, ein Modell M ist wahr. Wie wahrscheinlich ist es dann, die Daten D zu beobachten?</p>
</blockquote>
<p>Zum Beispiel: Eine faire Münze wird 10 Mal geworfen (Modell M: faire Münze). Wie wahrscheinlich ist es, 10 Mal Zahl zu werfen? Die Wahrscheinlichkeit hierfür liegt bei ca. 0.1%. Der Likelihood wäre also hier ~0.1%.</p>
<p>Bei komplexen Modellen kann der Likelihood sehr klein werden. Damit haben Computer Probleme, weil z.B. nur eine begrenzte Anzahl von Dezimalen berücksichtigt werden. Werden zuviele Dezimalstellen gerundet, kann es das Ergebnis verfälschen. Daher wird der Likelihood häufig logarithmiert; man spricht dann vom <em>log Likelihood</em>. Der Logarithmus von einer positiven, sehr kleine Zahl ist eine negative Zahl mit großen Absolutwert. Man verwendet meist den natürlichen Logarithmus, wobei das eigentlich keine Rolle spielt. Manchmal dreht man noch das Vorzeichen um, damit der Log Likelihood wieder positiv ist.</p>
<p>Gütekriterien wie AIC, BIC, CAIC oder die Devianz (engl. <em>deviance</em>) sind vom Likelihood abgeleitet. Meist wird noch berücksichtigt, wie komplex das Modell ist; komplexe Modelle tun sich leichter als einfachere Modelle, die Daten zu erklären. Aber sie könnten die Daten auch “überanpassen”. Um die mögliche Scheingenauigkeit komplexerer Modelle auszugleichen, wird der Likelihood vom AIC etc. mit einem Strafwert belegt, der proportional zur Komplexität des Modells ist <span class="citation">(Zumel, Mount, und Porzak <a href="#ref-zumel2014practical">2014</a>)</span>.</p>

<div class="rmdcaution">
<p>Man sollte in der Regel die Korrelation (r) nicht als Gütekriterium verwenden. Der Grund ist, dass die Korrelation sich nicht verändert, wenn man die Variablen skaliert. Die Korrelation zieht allein auf das Muster der Zusammenhänge - nicht die Größe der Abstände - ab. In der Regel ist die Größe der Abstände zwischen beobachteten und vorhergesagten Werten das, was uns interessiert.</p>
</div>
<p></p>
</div>
</div>
<h3>Literaturverzeichnis</h3>
<div id="refs" class="references">
<div id="ref-uncertainty">
<p>Briggs, William M. 2016. <em>Uncertainty: The Soul of Modeling, Probability &amp; Statistics</em>. Springer. <a href="https://www.amazon.com/Uncertainty-Soul-Modeling-Probability-Statistics-ebook/dp/B01JEJNUJK%3FSubscriptionId%3D0JYN1NVW651KCA56C102%26tag%3Dtechkie-20%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3DB01JEJNUJK">https://www.amazon.com/Uncertainty-Soul-Modeling-Probability-Statistics-ebook/dp/B01JEJNUJK%3FSubscriptionId%3D0JYN1NVW651KCA56C102%26tag%3Dtechkie-20%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3DB01JEJNUJK</a>.</p>
</div>
<div id="ref-zumel2014practical">
<p>Zumel, Nina, John Mount, und Jim Porzak. 2014. <em>Practical data science with R</em>. Manning.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inferenz-in-der-linearen-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="vertiefungen-zum-regressionmodell.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
