{
    "collab_server" : "",
    "contents" : "```{r include=FALSE, cache=FALSE}\nset.seed(1014)\noptions(digits = 3)\n\nknitr::opts_chunk$set(\n  comment = \"#>\",\n  message = FALSE,\n  warning = FALSE,\n  collapse = TRUE,\n  cache = TRUE,\n  out.width = \"70%\",\n  fig.align = 'center',\n  fig.width = 6,\n  fig.asp = 0.618,  # 1 / phi\n  fig.show = \"hold\"\n)\n\n```\n\n\n\n# Klassische lineare (numerische) Regression\n\n\n```{r echo = FALSE, out.width = \"30%\", fig.align = \"center\"}\nknitr::include_graphics(\"images/FOM.jpg\")\n```\n\n```{r echo = FALSE, out.width = \"10%\", fig.align = \"center\"}\nknitr::include_graphics(\"images/licence.png\")\n```\n\n\n```{block2, ziele-regression, type='rmdcaution', echo = TRUE} \nLernziele:\n\n- Wissen, was man unter Regression versteht.\n- Die Annahmen der Regression überprüfen können.\n- Regression mit kategorialen Prädiktoren durchführen können.\n- Die Regression inferenzstatisisch absichern können.\n- Die Modellgüte bei der Regression bestimmen können.\n- Vertiefende Aspekte beherrschen, wie Modellwahl und Interaktionen.\n\n\n```\n\n\nFür dieses Kapitel benötigen Sie folgende Pakete:\n```{r libs-regr}\nlibrary(caret)  # Modellieren\nlibrary(tidyverse)  # Datenjudo, Visualisierung,...\nlibrary(gridExtra)  # Mehrere Plots kombinieren\nlibrary(modelr)  # Residuen und Schätzwerte zum Datensatz hinzufügen\n```\n\n\n## Die Idee der klassischen Regression\n\nRegression\\index{Regression} ist eine bestimmte Art der *Modellierung* von Daten. Wir legen eine Gerade \"schön mittig\" in die Daten; damit haben wir ein einfaches Modell der Daten (vgl. Abb. \\@ref(fig:bsp-regression)).\n\n```{r bsp-regression, fig.cap = \"Beispiel für eine Regression\"}\nstats_test <- read.csv(\"data/test_inf_short.csv\")\n\nstats_test %>% \n  ggplot +\n  aes(x = study_time, y = score) +\n  geom_jitter() +\n  geom_abline(intercept = 24, \n              slope = 2.3, \n              color = \"red\")\n\n```\n\nSchauen wir uns die Syntax genauer an.\n\n```{block2, pseudo-regression, type='rmdpseudocode', echo = TRUE} \n\nLade die CSV-Datei mit den Daten als `stats_test`.\n  \nNehme `stats_test` UND DANN...  \nstarte ein neues Diagramm mit ggplot  \ndefiniere das Diagramm (X-Achse, Y-Achse)  \nzeichne das Geom \"Jitter\" (verwackeltes Punktediagramm)  \nund zeichne danach eine Gerade (\"abline\" in rot). \n\n\n```\n\nEine Regression zeigt anhand einer Regressionsgeraden einen \"Trend\" in den Daten an (s. weitere Beispiele in Abb. \\@ref(fig:bsp-regression2)).\n\n```{r bsp-regression2, echo = FALSE, fig.cap = \"Zwei weitere Beispiele für Regressionen\"}\n\nstats_test %>% \n   ggplot +\n  aes(x = self_eval, y = score) +\n  geom_jitter() +\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE) -> p1\n\n\nstats_test %>% \n   ggplot +\n  aes(x = interest, y = score) +\n  geom_jitter() +\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE) -> p2\n\n\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n\n\n```\n\n\nEine Regression lädt förmlich dazu ein, Vorhersagen zu treffen: Hat man erstmal eine Gerade, so kann man für jeden X-Wert (\"Prädiktor\") eine Vorhersage für den Y-Wert (\"Kriterium\") treffen. Anhand des Diagramms kann man also für jede Person (d.h. jeden Wert innerhalb des Wertebereichs von `study_time` oder einem anderen Prädiktor) einen Wert für `score` vorhersagen. Wie gut die Vorhersage ist, steht erstmal auf einen anderen Blatt.\n\nMan beachte, dass eine Gerade über ihre *Steigung* und ihren *Achsenabschnitt* festgelegt ist; in Abb. \\@ref(fig:bsp-regression) ist die Steigung 2.3 und der Achsenabschnitt 24.\n\nDer Achsenabschnitt zeigt also an, wie viele Klausurpunkte man \"bekommt\", wenn man gar nicht lernt (Gott bewahre); die Steigung gibt eine Art \"Wechselkurs\" an: Wie viele Klausurpunkte bekomme ich pro Stunde, die ich lerne. \n\nUnser Modell ist übrigens einfach gehalten: Man könnte argumentieren, dass der Zusatznutzen der 393. Stunde lernen geringer ist als der Zusatznutzen der ersten paar Stunden. Aber dann müssten wir anstelle der Gerade eine andere Funktion nutzen, um die Daten zu modellieren. Lassen wir es erst einmal einfach hier.\n\nAls \"Pseudo-R-Formel\" ausgedrückt: \n```\nscore = achsenabschnitt + steigung*study_time\n```\n\nDie Vorhersage für die Klausurpunkte (`score`) einer Person sind der Wert des Achsenabschnitts plus das Produkt aus der Anzahl der gelernten Stunden mal den Zusatznutzen pro gelernter Stunde.\n\n\nAber wie erkannt man, ob eine Regression \"gut\" ist - die Vorhersagen also präzise?\n\nIn R kann man eine Regression so berechnen:\n\n```{r}\nlm(score ~ study_time, data = stats_test)\n```\n\n`lm` steht dabei für \"lineares Modell\"; allgemeiner gesprochen lautet die Rechtschreibung für diesen Befehl:\n\n```\nlm(kriterium ~ praediktor, data = meine_datentabelle)\n```\n\nUm ausführlichere Informationen über das Regressionsmodell zu bekommen, kann man die Funktion `summary` nutzen:\n\n```\nmein_lm <- lm(kriterium ~ praediktor, data = meine_datentabelle)\nsummary(lm)\n```\n\nNatürlich kann das auch ~~in der Pfeife rauchen~~ mit der Pfeife darstellen:\n\n```\nlm(kriterium ~ praediktor, data = meine_datentabelle) %>% \n  lm\n```\n\n\n## Vorhersagegüte\n\nDer einfache Grundsatz lautet: Je geringer die Vorhersagefehler, desto besser; Abb. \\@ref(fig:resids-plot) zeigt ein Regressionsmodell mit wenig Vorhersagefehler (links) und ein Regressionsmodell mit viel Vorhersagefehler (rechts).\n\n```{r resids-plot, echo = FALSE, results = \"hold\", fig.cap = \"Geringer (links) vs. hoher (rechts) Vorhersagefehler\"}\n\nset.seed(42)  \nN      <- 100\nbeta   <- 0.4\nintercept <- 1\n\n\nsim <- data_frame(\n  x = rnorm(N),\n  error1 = rnorm(N, mean = 0, sd = .5),\n  error2 = rnorm(N, mean = 0, sd = 2),\n  y1 = intercept + x*beta + error1,\n  y2 = intercept + x*beta + error2,\n  pred = 1 + x*beta\n)\n\n\n\np1 <- ggplot(sim, aes(x, y1)) + \n  geom_abline(intercept = intercept, slope = beta, colour = \"red\") +\n  geom_point(colour = \"#00998a\") +\n  geom_linerange(aes(ymin = y1, ymax = pred), colour = \"grey40\") +\n  ylim(-6,+6)\n\n\np2 <- ggplot(sim, aes(x, y2)) + \n  geom_abline(intercept = intercept, slope = beta, colour = \"red\") +\n  geom_point(colour = \"#00998a\") +\n  geom_linerange(aes(ymin = y2, ymax = pred), colour = \"grey40\") +\n  ylim(-6,+6)\n\n\ngrid.arrange(p1, p2, ncol = 2)\n\n```\n\n\nIn einem Regressionsmodell lautet die grundlegenden Überlegung zur Modellgüte damit:\n\n>    Wie groß ist der Unterschied zwischen Vorhersage und Wirklichkeit?\n\nDie Größe des Unterschieds (Differenz, \"Delta\") zwischen vorhergesagten (geschätzten) Wert und Wirklichkeit, bezeichnet man als *Fehler*, *Residuum* oder Vohersagefehler, häufig mit $\\epsilon$ (griechisches e wie \"error\") abgekürzt.\n\n\nBetrachten Sie die beiden Plots in Abb. \\@ref(fig:resids-plot). Die rote Linie gibt die *vorhergesagten* (geschätzten) Werte wieder; die Punkte die *beobachteten* (\"echten\") Werte. Je länger die blauen Linien, desto größer die Vorhersagefehler. Je größer der Vorhersagefehler, desto schlechter. Und umgekehrt.\n\n>   Je kürzer die typische \"Abweichungslinie\", desto besser die Vohersage.\n\n\nSagt mein Modell voraus, dass Ihre Schuhgröße 49 ist, aber in Wahrheit liegt sie bei 39, so werden Sie dieses Modell als schlecht beurteilen, wahrscheinlich.\n\nLeider ist es nicht immer einfach zu sagen, wie groß der Fehler sein muss, damit das Modell als \"gut\" bzw. \"schlecht\" gilt. Man kann argumentieren, dass es keine wissenschaftliche Frage sei, wie viel \"viel\" oder \"genug\" ist [@uncertainty]. Das ist zwar plausibel, hilft aber nicht, wenn ich eine Entscheidung treffen muss. Stellen Sie sich vor: Ich zwinge Sie mit der Pistole auf der Brust, meine Schuhgröße zu schätzen.\n\nEine einfache Lösung ist, das beste Modell unter mehreren Kandidaten zu wählen.\n\nEin anderer Ansatz ist, die Vorhersage in Bezug zu einem Kriterium zu setzen. Dieses \"andere Kriterium\" könnte sein \"einfach die Schuhgröße raten\". Oder, etwas intelligenter, Sie schätzen meine Schuhgröße auf einen Wert, der eine gewisse Plausibilität hat, also z.B. die durchschnittliche Schuhgröße des deutschen Mannes. Auf dieser Basis kann man dann quantifizieren, ob und wieviel besser man als dieses Referenzkriterium ist.\n\n### Mittlere Quadratfehler\nEine der häufigsten Gütekennzahlen ist der *mittlere quadrierte Fehler* (engl. \"mean squared error\", MSE), wobei Fehler wieder als Differenz zwischen Vorhersage (`pred`) und beobachtete Wirklichkeit (`obs`, `y`) definiert ist. Dieser berechnet für jede Beobachtung den Fehler, quadriert diesen Fehler und bilden dann den Mittelwert dieser \"Quadratfehler\", also einen *mittleren Quadratfehler*. Die englische Abkürzung *MSE* ist auch im Deutschen gebräuchlich.\n\n$$ MSE = \\frac{1}{n} \\sum{(pred - obs)^2} $$\n\nKonzeptionell ist dieses Maß an die Varianz angelehnt. Zieht man aus diesem Maß die Wurzel, so erhält man den sog. *root mean square error* (RMSE), welchen man sich als die Standardabweichung der Vorhersagefehler vorstellen kann. In Pseudo-R-Syntax:\n\n```\nRMSE <- sqrt(mean((df$pred - df$obs)^2))\n```\n\nDer RMSE hat die selben Einheiten wie die zu schätzende Variable, also z.B. Schuhgrößen-Nummern.\n\n\n\n\n### R-Quadrat ($R^2$)\n$R^2$, auch *Bestimmtheitsmaß*\\index{Bestimmtheitsmaß} oder Determinationskoeffizient\\index{Determinationskoeffizient} genannt, gibt die Vorhersagegüte\\index{Vorhersagegüte} im Verhältnis zu einem \"Nullmodell\" an. Das Nullmodell hier würde sagen, wenn es sprechen könnte: \"Keine Ahnung, was ich schätzen soll, mich interessieren auch keine Prädiktoren, ich schätzen einfach immer den Mittelwert der Grundgesamtheit!\".\n\nDamit gibt $R^2$ an, wie gut unsere Vorhersagen im Verhältnis zu den Vorhersagen des Nullmodells sind. Ein $R^2$ von 25% (0.25) hieße, dass unser Vorhersagefehler 25% *kleiner* ist als der der Nullmodells. Ein $R^2$ von 100% (1) heißt also, dass wir den kompletten Fehler reduziert haben (Null Fehler übrig) - eine perfekte Vorhersage. Etwas formaler, kann man $R^2$ so definieren:\n\n$$ R^2 = 1 - \\left( \\frac{Nullmodellfehler - Vorhersagefehler}{Nullmodellfehler} \\right)$$\n\nPräziser, in R-Syntax:\n\n`\nR2 <- 1 - sum((df$pred - df$obs)^2) / sum((mean(df$obs) - df$obs)^2)\n`\n\nPraktischerweise gibt es einige R-Pakete, z.B. `caret`, die diese Berechnung für uns besorgen:\n\n```{r R2-caret, eval = FALSE}\n\npostResample(obs = obs, pred = pred)\n```\n\nHier steht `obs` für beobachtete Werte und `pred` für die vorhergesagten Werte (beides numerische Vektoren). Dieser Befehl gibt sowohl RMSE als auch $R^2$ wieder.\n\n\n### Likelihood and Friends\n\nDer *Likelihood* $L$ beantwortet folgende Frage:\n\n>   Angenommen, ein Modell M ist wahr. Wie wahrscheinlich ist es dann, die Daten D zu beobachten?\n\nZum Beispiel: Eine faire Münze wird 10 Mal geworfen (Modell M: faire Münze). Wie wahrscheinlich ist es, 10 Mal Zahl zu werfen? Die Wahrscheinlichkeit hierfür liegt bei ca. 0.1%. Der Likelihood wäre also hier ~0.1%.\n\nBei komplexen Modellen kann der Likelihood sehr klein werden. Damit haben Computer Probleme, weil z.B. nur eine begrenzte Anzahl von Dezimalen berücksichtigt werden. Werden zu viele Dezimalstellen gerundet, kann es das Ergebnis verfälschen. Daher wird der Likelihood häufig logarithmiert; man spricht dann vom *log Likelihood*. Der Logarithmus von einer positiven, sehr kleine Zahl ist eine negative Zahl mit großen Absolutwert. Man verwendet meist den natürlichen Logarithmus, wobei das eigentlich keine Rolle spielt. Manchmal dreht man noch das Vorzeichen um, damit der Log Likelihood wieder positiv ist. \n\nGütekriterien wie AIC, BIC, CAIC oder die Devianz (engl. *deviance*) sind vom Likelihood abgeleitet. Meist wird noch berücksichtigt, wie komplex das Modell ist; komplexe Modelle tun sich leichter als einfachere Modelle, die Daten zu erklären. Aber sie könnten die Daten auch \"überanpassen\". Um die mögliche Scheingenauigkeit komplexerer Modelle auszugleichen, wird der Likelihood vom AIC etc. mit einem Strafwert belegt, der proportional zur Komplexität des Modells ist [@zumel2014practical].\n\n\n\n```{block2, r-nicht-als-guete, type='rmdcaution', echo = TRUE}\nMan sollte in der Regel die Korrelation (r) nicht als Gütekriterium verwenden. Der Grund ist, dass die Korrelation sich nicht verändert, wenn man die Variablen skaliert. Die Korrelation zieht allein auf das Muster der Zusammenhänge - nicht die Größe der Abstände - ab. In der Regel ist die Größe der Abstände zwischen beobachteten und vorhergesagten Werten das, was uns interessiert.\n\n```\n\n\n\n## Beispiel für eine Regression\nWir werden weiter den Datensatz *tips* analysieren [@bryant1995practical].\n\nSofern noch nicht geschehen, können Sie in [hier](https://goo.gl/whKjnl) als `csv`-Datei herunterladen:\n```{r load-data}\ntips <- read.csv(\"https://sebastiansauer.github.io/data/tips.csv\")\n```\n\n\n\nWie hängen Trinkgeldhöhe `tip` und Rechnungshöhe `total_bill` zusammen? Kann die Höhe des Trinkgeldes als *lineare* Funktion der Rechnungshöhe linear modelliert werden? \n$$tip_i=\\beta_0+\\beta_1\\cdot total\\_bill_i+\\epsilon_i$$\n\nZunächst eine visuelle Analyse mi Hilfe eines Scatterplots.\n```{r}\nqplot(y = tip, x = total_bill, data = tips)\n```\n\nEs scheint einen positiven Zusammenhang zu geben. Modellieren wir das Kriterium `tip` (inhaltliche Entscheidung!) als lineare Funktion des Prädiktors `total_bill`:\n\n```{r}\nLinMod.1 <- lm(tip ~ total_bill, data=tips)\nsummary(LinMod.1)\n```\n\n\nDer Achsenabschnitt (`intercept`) wird mit `r round(coef(LinMod.1)[1],2)` geschätzt, die Steigung in Richtung `total_bill` mit `r round(coef(LinMod.1)[2],2)`: steigt `total_bill` um einen Dollar, steigt im *Durchschnitt* `tip` um `r round(coef(LinMod.1)[2], 2)`. \n\nDie (Punkt-)Prognose für `tip` lautet also\n\n`tip` = `r round(coef(LinMod.1)[1],2)` + `r round(coef(LinMod.1)[2],2)` * `total_bill`\n\nDie Koeffizienten (Steigung und Achsenabschnitt) werden dabei so geschätzt, dass $\\sum \\epsilon_i^2$ minimiert wird. Dies wird auch als  *Kleinste Quadrate* (*Ordinary Least Squares*, *OLS*) Kriterium bezeichnet^[Eine robuste Regression ist z. B. mit der Funktion `rlm()` aus dem Paket `MASS` möglich].\n\n\nDie (Punkt-)Prognose für die Trinkgeldhöhe, bspw. für eine Rechnung von 30$ kann einfacher berechnet werden mit\n\n```{r}\npredict(LinMod.1, data.frame(total_bill = 30))\n```\n\nalso ca. 4$.\n\nBerechnen wir noch die Vorversagegüte des Modells.\n\n```{r}\nsummary(LinMod.1)\n```\n\n\nDas Bestimmtheitsmaß $R^2$ ist mit `r round(summary(LinMod.1)$r.squared,2)` \"ok\": `r round(summary(LinMod.1)$r.squared*100)`-\\% der Variation des Trinkgeldes wird im Modell \"erklärt\".\n\n\n## Überprüfung der Annahmen der linearen Regression\n\nAber wie sieht es mit den Annahmen aus?\n\n- Die *Linearität des Zusammenhangs* haben wir zu Beginn mit Hilfe des Scatterplots \"überprüft\".\n- Zur Überprüfung der *Normalverteilung der Residuen* zeichnen wir ein Histogramm. Die *Residuen*\\index{Residuen} können über den Befehl `add_residuals` (Paket `modelr`) zum Datensatz hinzugefügt werden. Dann wird eine Spalte mit dem Namen `resid` zum Datensatz hinzugefügt.  \n\nHier scheint es zu passen:\n\n```{r}\ntips %>% \n  add_residuals(LinMod.1) %>% \n  ggplot +\n  aes(x = resid) +\n  geom_histogram()\n```\n\nÜbrigens kann man das Paket `modelr` auch nutzen, um sich komfortabel die vorhergesagten Werte zum Datensatz hinzufügen zu lassen (Spalte `pred`):\n\n```{r}\ntips %>% \n  add_predictions(LinMod.1) %>% \n  ggplot +\n  aes(x = pred) +\n  geom_histogram()\n```\n\n\n- *Konstante Varianz*: Dies kann z. B. mit einem Scatterplot der Residuen auf der y-Achse und den angepassten Werten auf der x-Achse überprüft werden. Bei jedem X-Wert sollte die Varianz der Y-Werte (etwa) gleich sein.\n\nDie angepassten (geschätzten) Werte kann man über den Befehl `add_predictions()` aus dem Paket `modelr` bekommen. Die Fehlerwerte entsprechend mit dem Befehl `add_residuals`.  Hypothesentests, d. h., $H_0:\\beta_1=0$. \n\n```{r tips-preds-resid, fig.cap = \"Vorhergesagte Werte vs. Residualwerte im Datensatz tips\"}\ntips %>% \n  add_predictions(LinMod.1) %>% \n  add_residuals(LinMod.1) %>% \n  ggplot() +\n  aes(y = resid, x = pred) +\n  geom_point()\n\n```\n\n\nDie Annahme der konstanten Varianz scheint verletzt zu sein (vgl. Abb. \\@ref(fig:tips-preds-resid)): je größer die Prognose des Trinkgeldes, desto größer wirkt die Streuung der Residuen. Dieses Phänomen ließ sich schon aus dem ursprünglichen Scatterplot \n`qplot(x = tip, y = total_bill, data=tips)` erahnen. Das ist auch inhaltlich plausibel: je höher die Rechnung, desto höher die Varianz beim Trinkgeld. Die Verletzung dieser Annahme beeinflusst *nicht* die Schätzung der Steigung, sondern die Schätzung des Standardfehlers, also des p-Wertes des\n\n- *Extreme Ausreißer*: Wie am Streudiagramm erkennbar, gibt es vereinzelt Ausreißer nach oben, allerdings ohne einen extremen Hebel.\n\n\n\n\n\n```{block2, tips-uebung, type='rmdexercises', echo = TRUE}\n1.  Um wie viel Dollar steigt im Durchschnitt das Trinkgeld, wenn eine Person mehr am Tisch sitzt?\n\n2.  Für wie aussagekräftig halten Sie Ihr Ergebnis aus 1.?\n\n```\n\n\n\n## Regression mit kategorialen Prädiktoren\nDer Wochentag `day` ist eine kategoriale Variable. Wie sieht eine Regression des Trinkgeldes darauf aus?\n\nZunächst grafisch:\n```{r}\nqplot(x = tip,y = day, data=tips)\n```\n\nUnd als Lineares Modell:\n```{r}\nLinMod.2 <- lm(tip ~ day, data=tips)\nsummary(LinMod.2)\n```\n\nDie im Modell angegebenen Schätzwerte sind die Änderung der Trinkgeldprognose, wenn z. B. der Tag ein Samstag (`daySat`) im Vergleich zu einer Referenzkategorie. Dies ist in R das erste Element des Vektors der Faktorlevel. Welcher dies ist ist über den Befehl `levels()` zu erfahren\n```{r}\nlevels(tips$day)\n```\n\n\nMöchte man die Reihenfolge der Faktorstufen ändern, so kann man innerhalb von `factor()` die Option `levels=` direkt in der gewünschten Sortierung setzen, z.B. so:\n\n```{r, eval=FALSE}\nday <- factor(tips$day, levels=c(\"Thur\", \"Fri\", \"Sat\",  \"Sun\"))\n```\n\n\n\n\n```{block2, tips-uebung2, type='rmdexercises', echo = TRUE}\n3.  Wie verändert sich die Rechnungshöhe im Durchschnitt, wenn die Essenszeit Dinner statt Lunch ist?\n4.  Wie viel \\% der Variation der Rechnungshöhe können Sie durch die Essenszeit modellieren?\n\n```\n\n\n\n\n## Multiple Regression\nAber wie wirken sich mehrere Einflussgrößen *zusammen* auf das Trinkgeld aus?\n```{r}\nLinMod.4 <- lm(tip ~ total_bill + size + sex  + smoker + day + time, data=tips)\nsummary(LinMod.4)\n```\nInteressant sind die negativen Vorzeichen vor den Schätzwerten für `sexMale` und `smokerYes` -- anscheinend geben Männer und Raucher weniger Trinkgeld, wenn alle anderen Faktoren konstant bleiben. Bei einer rein univariaten Betrachtung wäre etwas anderes herausgekommen!\n\n```{r}\nlm(tip ~ sex, data=tips) %>% summary\nlm(tip ~ smoker, data=tips)  %>% summary\n```\nDiese *Umkehrung* des modellierten Effektes liegt daran, dass es auch einen positiven Zusammenhang zur Rechnungshöhe gibt:\n```{r}\nlm(total_bill ~ sex, data=tips) %>% summary\nlm(total_bill ~ smoker, data=tips) %>% summary\n```\n\nIm vollem Modell `LinMod.4` sind alle unabhängigen Variablen berücksichtigt, die Koeffizienten beziehen sich dann immer auf: gegeben, die anderen Variablen bleiben konstant, d.h. ceteris paribus.\n\nVergleichen wir mal zwei Modelle:\n```{r}\nLinMod.5a <- lm(tip ~  sex, data=tips)\ncoef(LinMod.5a) # Koeffizienten extrahieren\nLinMod.5b <- lm(tip ~  sex + total_bill, data=tips)\ncoef(LinMod.5b) # Koeffizienten extrahieren\n```\nOhne die Berücksichtigung der **Kovariable/Störvariable** Rechnungshöhe geben \n `r levels(tips$sex)[2]`  \n ein um im Durchschnitt `r round(coef(LinMod.5a)[2],2)`\n *höheres* Trinkgeld, bei Kontrolle, d. h. gleicher Rechnungshöhe ein um \n `r abs(round(coef(LinMod.5b)[2],2))`\n *niedrigeres* Trinkgeld als die Referenzklasse \n `r levels(tips$sex)[1]` (`levels(tips$sex)[1]`). \n\n## Inferenz in der linearen Regression\nKehren wir noch einmal zur multiplen Regression (`LinMod.4`) zurück. \n```{r}\nsummary(LinMod.4)\n```\n\nIn der 4. Spalte der, mit Zeilennamen versehenen Tabelle `Coefficients` stehen die p-Werte der Nullhypothese, die unabhängige Variable hat, gegeben alle anderen Variablen im Modell, keinen linearen Einfluss auf die abhängige Variable: $H_0: \\beta_i=0$. \n\nZur schnelleren Übersicht finden sich dahinter \"Sternchen\" und \"Punkte\", die die entsprechenden Signifikanzniveaus symbolisieren: `***` bedeutet eine Irrtumswahrscheinlichkeit, Wahrscheinlichkeit für Fehler 1. Art, von unter 0.001, d. h. unter 0,1\\%. `**` entsprechend 1\\%, `*` 5\\% und `.` 10\\%. \n\nZum Signifikanzniveau von 10\\% sind hier also zwei Faktoren und der Achsenabschnitt (`(Intercept)`) signifikant -- nicht notwendigerweise relevant: Rechnungshöhe `total_bill` sowie Anzahl Personen `size`. Beides wirkt sich linear positiv auf die Trinkgeldhöhe aus: Mit jedem Dollar Rechnungshöhe steigt im Mittelwert die Trinkgeldhöhe um `r round(coef(LinMod.4)[2],2)` Dollar, \nmit jeder Person um `r round(coef(LinMod.4)[3],2)` Dollar -- gegeben alle anderen Faktoren bleiben konstant. Das Bestimmtheitsmaß R² (`Multiple R-squared:`) liegt bei \n`r round(summary(LinMod.4)$r.squared,2)`, also `r round(summary(LinMod.4)$r.squared*100)`\\% der Variation des Trinkgeldes wird im Modell erklärt.\n\nAußerdem wird getestet, ob alle Koeffizienten der unabhängigen Variablen gleich Null sind:\n$$H_0: \\beta_1=\\beta_2=\\cdots=\\beta_k=0$$\nDas Ergebnis des zugrunde-liegenden F-Tests (vgl. Varianzanalyse) wird in der letzten Zeile angegeben (`F-Statistic`). Hier wird $H_0$ also verworfen.\n\n\n\n## Vertiefungen zum Regressionmodell\n\n### Modellwahl\nDas Modell mit allen Variablen des Datensatzes, d. h., mit 6 unabhängigen (`LinMod.4`) erklärt `r round(summary(LinMod.4)$r.squared*100,2)`% der Variation, das Modell *nur* mit der Rechnungshöhe als erklärende Variable (`LinMod.1`) schon `r round(summary(LinMod.1)$r.squared*100,2)`%, der Erklärungszuwachs liegt also gerade einmal bei `r round(summary(LinMod.4)$r.squared*100,2) - round(summary(LinMod.1)$r.squared*100,2)` Prozentpunkten. In der Statistik ist die Wahl des *richtigen* Modells eine der größten Herausforderungen, auch deshalb, weil das wahre Modell in der Regel nicht bekannt ist und es schwer ist, die richtige Balance zwischen Einfachheit und Komplexität zu finden. Aufgrund des Zufalls kann es immer passieren, dass das Modell sich zu sehr an die *zufälligen* Daten anpasst (Stichwort: Overfitting). Es gibt unzählige Modellwahlmethoden, und leider garantiert keine, dass immer das beste Modell gefunden wird. Eine Möglichkeit ist die sogenannte Schrittweise-Rückwärtsselektion auf Basis des Akaike-Informationskriteriums (AIC)^[siehe z. B. Rob J Hyndman & George Athanasopoulos, Forecasting: principles and practice [@hyndman2014forecasting], Kapitel 5.3: Selecting predictors,   [https://www.otexts.org/fpp/5/3](https://www.otexts.org/fpp/5/3)]. Diese ist nicht nur recht weit verbreitet - und liefert unter bestimmten Annahmen das \"richtige\" Modell - sondern in R durch den Befehl `step()` einfach umsetzbar:\n```{r}\nstep(LinMod.4)\n```\nIn den letzten Zeilen der Ausgabe steht das beste Modell, das diese Methode (schrittweise, rückwärts) mit diesem Kriterium (AIC) bei diesen Daten findet (Punktprognose, d. h. ohne Residuum):\n\n`tip =  0.66894 +  0.09271 * total_bill + 0.19260 * size`\n\nDer Ausgabe können Sie auch entnehmen, welche Variablen in welcher Reihenfolge *entfernt* wurden: Zunächst `day`, dann `time`, danach `sex` und schließlich `smoker`. Hier sind also dieselben Variablen noch im Modell, die auch in `LinMod.4` signifikant zum Niveau 10\\% waren, eine Auswahl der dort signifikanten Variablen hätte also dasselbe Modell ergeben. Das ist häufig so, aber nicht immer!\n\n### Interaktionen \n\nWir haben gesehen, dass es einen Zusammenhang zwischen der Trinkgeldhöhe und der Rechnungshöhe gibt. Vielleicht unterscheidet sich der Zusammenhang je nachdem, ob geraucht wurde, d. h., vielleicht gibt es eine Interaktion (Wechselwirkung). Die kann in `lm` einfach durch ein `*` zwischen den unabhängigen Variablen modelliert werden:\n\n```{r}\nLinMod.6 <- lm(tip ~ smoker*total_bill, data = tips)\nsummary(LinMod.6)\n```\n\nDer Schätzwert für die Interaktion steht bei `:`. Hier also: Wenn geraucht wurde, ist die Steigung im Durchschnitt um 6,8 Cent geringer. Aber wenn geraucht wurde, ist die Rechnung im Achsenabschnitt erstmal um 1,20\\$ höher (Effekt, ceteris paribus). Wer will, kann ausrechnen, ab welcher Rechnungshöhe Rauchertische im Mittelwert lukrativer sind... \n\nDas gleiche Bild (höhere Achsenabschnitt, geringere Steigung) ergibt sich übrigens bei getrennten Regressionen:\n```{r}\nlm(tip~total_bill, data=tips, subset = smoker==\"Yes\")\nlm(tip~total_bill, data=tips, subset = smoker==\"No\")\n```\n\n### Weitere Modellierungsmöglichkeiten\n\nÜber das Formelinterface `y~x` können auch direkt z. B. Polynome modelliert werden. Hier eine quadratische Funktion:\n```{r}\nsummary(lm(tip~I(total_bill^2)+total_bill, data=tips))\n```\n\nD. h., die geschätzte Funktion ist eine \"umgedrehte Parabel\" (negatives Vorzeichen bei `I(total_bill^2) `), bzw. die Funktion ist konkav, die Steigung nimmt ab. Allerdings ist der Effekt nicht signifikant. **Hinweis:** Um zu \"rechnen\" und nicht beispielsweise Interaktion zu modellieren, geben Sie die Variablen in der Formel in der Funktion `I()` (*As Is*) ein.\n\n\n\n\n\n\n## Fallstudie zu Overfitting {#overfitting-casestudy}\n\nVergleichen wir im ersten Schritt eine Regression, die die Modellgüte anhand der *Trainingsstichprobe* schätzt mit einer Regression, bei der die Modellgüte in einer *Test-Stichprobe* überprüft wird.\n\n\nZuerst führen wir dafür eine simple Regression aus und lassen uns $R^2$ ausgeben.\n```{r lm-overfitting1}\ndf <-  read_csv(\"https://sebastiansauer.github.io/data/wo_men.csv\")\n\nlm1 <- lm(shoe_size ~ height, data = df)\nsummary(lm1)$r.squared\n```\n\n\nIm zweiten Schritt teilen wir die Stichprobe in eine Trainings- und eine Test-Stichprobe auf. Wir \"trainineren\" das Modell anhand der Daten aus der Trainings-Stichprobe:\n```{r lm-overfitting2}\ntrain <- df %>% \n  sample_frac(.8, replace = FALSE)  # Stichprobe von 80%, ohne Zurücklegen\n\ntest <- df %>% \n  anti_join(train)  # Alle Zeilen von \"df\", die nicht in \"train\" vorkommen\n\nlm2 <- lm(shoe_size ~ height, data = train)\n```\n\n\nDann testen wir (die Modellgüte) anhand der Test-Stichprobe. Also los, `lm2`, mach Deine Vorhersage:\n\n```{r lm-overfitting-predict}\nlm2_predict <- predict(lm2, newdata = test)\n```\n\nDiese Syntax sagt:\n\n```{block2, lm2-predict-block, type='rmdpseudocode', echo = TRUE}\nSpeichere unter dem Namen \"lm2_predict\" das Ergebnis folgender Berechnung:  \nMache eine Vorhersage (\"to predict\") anhand des Modells \"lm2\",   \nwobei frische Daten (\"newdata = test\") verwendet werden sollen. \n\n```\n\nAls Ergebnis bekommen wir einen Vektor, der für jede Beobachtung des Test-Samples den geschätzten (vorhergesagten) Trinkgeld-Wert speichert.\n\n```{r R2-postresample}\ncaret::postResample(pred = lm2_predict, obs = test$shoe_size)\n\n```\n\nDie Funktion `postResample` aus dem Paket `caret` liefert uns zentrale Gütekennzahlen unser Modell. Wir sehen, dass die Modellgüte im Test-Sample deutlich schlechter ist als im Trainings-Sample. Ein typischer Fall, der uns warnt, nicht vorschnell optimistisch zu sein!\n\n\n\n## Verweise\n\nDieses Kapitel basiert teilweise auf Übungen zum Buch [OpenIntro](https://www.openintro.org/stat/index.php?stat_book=isrs) [@introstats] unter der Lizenz [Creative Commons Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0). \n\n\n\n",
    "created" : 1493752760861.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4062215550",
    "id" : "8BB7B1EE",
    "lastKnownWriteTime" : 1493898460,
    "last_content_update" : 1493898460,
    "path" : "~/Documents/Publikationen/In_Arbeit/Praxis_der_Datenanalyse/071_Regression.Rmd",
    "project_path" : "071_Regression.Rmd",
    "properties" : {
        "docOutlineVisible" : "1",
        "ignored_words" : "mean,squared,error,sum,obs,überanpassen,Strafwert,Trinkgeldhöhe,Faktorlevel,paribus,Erklärungszuwachs,Modellwahlmethoden,Rückwärtsselektion,Akaike,Punktprognose,Rauchertische,Formelinterface,trainineren,bsp,regression,resids,e\n"
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}