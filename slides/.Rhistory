library(latex2exp)
unlink('PraDa_Folien_cache', recursive = TRUE)
stats_test <- read_csv("../data/test_inf_short.csv")
stats_test <- readr::read_csv("../data/test_inf_short.csv")
stats_test %>%
group_by(interessiert) %>%
summarise(score = mean(score)) -> score_interesse
library(tidyverse)
stats_test %>%
group_by(interessiert) %>%
summarise(score = mean(score)) -> score_interesse
stats_test$interessiert <- stats_test$interest > 3
stats_test %>%
group_by(interessiert) %>%
summarise(score = mean(score)) -> score_interesse
score_interesse
library(Grid)
library(grid)
grid.arrange(p1, p2, nrow = 2)
library(GridExtra)
library("gridExtra", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
Aktien <- readr::read_csv("../data/Aktien.csv") %>% na.omit
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
annotate(label = "Test", x= 5, y= .1)
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
annotate(label = "Test", x= 5, y= .1, geom = "text")
data_frame(
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
annotate(label = "Test", x= 5, y= .1, geom = "text")
data_frame(
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
annotate(label = "Test", x= 5, y= .1, geom = "text")
data_frame(
x = x,
y = y)
x <- seq(-10,10,by = 0.1)
y <- 1/(1+exp(-x))        # exp() ist die e-Funktion
data_frame(
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
annotate(label = "Test", x= 5, y= .1, geom = "text")
install.packages("TeX")
library(latex2exp)
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
annotate(label = "Test", x= 5, y= .1, geom = TeX("$p(y=1)=\\frac{e^x}{1+e^x}$"))
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
annotate(label = TeX("$p(y=1)=\\frac{e^x}{1+e^x}$"), x= 5, y= .1, geom = "text"))
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
annotate(label = TeX("$p(y=1)=\\frac{e^x}{1+e^x}$"), x= 5, y= .1, geom = "text")
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
labs(main = TeX("$p(y=1)=\\frac{e^x}{1+e^x}$"), x= 5, y= .1, geom = "text")
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
labs(main = TeX("$p(y=1)=\\frac{e^x}{1+e^x}$"))
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
ggtitle(TeX("$p(y=1)=\\frac{e^x}{1+e^x}$"))
x = x,
y = y) %>%
ggplot() +
aes(x = x, y = y) +
geom_line(color = "#00998a") +
ggtitle(TeX("Die e-Funktion: $p(y=1)=\\frac{e^x}{1+e^x}$"))
pander::pander(df, caption = "Vier Arten von Ergebnisse von Klassfikationen")
pander::pander(df, caption = "Vier Arten von Ergebnisse von Klassfikationen")
pander::pander(df, caption = "Vier Arten von Ergebnisse von Klassfikationen")
pander(df, caption = "Vier Arten von Ergebnisse von Klassfikationen")
library(pander)
pander(df, caption = "Vier Arten von Ergebnisse von Klassfikationen")
df <- readr::read_csv("../includes/class_results.csv")
pander(df, caption = "Vier Arten von Ergebnisse von Klassfikationen")
(cm <- SDMTools::confusion.matrix(Aktien$Aktienkauf,
glm1$fitted.values))
glm1 <- glm(Aktienkauf ~ Risikobereitschaft,
family = binomial("logit"),
data = Aktien)
(cm <- SDMTools::confusion.matrix(Aktien$Aktienkauf,
glm1$fitted.values))
confusion.matrix
SDMTools::confusion.matrix
sensitivity(cm); specificity(cm)
library(knitr)
library(gridExtra)
library(broom)
library(grid)
library(modelr)
library(viridis)
library(SDMTools)  # Güte von Klassifikationsmodellen
library(pROC)  # für ROC- und AUC-Berechnung
library(BaylorEdPsych)  # Pseudo-R-Quadrat
library(pander)
sensitivity(cm); specificity(cm)
library(cluster)
seg.k <- kmeans(segment.num, centers = 4, nstart = 10)
segment <- read.csv2("../data/segment.csv")
segment.num <- segment %>%
mutate(Frau = Geschlecht == "Frau") %>%
mutate(Eigenheim = Eigenheim == "Ja") %>%
mutate(Mitgliedschaft = Mitgliedschaft == "Ja") %>%
dplyr::select(-Geschlecht, -Segment)
seg.k <- kmeans(segment.num, centers = 4, nstart = 10)
seg.k
clusplot(segment.num, seg.k$cluster,
color = TRUE, shade = TRUE, labels = 4)
biplot(Werte.pc)
Werte.pca <- principal(Werte, nfactors = 5)
library(psych)
Werte.pca <- principal(Werte, nfactors = 5)
View(stats_test)
Werte <- read.csv2("../data/Werte.csv")
Werte.sc <- scale(Werte)
glimpse(Werte)
corrplot(cor(Werte.sc), order = "hclust")
Werte.pc <- prcomp(Werte.sc)  # Principal Components berechnen
Werte.pc$sdev[1]^2 / Gesamtvarianz
Gesamtvarianz <- sum(Werte.pc$sdev^2)
Werte.pc$sdev[1]^2 / Gesamtvarianz
plot(Werte.pc, type="l")
VSS.scree(Werte)
Werte.pca <- principal(Werte, nfactors = 5)
Werte.pca <- principal(Werte, nfactors = 5, rotate = "FALSE")
Werte.pca <- principal(Werte, nfactors = 5, rotate = "none")
Werte.ob <- factanal(Werte, factors = 5, scores = "Bartlett")
Werte.ob
tidytext_df %>% head
text <- c("Wir haben die Frauen zu Bett gebracht,",
"als die Männer in Frankreich standen.",
"Wir hatten uns das viel schöner gedacht.",
"Wir waren nur Konfirmanden.")
text_df <- data_frame(Zeile = 1:4,
text = text)
text_df %>%
unnest_tokens(wort, text) -> tidytext_df
tidytext_df %>% head
library(tidytext)
text_df %>%
unnest_tokens(wort, text) -> tidytext_df
tidytext_df %>% head
afd_count %>%
top_n(10) %>%
knitr::kable()
afd_df %>%
count(token, sort = TRUE) -> afd_count
afd_df %>%
na.omit() %>%  # fehlende Werte löschen
count(token, sort = TRUE)
afd_url <- paste0("https://www.alternativefuer.de",
"/wp-content/uploads/sites/7/2016/05/",
"2016-06-27_afd-grundsatzprogramm_web-version.pdf")
afd_pfad <- "data/afd_programm.pdf"
download(afd_url, afd_pfad)
afd_raw <- pdf_text(afd_pfad)
afd_df <- data_frame(Zeile = 1:96,
afd_raw)
afd_df %>%
unnest_tokens(token, afd_raw) %>%
filter(str_detect(token, "[a-z]")) -> afd_df
count(afd_df)
afd_url <- paste0("https://www.alternativefuer.de",
"/wp-content/uploads/sites/7/2016/05/",
"2016-06-27_afd-grundsatzprogramm_web-version.pdf")
afd_pfad <- "data/afd_programm.pdf"
download(afd_url, afd_pfad)
afd_raw <- pdf_text(afd_pfad)
afd_df <- data_frame(Zeile = 1:96,
afd_raw)
afd_df %>%
unnest_tokens(token, afd_raw) %>%
filter(str_detect(token, "[a-z]")) -> afd_df
count(afd_df)
afd_url <- paste0("https://www.alternativefuer.de",
"/wp-content/uploads/sites/7/2016/05/",
"2016-06-27_afd-grundsatzprogramm_web-version.pdf")
afd_pfad <- "data/afd_programm.pdf"
download(afd_url, afd_pfad)
afd_raw <- pdf_text(afd_pfad)
afd_df <- data_frame(Zeile = 1:96,
afd_raw)
afd_df %>%
unnest_tokens(token, afd_raw) %>%
filter(str_detect(token, "[a-z]")) -> afd_df
count(afd_df)
afd_url <- paste0("https://www.alternativefuer.de",
"/wp-content/uploads/sites/7/2016/05/",
"2016-06-27_afd-grundsatzprogramm_web-version.pdf")
afd_pfad <- "data/afd_programm.pdf"
download(afd_url, afd_pfad)
afd_raw <- pdf_text(afd_pfad)
afd_df <- data_frame(Zeile = 1:96,
afd_raw)
afd_df %>%
unnest_tokens(token, afd_raw) %>%
filter(str_detect(token, "[a-z]")) -> afd_df
count(afd_df)
library(stringr)  # Textverarbeitung
library(tidytext)  # Textmining
library(pdftools)  # PDF einlesen
library(downloader)  # Daten herunterladen
library(lsa)  # Stopwörter
library(SnowballC)  # Wörter trunkieren
library(wordcloud)  # Wordcloud anzeigen
find_fun("heatmap.2")
find_funs <- function(f) {
h <- help.search(paste0("^",f,"$"),agrep=FALSE)
h$matches[,"Package"]
}
find_funs("heatmap.2")
afd_url <- "../data/2016-06-27_afd-grundsatzprogramm_web-version.pdf"
afd_pfad <- "../data/afd_programm.pdf"
afd_raw <- pdf_text(afd_pfad)
afd_raw <- pdftools::pdf_text(afd_pfad)
warnings()
afd_count %>%
top_n(10) %>%
knitr::kable()
#library(mosaic)
library(tidyverse)
library(formatR)
library(knitr)
library(gridExtra)
library(broom)
library(grid)
library(modelr)
library(viridis)
library(SDMTools)  # Güte von Klassifikationsmodellen
library(pROC)  # für ROC- und AUC-Berechnung
library(BaylorEdPsych)  # Pseudo-R-Quadrat
library(pander)
library(cluster)
library(psych)
library(stringr)  # Textverarbeitung
library(tidytext)  # Textmining
library(pdftools)  # PDF einlesen
library(downloader)  # Daten herunterladen
library(lsa)  # Stopwörter
library(SnowballC)  # Wörter trunkieren
library(wordcloud)  # Wordcloud anzeigen
text <- c("Wir haben die Frauen zu Bett gebracht,",
"als die Männer in Frankreich standen.",
"Wir hatten uns das viel schöner gedacht.",
"Wir waren nur Konfirmanden.")
text_df <- data_frame(Zeile = 1:4,
text = text)
text_df %>%
unnest_tokens(output = wort, input = text) -> tidytext_df
tidytext_df %>% head
afd_url <- paste0("https://www.alternativefuer.de",
"/wp-content/uploads/sites/7/2016/05/",
"2016-06-27_afd-grundsatzprogramm_web-version.pdf")
afd_url <- "../data/2016-06-27_afd-grundsatzprogramm_web-version.pdf"
afd_pfad <- "../data/afd_programm.pdf"
# download(afd_url, afd_pfad)
afd_raw <- pdftools::pdf_text(afd_pfad)
afd_df <- data_frame(Zeile = 1:96,
afd_raw)
afd_df %>%
unnest_tokens(token, afd_raw) %>%
filter(str_detect(token, "[a-z]")) -> afd_df
count(afd_df)
afd_df %>%
na.omit() %>%  # fehlende Werte löschen
count(token, sort = TRUE)
afd_df %>%
na.omit() %>%  # fehlende Werte löschen
count(token, sort = TRUE) %>%
head
data(stopwords_de)
stopwords_de <- data_frame(word = stopwords_de)
stopwords_de <- stopwords_de %>%
rename(token = word)
afd_df %>%
anti_join(stopwords_de) -> afd_df
afd_df %>%
count(token, sort = TRUE) -> afd_count
afd_count %>% head
afd_count %>%
top_n(10) %>%
knitr::kable()
afd_count %>%
top_n(6) %>%
knitr::kable()
data(stopwords_de)
stopwords_de <- data_frame(word = stopwords_de)
stopwords_de <- stopwords_de %>%
rename(token = word)
afd_df %>%
anti_join(stopwords_de) -> afd_df
afd_df %>%
count(token, sort = TRUE) -> afd_count
mtcars %>% head %>% glimpse
library(tidyverse)
mtcars %>% head %>% glimpse
Werte <- read.csv2("../data/Werte.csv")
Werte.sc <- scale(Werte)
Werte.sc %>% scale %>% as_tibble
Werte.sc %>% scale %>% as_tibble -> Werte.sc
Werte %>% scale %>% as_tibble -> Werte.sc
Werte.sc %>%
dplyr::select(1:5) %>%
slice(1:5) %>%
knitr::kable
Werte.sc %>%
dplyr::select(1:5) %>%
slice(1:5)
Werte.sc %>%
dplyr::select(1:5) %>%
slice(1:5) %>%
knitr::kable()
unlink('PraDa_Folien_cache', recursive = TRUE)
