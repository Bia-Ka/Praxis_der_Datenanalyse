
## Baumbasierte Verfahren

### Konjunturanalyse
Der B3 Datensatz *Heilemann, U. and Münch, H.J. (1996): West German Business Cycles 1963-1994: A Multivariate Discriminant Analysis. CIRET–Conference in Singapore, CIRET–Studien 50.* enthält Quartalsweise Konjunkturdaten aus (West-)Deutschland.

```{r}
B3 <- read.csv2("https://goo.gl/0YCEHf")
str(B3) # Datenstruktur
head(B3); tail(B3)
```

Dabei sind folgende Variablen enthalten:

- Bruttosozialprodukt (real): `BSP91JW`
- Privater Verbrauch (real): `CP91JW`
- Anteil Staatsdefizit am Bruttosozialprodukt (%): `DEFRATE`
- Abhängig Erwerbstätige: `EWAJW`
- Anteil Außenbeitrag am Bruttosozialprodukt (%): `EXIMRATE`
- Geldmenge M1: `GM1JW`
- Investitionen in Ausrüstungsgüter (real): `IAU91JW`
- Investitionen in Bauten (real): `IB91JW`
- Lohnstückkosten: `LSTKJW`
- Preisindex des Bruttosozialprodukts: `PBSPJW`
- Preisindex des privaten Verbrauchs: `PCPJW`
- Kurzfristiger Zinssatz (nominal): `ZINSK`
- Langfristiger Zinssatz (real): `ZINSLR`
- Konjunkturphase: 1. Aufschwung, 2. Oberer Wendepunkt, 3. Abschwung,4. Unterer Wendepunkt: `PHASEN`

Variablen mit der Endung *JW* beziehen sich auf die jährliche Veränderung.

### Regressionsbäume
Um einen Regressionsbaum zu erzeugen, muss zunächst das Zusatzpaket `rpart` geladen werden:
```{r, message=FALSE}
library(rpart)
```

Um z. B. die Veränderung des Bruttosozialprodukt als Funktion von Privater Verbrauch, Investitionen in Ausrüstungsgüter, Investitionen in Bauten und Geldmenge M1 als Regressionsbaum zu modellieren reicht der Befehl
```{r}
regbaum <- rpart(BSP91JW ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=B3)
```


Um das Ergebnis auszugeben genügt:
```{r}
regbaum
```
*Lesebeispiel:* Wenn CP91JW>=3.705 und IAU91JW>=11.335 und IB91JW>=7.55 liegt, dann liegt die durchschnittliche Veränderung des BSP91JW bei 8.639. 11 Beobachtungen erfüllen die Kriterien der unabhängigen Variablen

Bzw. um den Baum zu zeichnen

```{r}
par(xpd = TRUE) # Grafikparameter der sicherstellt, dass alles ins Bild passt
plot(regbaum, compress = TRUE) # Baum zeichnen
text(regbaum) # Baum beschriften
```


Eine deutlich schönere Ausgabe erhält man z. B. mit dem Zusatzpaket `rpart.plot`, welches man *einmalig* über
```{r, eval=FALSE}
install.packages("rpart.plot")
```
installieren muss und dann benutzen kann.

Zunächst laden
```{r, message=FALSE}
library(rpart.plot)

```
und dann zeichnen:
```{r}
rpart.plot(regbaum)
```



#### Kreuzvalidierung

##### Anpassungsgüte
Wie gut ist das Modell? Über `predict` können die Punktprognosen berechnet werden:
```{r}
head(predict(regbaum))
```
Diese werden mit den beobachteten Werten verglichen:
```{r}
head(B3$BSP91JW)
```

Der **Mean Squared Error** ist dann
```{r}
baummse <- mean( (predict(regbaum) - B3$BSP91JW)^2 )
baummse
```

Vergleichen wir das Ergebnis mit dem einer linearen Regression
```{r}
reglm <- lm(BSP91JW ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=B3)
summary(reglm)
```

Der MSE der Linearen Regression liegt bei
```{r}
lmmse <- mean( (predict(reglm) - B3$BSP91JW)^2 )
lmmse
```

Der Baum ist einfacher und weniger flexibel, aber auch schlechter im Bezug auf die Anpassungsgüte.

##### Prognosegüte
Für eine k=3 fache Kreuzvalidierung müssen 3 Testdatensätze erzeugt werden.

Zunächst wird dafür ein Aufteilungsvektor gebildet:
```{r}
aufteilung <- rep(1:3, length.out=nrow(B3))
```
und dann wird aufgeteilt:
```{r}
test1 <- B3[aufteilung==1,]
train1 <- B3[aufteilung!=1,]

test2 <- B3[aufteilung==2,]
train2 <- B3[aufteilung!=2,]

test3 <- B3[aufteilung==3,]
train3 <- B3[aufteilung!=3,]
```

Anschließend werden die Modelle auf den Trainingsdaten geschätzt, und auf den Testdaten überprüft:
```{r}
# Runde 1
b1 <- rpart(BSP91JW ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train1)
l1 <- lm(BSP91JW ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train1)
mseb1 <- mean( (predict(b1, newdata = test1) - test1$BSP91JW)^2 )
msel1 <- mean( (predict(l1, newdata = test1) - test1$BSP91JW)^2 )

# Runde 2
b2 <- rpart(BSP91JW ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train2)
l2 <- lm(BSP91JW ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train2)
mseb2 <- mean( (predict(b2, newdata = test2) - test2$BSP91JW)^2 )
msel2 <- mean( (predict(l2, newdata = test2) - test2$BSP91JW)^2 )

# Runde 3
b3 <- rpart(BSP91JW ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train3)
l3 <- lm(BSP91JW ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train3)
mseb3 <- mean( (predict(b3, newdata = test3) - test3$BSP91JW)^2 )
msel3 <- mean( (predict(l3, newdata = test3) - test3$BSP91JW)^2 )

# Ergebnisse zusammenfassen
msecvb <- c(mseb1, mseb2, mseb3)
msecvl <- c(msel1, msel2, msel3)

# Mittelwert des Prognose MSE
mean(msecvb)
mean(msecvl)
```

Bei den vorliegenden Daten ist also ein *lineares* Modell dem Baummodell im Bezug auf den *MSE* überlegen.

**Hinweis:** In der Praxis führt man die Aufteilung nicht manuell sondern innerhalb von Schleifen durch.

### Klassifikationbäume
Untersuchen wir, ob makroökonomische Kennzahlen geeignet sind, die Konjunkturphasen zu unterscheiden. 
Zunächst stellen wir fest, dass die eigentlich kategorielle Variable `PHASEN` hier numerisch kodiert wurde, was aber schnell verwirren würde.
```{r}
typeof(B3$PHASEN)
```
Typänderung zu `factor` geht einfach:
```{r}
B3$PHASEN <- as.factor(B3$PHASEN)
```
Wenn wir die einzelnen `levels` des Faktors als numerische Werte verwenden wollen würde man den Befehl `as.numeric()` verwenden. Aber sicherheitshalber vorher über `levels()` gucken, ob die Reihenfolge auch stimmt.

Um die Interpretation zu erleichtern können wir hier einfach die Faktorstufe umbenennen.
```{r}
levels(B3$PHASEN) <- c("Aufschwung", "Oberer Wendepunkt", 
                       "Abschwung", "Unterer Wendepunkt")
```

Um z. B. die Konjunkturphase als Funktion von Privater Verbrauch, Investitionen in Ausrüstungsgüter, Investitionen in Bauten und Geldmenge M1 als Regressionsbaum zu modellieren reicht jetzt der Befehl
```{r}
klassbaum <- rpart(PHASEN ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=B3)
```


Um das Ergebnis auszugeben genügt:
```{r}
klassbaum
```
*Lesebeispiel:* Wenn IAU91JW< -0.09 und GM1JW>=11.355 liegt, dann ist der Untere Wendepunkt die häufigste Merkmalsausprägung von PHASEN (relative Häufigkeit von PHASEN=4 hier: 0.7) 10 Beobachtungen erfüllen die Kriterien der unabhängigen Variablen.


```{r}
par(xpd = TRUE) # Grafikparameter der sicherstellt, dass alles ins Bild passt
plot(klassbaum, compress = TRUE) # Baum zeichnen
text(klassbaum) # Baum beschriften
```

Bzw. "schöner":
```{r}
rpart.plot(klassbaum)
```


#### Kreuzvalidierung

Wie gut ist das Modell? Auch hier können über `predict` die Punktprognosen bestimmt werden:
```{r}
head(predict(klassbaum, type="class"))
```
Diese werden mit den beobachteten Werten verglichen:
```{r}
head(B3$PHASEN)
```

Die **Fehlklassifikationsrate** ist dann
```{r}
baumer <- mean( (predict(klassbaum, type="class") != B3$PHASEN) )
baumer
```
also knapp 30%.

Vergleichen kann man den Klassifikationsbaum z. B. mit der *Linearen Diskriminanzanalyse*. Diese ist im Paket `MASS` implementiert.
```{r, message=FALSE}
library(MASS)
```

```{r}
klasslda <- lda(PHASEN ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=B3)
klasslda

ldaer <- mean( (predict(klasslda)$class != B3$PHASEN) )
ldaer
```
Im Bezug auf die *Klassifikation* scheint der Baum in der Anpassungsgüte besser als die Lineare Diskriminanzanalyse zu sein. Aber wie sieht es kreuzvalidiert, d. h. in der Prognose aus?


Zunächst wird wieder dafür ein Aufteilungsvektor gebildet:
```{r}
aufteilung <- rep(1:3, length.out=nrow(B3))
```
und dann wird aufgeteilt:
```{r}
test1 <- B3[aufteilung==1,]
train1 <- B3[aufteilung!=1,]

test2 <- B3[aufteilung==2,]
train2 <- B3[aufteilung!=2,]

test3 <- B3[aufteilung==3,]
train3 <- B3[aufteilung!=3,]
```

```{r}
# Runde 1
b1 <- rpart(PHASEN  ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train1)
l1 <- lda(PHASEN ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train1)
erb1 <- mean( (predict(b1, newdata = test1, type = "class") != test1$PHASEN) )
erl1 <- mean( (predict(l1, newdata = test1)$class  != test1$PHASEN) )

# Runde 2
b2 <- rpart(PHASEN  ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train2)
l2 <- lda(PHASEN ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train2)
erb2 <- mean( (predict(b2, newdata = test2, type = "class") != test2$PHASEN) )
erl2 <- mean( (predict(l2, newdata = test2)$class  != test2$PHASEN) )

# Runde 3
b3 <- rpart(PHASEN  ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train3)
l3 <- lda(PHASEN ~ CP91JW + IAU91JW + IB91JW + GM1JW, data=train3)
erb3 <- mean( (predict(b3, newdata = test3, type = "class") != test3$PHASEN) )
erl3 <- mean( (predict(l3, newdata = test3)$class  != test3$PHASEN) )

# Ergebnisse zusammenfassen
ercvb <- c(erb1, erb2, erb3)
ercvl <- c(erl1, erl2, erl3)

# Mittelwert des Prognose MSE
mean(ercvb)
mean(ercvl)
```
In der *Prognosegüte* ist hier -- anders als in der Anpassungsgüte -- die Lineare Diskriminanzanalyse besser.



### Parameter `rpart` 
Neben dem Splitkrierium können verschiedene Parameter des Algorithmus eingestellt werden (siehe `?rpart.control`), u. a.:

- minsplit: Minimale Anzahl Beobachtungen im Knoten damit Aufteilung versucht wird
- minbucket: Minimale Anzahl Beobachtungen im Blatt
- cp: Komplexitätsparameter (pruning)
- xval: Anzahl Kreuzvaliderungen (pruning)
- maxdepth: Maximale Tiefe eines Blattes

Diese können mit der Funktion `train` aus dem Paket [`caret`](https://topepo.github.io/caret/index.html) automatisch optimiert werden.

Alternativen/ Ergänzungen zu `rpart`: 

- [`tree`](https://cran.r-project.org/web/packages/tree/)
- [`partykit`](http://partykit.r-forge.r-project.org/partykit/)
- Erweiterung: Viele Bäume: [`randomForest`](https://cran.r-project.org/web/packages/randomForest/) 

