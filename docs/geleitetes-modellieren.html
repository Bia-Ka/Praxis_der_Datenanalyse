<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Praxis der Datenanalyse</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Eine Einführung in moderne Statistik für Praktiker">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Praxis der Datenanalyse" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.jpg" />
  <meta property="og:description" content="Eine Einführung in moderne Statistik für Praktiker" />
  <meta name="github-repo" content="sebastiansauer/Praxis_der_Datenanalyse" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Praxis der Datenanalyse" />
  
  <meta name="twitter:description" content="Eine Einführung in moderne Statistik für Praktiker" />
  <meta name="twitter:image" content="images/cover.jpg" />

<meta name="author" content="Sebastian Sauer">


<meta name="date" content="2017-02-21">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="statistisches-modellieren.html">
<link rel="next" href="ungeleitetes-modellieren.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Praxis der Datenanalyse</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Vorwort</a></li>
<li class="chapter" data-level="1" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html"><i class="fa fa-check"></i><b>1</b> Rahmen - Teil 1</a><ul>
<li class="chapter" data-level="1.1" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#software"><i class="fa fa-check"></i><b>1.1</b> Software</a><ul>
<li class="chapter" data-level="1.1.1" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#r-und-rstudio-installieren"><i class="fa fa-check"></i><b>1.1.1</b> R und RStudio installieren</a></li>
<li class="chapter" data-level="1.1.2" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#hilfe-r-tut-nicht-so-wie-ich-das-will"><i class="fa fa-check"></i><b>1.1.2</b> Hilfe! R tut nicht so wie ich das will</a></li>
<li class="chapter" data-level="1.1.3" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#die-denk--und-gefuhlswelt-von-r"><i class="fa fa-check"></i><b>1.1.3</b> Die Denk- und Gefühlswelt von R</a></li>
<li class="chapter" data-level="1.1.4" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#pakete-installieren"><i class="fa fa-check"></i><b>1.1.4</b> Pakete installieren</a></li>
<li class="chapter" data-level="1.1.5" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#r-pakete-fur-dieses-buch"><i class="fa fa-check"></i><b>1.1.5</b> R-Pakete für dieses Buch</a></li>
<li class="chapter" data-level="1.1.6" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#datensatze"><i class="fa fa-check"></i><b>1.1.6</b> Datensätze</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#bildnachweise"><i class="fa fa-check"></i><b>1.2</b> Bildnachweise</a></li>
<li class="chapter" data-level="1.3" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#errrstkontakt"><i class="fa fa-check"></i><b>1.3</b> ERRRstkontakt</a><ul>
<li class="chapter" data-level="1.3.1" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#r-als-taschenrechner"><i class="fa fa-check"></i><b>1.3.1</b> R als Taschenrechner</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#was-ist-statistik-wozu-ist-sie-gut"><i class="fa fa-check"></i><b>1.4</b> Was ist Statistik? Wozu ist sie gut?</a></li>
<li class="chapter" data-level="1.5" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#versionshinweise"><i class="fa fa-check"></i><b>1.5</b> Versionshinweise</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tidy-data-daten-sauber-einlesen.html"><a href="tidy-data-daten-sauber-einlesen.html"><i class="fa fa-check"></i><b>2</b> Tidy Data - Daten sauber einlesen</a><ul>
<li class="chapter" data-level="2.1" data-path="tidy-data-daten-sauber-einlesen.html"><a href="tidy-data-daten-sauber-einlesen.html#daten-in-r-importieren"><i class="fa fa-check"></i><b>2.1</b> Daten in R importieren</a></li>
<li class="chapter" data-level="2.2" data-path="tidy-data-daten-sauber-einlesen.html"><a href="tidy-data-daten-sauber-einlesen.html#normalform-einer-tabelle"><i class="fa fa-check"></i><b>2.2</b> Normalform einer Tabelle</a></li>
<li class="chapter" data-level="2.3" data-path="tidy-data-daten-sauber-einlesen.html"><a href="tidy-data-daten-sauber-einlesen.html#verweise"><i class="fa fa-check"></i><b>2.3</b> Verweise</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html"><i class="fa fa-check"></i><b>3</b> Daten aufbereiten</a><ul>
<li class="chapter" data-level="3.1" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#typische-probleme"><i class="fa fa-check"></i><b>3.1</b> Typische Probleme</a></li>
<li class="chapter" data-level="3.2" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#daten-aufbereiten-mit-dplyr"><i class="fa fa-check"></i><b>3.2</b> Daten aufbereiten mit <code>dplyr</code></a><ul>
<li class="chapter" data-level="3.2.1" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#zeilen-filtern-mit-filter"><i class="fa fa-check"></i><b>3.2.1</b> Zeilen filtern mit <code>filter</code></a></li>
<li class="chapter" data-level="3.2.2" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#spalten-wahlen-mit-select"><i class="fa fa-check"></i><b>3.2.2</b> Spalten wählen mit <code>select</code></a></li>
<li class="chapter" data-level="3.2.3" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#zeilen-sortieren-mit-arrange"><i class="fa fa-check"></i><b>3.2.3</b> Zeilen sortieren mit <code>arrange</code></a></li>
<li class="chapter" data-level="3.2.4" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#datensatz-gruppieren-mit-group_by"><i class="fa fa-check"></i><b>3.2.4</b> Datensatz gruppieren mit <code>group_by</code></a></li>
<li class="chapter" data-level="3.2.5" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#eine-spalte-zusammenfassen-mit-summarise"><i class="fa fa-check"></i><b>3.2.5</b> Eine Spalte zusammenfassen mit <code>summarise</code></a></li>
<li class="chapter" data-level="3.2.6" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#zeilen-zahlen-mit-n-und-count"><i class="fa fa-check"></i><b>3.2.6</b> Zeilen zählen mit <code>n</code> und <code>count</code></a></li>
<li class="chapter" data-level="3.2.7" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#die-pfeife"><i class="fa fa-check"></i><b>3.2.7</b> Die Pfeife</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#fallstudie-nycflights13"><i class="fa fa-check"></i><b>3.3</b> Fallstudie <code>nycflights13</code></a></li>
<li class="chapter" data-level="3.4" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#checkliste-zum-datenjudo"><i class="fa fa-check"></i><b>3.4</b> Checkliste zum Datenjudo</a><ul>
<li class="chapter" data-level="3.4.1" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#auf-fehlende-werte-prufen"><i class="fa fa-check"></i><b>3.4.1</b> Auf fehlende Werte prüfen*</a></li>
<li class="chapter" data-level="3.4.2" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#falle-mit-fehlenden-werte-loschen"><i class="fa fa-check"></i><b>3.4.2</b> Fälle mit fehlenden Werte löschen</a></li>
<li class="chapter" data-level="3.4.3" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#fehlende-werte-ggf.-ersetzen"><i class="fa fa-check"></i><b>3.4.3</b> Fehlende Werte ggf. ersetzen</a></li>
<li class="chapter" data-level="3.4.4" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#nach-fehlern-suchen"><i class="fa fa-check"></i><b>3.4.4</b> Nach Fehlern suchen</a></li>
<li class="chapter" data-level="3.4.5" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#ausreiser-identifizieren"><i class="fa fa-check"></i><b>3.4.5</b> Ausreiser identifizieren</a></li>
<li class="chapter" data-level="3.4.6" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#hochkorrelierte-variablen-finden"><i class="fa fa-check"></i><b>3.4.6</b> Hochkorrelierte Variablen finden</a></li>
<li class="chapter" data-level="3.4.7" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#z-standardisieren"><i class="fa fa-check"></i><b>3.4.7</b> z-Standardisieren</a></li>
<li class="chapter" data-level="3.4.8" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#quasi-konstante-finden"><i class="fa fa-check"></i><b>3.4.8</b> Quasi-Konstante finden</a></li>
<li class="chapter" data-level="3.4.9" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#auf-normalverteilung-prufen"><i class="fa fa-check"></i><b>3.4.9</b> Auf Normalverteilung prüfen</a></li>
<li class="chapter" data-level="3.4.10" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#mittelwerte-pro-zeile-berechnen"><i class="fa fa-check"></i><b>3.4.10</b> Mittelwerte pro Zeile berechnen</a></li>
<li class="chapter" data-level="3.4.11" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#u"><i class="fa fa-check"></i><b>3.4.11</b> U</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#verweise-1"><i class="fa fa-check"></i><b>3.5</b> Verweise</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html"><i class="fa fa-check"></i><b>4</b> Daten visualisieren</a><ul>
<li class="chapter" data-level="4.1" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#haufige-arten-von-diagrammen"><i class="fa fa-check"></i><b>4.1</b> Häufige Arten von Diagrammen</a><ul>
<li class="chapter" data-level="4.1.1" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#eine-kontinuierliche-variable"><i class="fa fa-check"></i><b>4.1.1</b> Eine kontinuierliche Variable</a></li>
<li class="chapter" data-level="4.1.2" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#zwei-kontinuierliche-variablen"><i class="fa fa-check"></i><b>4.1.2</b> Zwei kontinuierliche Variablen</a></li>
<li class="chapter" data-level="4.1.3" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#eine-diskrete-variable"><i class="fa fa-check"></i><b>4.1.3</b> Eine diskrete Variable</a></li>
<li class="chapter" data-level="4.1.4" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#zwei-diskrete-variablen"><i class="fa fa-check"></i><b>4.1.4</b> Zwei diskrete Variablen</a></li>
<li class="chapter" data-level="4.1.5" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#zusammenfassungen-zeigen"><i class="fa fa-check"></i><b>4.1.5</b> Zusammenfassungen zeigen</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#farblehre"><i class="fa fa-check"></i><b>4.2</b> Farblehre</a></li>
<li class="chapter" data-level="4.3" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#prinzipien"><i class="fa fa-check"></i><b>4.3</b> Prinzipien</a></li>
<li class="chapter" data-level="4.4" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#erweiterungen-fur-ggplot"><i class="fa fa-check"></i><b>4.4</b> Erweiterungen für ggplot</a><ul>
<li class="chapter" data-level="4.4.1" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#ggpairs"><i class="fa fa-check"></i><b>4.4.1</b> ggpairs</a></li>
<li class="chapter" data-level="4.4.2" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#weitere"><i class="fa fa-check"></i><b>4.4.2</b> Weitere</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#fallstudie"><i class="fa fa-check"></i><b>4.5</b> Fallstudie</a><ul>
<li class="chapter" data-level="4.5.1" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#daten-einlesen"><i class="fa fa-check"></i><b>4.5.1</b> Daten einlesen</a></li>
<li class="chapter" data-level="4.5.2" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#daten-umstellen"><i class="fa fa-check"></i><b>4.5.2</b> Daten umstellen</a></li>
<li class="chapter" data-level="4.5.3" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#diagramme-fur-anteile"><i class="fa fa-check"></i><b>4.5.3</b> Diagramme für Anteile</a></li>
<li class="chapter" data-level="4.5.4" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#um-90-drehen"><i class="fa fa-check"></i><b>4.5.4</b> Um 90° drehen</a></li>
<li class="chapter" data-level="4.5.5" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#text-labels-fur-die-items"><i class="fa fa-check"></i><b>4.5.5</b> Text-Labels für die Items</a></li>
<li class="chapter" data-level="4.5.6" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#diagramm-mit-haufigkeiten"><i class="fa fa-check"></i><b>4.5.6</b> Diagramm mit Häufigkeiten</a></li>
<li class="chapter" data-level="4.5.7" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#farbschema"><i class="fa fa-check"></i><b>4.5.7</b> Farbschema</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#verweise-2"><i class="fa fa-check"></i><b>4.6</b> Verweise</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html"><i class="fa fa-check"></i><b>5</b> Statistisches Modellieren</a><ul>
<li class="chapter" data-level="5.1" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#Modellieren"><i class="fa fa-check"></i><b>5.1</b> Was ist ein Modell? Was ist Modellieren?</a><ul>
<li class="chapter" data-level="5.1.1" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#ziele-des-modellierens"><i class="fa fa-check"></i><b>5.1.1</b> Ziele des Modellierens</a></li>
<li class="chapter" data-level="5.1.2" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#parametrische-modelle-vs.non-parametrische-modelle"><i class="fa fa-check"></i><b>5.1.2</b> Parametrische Modelle vs. non-parametrische Modelle</a></li>
<li class="chapter" data-level="5.1.3" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#wann-welches-modell"><i class="fa fa-check"></i><b>5.1.3</b> Wann welches Modell?</a></li>
<li class="chapter" data-level="5.1.4" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#einfache-vs.komplexe-modelle"><i class="fa fa-check"></i><b>5.1.4</b> Einfache vs. komplexe Modelle</a></li>
<li class="chapter" data-level="5.1.5" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#training--vs.test-stichprobe"><i class="fa fa-check"></i><b>5.1.5</b> Training- vs. Test-Stichprobe</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#der-p-wert"><i class="fa fa-check"></i><b>5.2</b> Der p-Wert</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html"><i class="fa fa-check"></i><b>6</b> Geleitetes Modellieren</a><ul>
<li class="chapter" data-level="6.1" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#einfache-lineare-regression"><i class="fa fa-check"></i><b>6.1</b> Einfache lineare Regression</a><ul>
<li class="chapter" data-level="6.1.1" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#uberprufung-der-annahmen"><i class="fa fa-check"></i><b>6.1.1</b> Überprüfung der Annahmen</a></li>
<li class="chapter" data-level="6.1.2" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#regression-mit-kategorialen-werten"><i class="fa fa-check"></i><b>6.1.2</b> Regression mit kategorialen Werten</a></li>
<li class="chapter" data-level="6.1.3" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#multiple-regression"><i class="fa fa-check"></i><b>6.1.3</b> Multiple Regression</a></li>
<li class="chapter" data-level="6.1.4" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#inferenz-in-der-linearen-regression"><i class="fa fa-check"></i><b>6.1.4</b> Inferenz in der linearen Regression</a></li>
<li class="chapter" data-level="6.1.5" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#erweiterungen"><i class="fa fa-check"></i><b>6.1.5</b> Erweiterungen</a></li>
<li class="chapter" data-level="6.1.6" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#ubung-teaching-rating"><i class="fa fa-check"></i><b>6.1.6</b> Übung: Teaching Rating</a></li>
<li class="chapter" data-level="6.1.7" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#literatur"><i class="fa fa-check"></i><b>6.1.7</b> Literatur</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#klassifizierende-regression"><i class="fa fa-check"></i><b>6.2</b> Klassifizierende Regression</a><ul>
<li class="chapter" data-level="6.2.1" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#vorbereitung"><i class="fa fa-check"></i><b>6.2.1</b> Vorbereitung</a></li>
<li class="chapter" data-level="6.2.2" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#problemstellung"><i class="fa fa-check"></i><b>6.2.2</b> Problemstellung</a></li>
<li class="chapter" data-level="6.2.3" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#die-idee-der-logistischen-regression"><i class="fa fa-check"></i><b>6.2.3</b> Die Idee der logistischen Regression</a></li>
<li class="chapter" data-level="6.2.4" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#welche-unterschiede-zur-linearen-regression-gibt-es-in-der-ausgabe"><i class="fa fa-check"></i><b>6.2.4</b> Welche Unterschiede zur linearen Regression gibt es in der Ausgabe?</a></li>
<li class="chapter" data-level="6.2.5" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#interpretation-der-koeffizienten"><i class="fa fa-check"></i><b>6.2.5</b> Interpretation der Koeffizienten</a></li>
<li class="chapter" data-level="6.2.6" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#kategoriale-variablen"><i class="fa fa-check"></i><b>6.2.6</b> Kategoriale Variablen</a></li>
<li class="chapter" data-level="6.2.7" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#multiple-logistische-regression"><i class="fa fa-check"></i><b>6.2.7</b> Multiple logistische Regression</a></li>
<li class="chapter" data-level="6.2.8" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#erweiterungen-1"><i class="fa fa-check"></i><b>6.2.8</b> Erweiterungen</a></li>
<li class="chapter" data-level="6.2.9" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#ubung-rot--oder-weiwein"><i class="fa fa-check"></i><b>6.2.9</b> Übung: Rot- oder Weißwein?</a></li>
<li class="chapter" data-level="6.2.10" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#literatur-1"><i class="fa fa-check"></i><b>6.2.10</b> Literatur</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#baumbasierte-verfahren"><i class="fa fa-check"></i><b>6.3</b> Baumbasierte Verfahren</a><ul>
<li class="chapter" data-level="6.3.1" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#konjunturanalyse"><i class="fa fa-check"></i><b>6.3.1</b> Konjunturanalyse</a></li>
<li class="chapter" data-level="6.3.2" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#regressionsbaume"><i class="fa fa-check"></i><b>6.3.2</b> Regressionsbäume</a></li>
<li class="chapter" data-level="6.3.3" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#klassifikationbaume"><i class="fa fa-check"></i><b>6.3.3</b> Klassifikationbäume</a></li>
<li class="chapter" data-level="6.3.4" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#parameter-rpart"><i class="fa fa-check"></i><b>6.3.4</b> Parameter <code>rpart</code></a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#ausblick"><i class="fa fa-check"></i><b>6.4</b> Ausblick</a></li>
<li class="chapter" data-level="6.5" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#fallstudie-uberleben-auf-der-titanic"><i class="fa fa-check"></i><b>6.5</b> Fallstudie: Überleben auf der Titanic</a><ul>
<li class="chapter" data-level="6.5.1" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#daten-und-pakete-laden"><i class="fa fa-check"></i><b>6.5.1</b> Daten und Pakete laden</a></li>
<li class="chapter" data-level="6.5.2" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#erster-blick"><i class="fa fa-check"></i><b>6.5.2</b> Erster Blick</a></li>
<li class="chapter" data-level="6.5.3" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#welche-variablen-sind-interessant"><i class="fa fa-check"></i><b>6.5.3</b> Welche Variablen sind interessant?</a></li>
<li class="chapter" data-level="6.5.4" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#univariate-haufigkeiten"><i class="fa fa-check"></i><b>6.5.4</b> Univariate Häufigkeiten</a></li>
<li class="chapter" data-level="6.5.5" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#bivariate-haufigkeiten"><i class="fa fa-check"></i><b>6.5.5</b> Bivariate Häufigkeiten</a></li>
<li class="chapter" data-level="6.5.6" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#signifikanztest"><i class="fa fa-check"></i><b>6.5.6</b> Signifikanztest</a></li>
<li class="chapter" data-level="6.5.7" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#effektstarke"><i class="fa fa-check"></i><b>6.5.7</b> Effektstärke</a></li>
<li class="chapter" data-level="6.5.8" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#logististische-regression"><i class="fa fa-check"></i><b>6.5.8</b> Logististische Regression</a></li>
<li class="chapter" data-level="6.5.9" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#effektstarken-visualieren"><i class="fa fa-check"></i><b>6.5.9</b> Effektstärken visualieren</a></li>
<li class="chapter" data-level="6.5.10" data-path="geleitetes-modellieren.html"><a href="geleitetes-modellieren.html#fazit"><i class="fa fa-check"></i><b>6.5.10</b> Fazit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html"><i class="fa fa-check"></i><b>7</b> Ungeleitetes Modellieren</a><ul>
<li class="chapter" data-level="7.1" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#clusteranalyse"><i class="fa fa-check"></i><b>7.1</b> Clusteranalyse</a><ul>
<li class="chapter" data-level="7.1.1" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#hierarchische-clusteranalyse"><i class="fa fa-check"></i><b>7.1.1</b> Hierarchische Clusteranalyse</a></li>
<li class="chapter" data-level="7.1.2" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#k-means-clusteranalyse"><i class="fa fa-check"></i><b>7.1.2</b> k-Means Clusteranalyse</a></li>
<li class="chapter" data-level="7.1.3" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#ubung-b3-datensatz"><i class="fa fa-check"></i><b>7.1.3</b> Übung: B3 Datensatz</a></li>
<li class="chapter" data-level="7.1.4" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#literatur-2"><i class="fa fa-check"></i><b>7.1.4</b> Literatur</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#dimensionsreduktion"><i class="fa fa-check"></i><b>7.2</b> Dimensionsreduktion</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#grunde-fur-die-notwendigkeit-der-datenreduktion"><i class="fa fa-check"></i><b>7.2.1</b> Gründe für die Notwendigkeit der Datenreduktion</a></li>
<li class="chapter" data-level="7.2.2" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#benotigte-pakete"><i class="fa fa-check"></i><b>7.2.2</b> Benötigte Pakete</a></li>
<li class="chapter" data-level="7.2.3" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#daten-einlesen-1"><i class="fa fa-check"></i><b>7.2.3</b> Daten einlesen</a></li>
<li class="chapter" data-level="7.2.4" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#neuskalierung-der-daten"><i class="fa fa-check"></i><b>7.2.4</b> Neuskalierung der Daten</a></li>
<li class="chapter" data-level="7.2.5" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#zusammenhange-in-den-daten"><i class="fa fa-check"></i><b>7.2.5</b> Zusammenhänge in den Daten</a></li>
<li class="chapter" data-level="7.2.6" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#aggregation-der-durchschnittlichen-bewertungen-nach-marke"><i class="fa fa-check"></i><b>7.2.6</b> Aggregation der durchschnittlichen Bewertungen nach Marke</a></li>
<li class="chapter" data-level="7.2.7" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#visualisierung-der-aggregierten-markenbewertungen"><i class="fa fa-check"></i><b>7.2.7</b> Visualisierung der aggregierten Markenbewertungen</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#hauptkomponentenanalyse-pca"><i class="fa fa-check"></i><b>7.3</b> Hauptkomponentenanalyse (PCA)</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#bestimmung-der-anzahl-der-hauptkomponenten"><i class="fa fa-check"></i><b>7.3.1</b> Bestimmung der Anzahl der Hauptkomponenten</a></li>
<li class="chapter" data-level="7.3.2" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#scree-plot"><i class="fa fa-check"></i><b>7.3.2</b> Scree-Plot</a></li>
<li class="chapter" data-level="7.3.3" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#elbow-kriterium"><i class="fa fa-check"></i><b>7.3.3</b> Elbow-Kriterium</a></li>
<li class="chapter" data-level="7.3.4" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#biplot"><i class="fa fa-check"></i><b>7.3.4</b> Biplot</a></li>
<li class="chapter" data-level="7.3.5" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#wahrnehmungsraum"><i class="fa fa-check"></i><b>7.3.5</b> Wahrnehmungsraum</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#exploratorische-faktorenanalyse-efa"><i class="fa fa-check"></i><b>7.4</b> Exploratorische Faktorenanalyse (EFA)</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#finden-einer-efa-losung"><i class="fa fa-check"></i><b>7.4.1</b> Finden einer EFA Lösung</a></li>
<li class="chapter" data-level="7.4.2" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#heatmap-mit-ladungen"><i class="fa fa-check"></i><b>7.4.2</b> Heatmap mit Ladungen</a></li>
<li class="chapter" data-level="7.4.3" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#berechnung-der-faktor-scores"><i class="fa fa-check"></i><b>7.4.3</b> Berechnung der Faktor-Scores</a></li>
<li class="chapter" data-level="7.4.4" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#interne-konsistenz-der-skalen"><i class="fa fa-check"></i><b>7.4.4</b> Interne Konsistenz der Skalen</a></li>
<li class="chapter" data-level="7.4.5" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#ubung"><i class="fa fa-check"></i><b>7.4.5</b> Übung</a></li>
<li class="chapter" data-level="7.4.6" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#literatur-3"><i class="fa fa-check"></i><b>7.4.6</b> Literatur</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#assoziationsanalyse"><i class="fa fa-check"></i><b>7.5</b> Assoziationsanalyse</a><ul>
<li class="chapter" data-level="7.5.1" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#einfuhrung"><i class="fa fa-check"></i><b>7.5.1</b> Einführung</a></li>
<li class="chapter" data-level="7.5.2" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#kennzahlen-einer-assoziationsanalyse"><i class="fa fa-check"></i><b>7.5.2</b> Kennzahlen einer Assoziationsanalyse</a></li>
<li class="chapter" data-level="7.5.3" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#beispiel"><i class="fa fa-check"></i><b>7.5.3</b> Beispiel</a></li>
<li class="chapter" data-level="7.5.4" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#assoziationsanalyse-mit-r"><i class="fa fa-check"></i><b>7.5.4</b> Assoziationsanalyse mit R</a></li>
<li class="chapter" data-level="7.5.5" data-path="ungeleitetes-modellieren.html"><a href="ungeleitetes-modellieren.html#visualisierung"><i class="fa fa-check"></i><b>7.5.5</b> Visualisierung</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="textmining.html"><a href="textmining.html"><i class="fa fa-check"></i><b>8</b> Textmining</a><ul>
<li class="chapter" data-level="8.1" data-path="textmining.html"><a href="textmining.html#einfuhrung-1"><i class="fa fa-check"></i><b>8.1</b> Einführung</a><ul>
<li class="chapter" data-level="8.1.1" data-path="textmining.html"><a href="textmining.html#grundbegriffe"><i class="fa fa-check"></i><b>8.1.1</b> Grundbegriffe</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="textmining.html"><a href="textmining.html#grundlegende-analyse"><i class="fa fa-check"></i><b>8.2</b> Grundlegende Analyse</a><ul>
<li class="chapter" data-level="8.2.1" data-path="textmining.html"><a href="textmining.html#tidy-text-dataframes"><i class="fa fa-check"></i><b>8.2.1</b> Tidy Text Dataframes</a></li>
<li class="chapter" data-level="8.2.2" data-path="textmining.html"><a href="textmining.html#text-daten-einlesen"><i class="fa fa-check"></i><b>8.2.2</b> Text-Daten einlesen</a></li>
<li class="chapter" data-level="8.2.3" data-path="textmining.html"><a href="textmining.html#worthaufigkeiten-auszahlen"><i class="fa fa-check"></i><b>8.2.3</b> Worthäufigkeiten auszählen</a></li>
<li class="chapter" data-level="8.2.4" data-path="textmining.html"><a href="textmining.html#visualisierung-1"><i class="fa fa-check"></i><b>8.2.4</b> Visualisierung</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="textmining.html"><a href="textmining.html#sentiment-analyse"><i class="fa fa-check"></i><b>8.3</b> Sentiment-Analyse</a><ul>
<li class="chapter" data-level="8.3.1" data-path="textmining.html"><a href="textmining.html#ungewichtete-sentiment-analyse"><i class="fa fa-check"></i><b>8.3.1</b> Ungewichtete Sentiment-Analyse</a></li>
<li class="chapter" data-level="8.3.2" data-path="textmining.html"><a href="textmining.html#anzahl-der-unterschiedlichen-negativen-bzw.-positiven-worter"><i class="fa fa-check"></i><b>8.3.2</b> Anzahl der unterschiedlichen negativen bzw. positiven Wörter</a></li>
<li class="chapter" data-level="8.3.3" data-path="textmining.html"><a href="textmining.html#gewichtete-sentiment-analyse"><i class="fa fa-check"></i><b>8.3.3</b> Gewichtete Sentiment-Analyse</a></li>
<li class="chapter" data-level="8.3.4" data-path="textmining.html"><a href="textmining.html#tokens-mit-den-extremsten-sentimentwerten"><i class="fa fa-check"></i><b>8.3.4</b> Tokens mit den extremsten Sentimentwerten</a></li>
<li class="chapter" data-level="8.3.5" data-path="textmining.html"><a href="textmining.html#relativer-sentiments-wert"><i class="fa fa-check"></i><b>8.3.5</b> Relativer Sentiments-Wert</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="textmining.html"><a href="textmining.html#verknupfung-mit-anderen-variablen"><i class="fa fa-check"></i><b>8.4</b> Verknüpfung mit anderen Variablen</a></li>
<li class="chapter" data-level="8.5" data-path="textmining.html"><a href="textmining.html#vertiefung"><i class="fa fa-check"></i><b>8.5</b> Vertiefung</a><ul>
<li class="chapter" data-level="8.5.1" data-path="textmining.html"><a href="textmining.html#erstellung-des-sentiment-lexikons"><i class="fa fa-check"></i><b>8.5.1</b> Erstellung des Sentiment-Lexikons</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="textmining.html"><a href="textmining.html#verweise-3"><i class="fa fa-check"></i><b>8.6</b> Verweise</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ergebnisse-kommunizieren.html"><a href="ergebnisse-kommunizieren.html"><i class="fa fa-check"></i><b>9</b> Ergebnisse kommunizieren</a><ul>
<li class="chapter" data-level="9.1" data-path="ergebnisse-kommunizieren.html"><a href="ergebnisse-kommunizieren.html#markdown-und-rmarkdown"><i class="fa fa-check"></i><b>9.1</b> Markdown und RMarkdown</a></li>
<li class="chapter" data-level="9.2" data-path="ergebnisse-kommunizieren.html"><a href="ergebnisse-kommunizieren.html#reproduzierbarkeit"><i class="fa fa-check"></i><b>9.2</b> Reproduzierbarkeit</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="rahmen-teil-2.html"><a href="rahmen-teil-2.html"><i class="fa fa-check"></i><b>10</b> Rahmen - Teil 2</a><ul>
<li class="chapter" data-level="10.1" data-path="rahmen-teil-2.html"><a href="rahmen-teil-2.html#trends"><i class="fa fa-check"></i><b>10.1</b> Trends</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Praxis der Datenanalyse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="geleitetes-modellieren" class="section level1">
<h1><span class="header-section-number">Kapitel 6</span> Geleitetes Modellieren</h1>
<div id="einfache-lineare-regression" class="section level2">
<h2><span class="header-section-number">6.1</span> Einfache lineare Regression</h2>
<p>Wir werden weiter den Datensatz <em>tips</em> analysieren <span class="citation">(Bryant and Smith <a href="#ref-bryant1995practical">1995</a>)</span>.</p>
<p>Sofern noch nicht geschehen, können Sie in <a href="https://goo.gl/whKjnl">hier</a> als <code>csv</code>-Datei herunterladen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tips &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;https://sebastiansauer.github.io/data/tips.csv&quot;</span>)</code></pre></div>
<p>Zur Unterstützung der Analyse wird (wieder) das Paket <code>mosaic</code> verwendet; außerdem laden wir <code>ggplot2</code> für <code>qplot</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mosaic)
<span class="kw">library</span>(ggplot2)</code></pre></div>
<p>Wie hängen Trinkgeldhöhe <code>tip</code> und Rechnungshöhe <code>total_bill</code> zusammen? Kann die Höhe des Trinkgeldes als <em>lineare</em> Funktion der Rechnungshöhe linear modelliert werden? <span class="math display">\[tip_i=\beta_0+\beta_1\cdot total\_bill_i+\epsilon_i\]</span></p>
<p>Zunächst eine visuelle Analyse mi Hilfe eines Scatterplots.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(<span class="dt">y =</span> tip, <span class="dt">x =</span> total_bill, <span class="dt">data =</span> tips)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-4-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Es scheint einen positiven Zusammenhang zu geben. Modellieren wir die <strong>abhängige</strong> Variable <code>tip</code> (inhaltliche Entscheidung!) als lineare Funktion der <strong>unabhängigen</strong> Variable <code>total_bill</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">LinMod<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(tip ~<span class="st"> </span>total_bill, <span class="dt">data=</span>tips)
<span class="kw">summary</span>(LinMod<span class="fl">.1</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ total_bill, data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -3.198 -0.565 -0.097  0.486  3.743 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)  0.92027    0.15973    5.76  2.5e-08 ***</span>
<span class="co">#&gt; total_bill   0.10502    0.00736   14.26  &lt; 2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 1.02 on 242 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.457,  Adjusted R-squared:  0.454 </span>
<span class="co">#&gt; F-statistic:  203 on 1 and 242 DF,  p-value: &lt;2e-16</span></code></pre></div>
<p>Der Achsenabschnitt (<code>intercept</code>) wird mit 0.92 geschätzt, die Steigung in Richtung <code>total_bill</code> mit 0.11: steigt <code>total_bill</code> um einen Dollar, steigt im <em>Durchschnitt</em> <code>tip</code> um 0.11. Die (Punkt-)Prognose für <code>tip</code> lautet also</p>
<p><code>tip</code> = 0.92 + 0.11 * <code>total_bill</code></p>
<p>Die Koeffzienten werden dabei so geschätzt, dass <span class="math inline">\(\sum \epsilon_i^2\)</span> minimiert wird. Dies wird auch als <em>Kleinste Quadrate</em> (<em>Ordinary Least Squares</em>, <em>OLS</em>) Kriterium bezeichnet. Eine robuste Regression ist z. B. mit der Funktion <code>rlm()</code> aus dem Paket <code>MASS</code> möglich.</p>
<p>In mosaic kann ein solches Modell einfach als neue Funktion definiert werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">LinMod.1Fun &lt;-<span class="st"> </span><span class="kw">makeFun</span>(LinMod<span class="fl">.1</span>)</code></pre></div>
<p>Die (Punkt-)Prognose für die Trinkgeldhöhe, bspw. für eine Rechnung von 30$ kann dann berechnet werden</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">LinMod.1Fun</span>(<span class="dt">total_bill=</span><span class="dv">30</span>)
<span class="co">#&gt;    1 </span>
<span class="co">#&gt; 4.07</span></code></pre></div>
<p>also 4.07$.</p>
<p>In mosaic kann die Modellgerade über</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotModel</span>(LinMod<span class="fl">.1</span>)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-8-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>betrachtet werden. Das Bestimmtheitsmaß R² ist mit 0.46 “ok”: 46-% der Variation des Trinkgeldes wird im Modell erklärt.</p>
<div id="uberprufung-der-annahmen" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Überprüfung der Annahmen</h3>
<p>Aber wie sieht es mit den Annahmen aus?</p>
<ul>
<li>Die Linearität des Zusammenhangs haben wir zu Beginn mit Hilfe des Scatterplots “überprüft”.</li>
<li>Zur Überprüfung der Normalverteilung der Residuen zeichnen wir ein Histogramm. Die <em>Residuen</em> können über den Befehl <code>resid()</code> aus einem Linearen Modell extrahiert werden. Hier scheint es zu passen:</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">resid_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Residuen =</span> <span class="kw">resid</span>(LinMod<span class="fl">.1</span>))
<span class="kw">qplot</span>(<span class="dt">x =</span> Residuen, <span class="dt">data =</span> resid_df)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-9-1.png" width="70%" style="display: block; margin: auto;" /></p>
<ul>
<li><em>Konstante Varianz</em>: Dies kann z. B. mit einem Scatterplot der Residuen auf der y-Achse und den angepassten Werten auf der x-Achse überprüft werden. Die angepassten (geschätzten) Werte werden über den Befehl <code>fitted()</code><a href="#fn31" class="footnoteRef" id="fnref31"><sup>31</sup></a> extrahiert. Diese Annahme scheint verletzt zu sein (siehe unten): je größer die Prognose des Trinkgeldes, desto größer wirkt die Streuung der Residuen. Dieses Phänomen ließ sich schon aus dem ursprünglichen Scatterplot <code>qplot(x = tip, y = total_bill, data=tips)</code> erahnen. Das ist auch inhaltlich plausibel: je höher die Rechnung, desto höher die Varianz beim Trinkgeld. Die Verletzung dieser Annahme beeinflusst <em>nicht</em> die Schätzung der Steigung, sondern die Schätzung des Standardfehlers, also des p-Wertes des Hypothesentests, d. h., <span class="math inline">\(H_0:\beta_1=0\)</span>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">resid_df$fitted &lt;-<span class="st"> </span><span class="kw">fitted</span>(LinMod<span class="fl">.1</span>)
<span class="kw">qplot</span>(<span class="dt">x =</span> Residuen, <span class="dt">y =</span> fitted, <span class="dt">data =</span> resid_df)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-10-1.png" width="70%" style="display: block; margin: auto;" /></p>
<ul>
<li><em>Extreme Ausreißer</em>: Wie am Plot der Linearen Regression <code>plotModel(LinMod.1)</code> erkennbar, gibt es vereinzelt Ausreißer nach oben, allerdings ohne einen extremen Hebel.</li>
</ul>
<p>Hängt die Rechnungshöhe von der Anzahl der Personen ab? Bestimmt, aber wie?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">xyplot</span>(total_bill ~<span class="st"> </span>size, <span class="dt">data=</span>tips)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-11-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Da bei diskreten metrischen Variablen (hier <code>size</code>) Punkte übereinander liegen können, sollte man “jittern” (“schütteln”), d. h., eine (kleine) Zufallszahl addieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(<span class="dt">x =</span> total_bill, <span class="dt">y =</span> size, <span class="dt">data =</span> tips, <span class="dt">geom =</span> <span class="st">&quot;jitter&quot;</span>)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-12-1.png" width="70%" style="display: block; margin: auto;" /></p>

<div class="rmdexercises">
<ol style="list-style-type: decimal">
<li><p>Um wie viel Dollar steigt im Durchschnitt das Trinkgeld, wenn eine Person mehr am Tisch sitzt?</p></li>
<li>Für wie aussagekräftig halten Sie Ihr Ergebnis aus 1.?
</div>
<p></p></li>
</ol>
</div>
<div id="regression-mit-kategorialen-werten" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Regression mit kategorialen Werten</h3>
<p>Der Wochentag <code>day</code> ist eine kategoriale Variable. Wie sieht eine Regression des Trinkgeldes darauf aus?</p>
<p>Zunächst grafisch:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(<span class="dt">x =</span> tip,<span class="dt">y =</span> day, <span class="dt">data=</span>tips)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-13-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Und als Lineares Modell:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">LinMod<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(tip ~<span class="st"> </span>day, <span class="dt">data=</span>tips)
<span class="kw">summary</span>(LinMod<span class="fl">.2</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ day, data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -2.245 -0.993 -0.235  0.538  7.007 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   2.7347     0.3161    8.65  7.5e-16 ***</span>
<span class="co">#&gt; daySat        0.2584     0.3489    0.74     0.46    </span>
<span class="co">#&gt; daySun        0.5204     0.3534    1.47     0.14    </span>
<span class="co">#&gt; dayThur       0.0367     0.3613    0.10     0.92    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 1.38 on 240 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.0205, Adjusted R-squared:  0.00823 </span>
<span class="co">#&gt; F-statistic: 1.67 on 3 and 240 DF,  p-value: 0.174</span></code></pre></div>
<p>Die im Modell angegebenen Schätzwerte sind die Änderung der Trinkgeldprognose, wenn z. B. der Tag ein Samstag (<code>daySat</code>) im Vergleich zu einer Referenzkategorie. Dies ist in R das erste Element des Vektors der Faktorlevel. Welcher dies ist ist über den Befehl <code>levels()</code> zu erfahren</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">levels</span>(tips$day)
<span class="co">#&gt; [1] &quot;Fri&quot;  &quot;Sat&quot;  &quot;Sun&quot;  &quot;Thur&quot;</span></code></pre></div>
<p>hier also Fri (aufgrund der standardmäßig aufsteigenden alphanumerischen Sortierung). Dies kann über <code>relevel()</code> geändert werden. Soll z. B. die Referenz der Donnerstag, <code>Thur</code> sein:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tips$day &lt;-<span class="st"> </span><span class="kw">relevel</span>(tips$day, <span class="dt">ref =</span> <span class="st">&quot;Thur&quot;</span>)
<span class="kw">levels</span>(tips$day)
<span class="co">#&gt; [1] &quot;Thur&quot; &quot;Fri&quot;  &quot;Sat&quot;  &quot;Sun&quot;</span></code></pre></div>
<p>Das Modell ändert sich entsprechend:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">LinMod<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(tip ~<span class="st"> </span>day, <span class="dt">data=</span>tips)
<span class="kw">summary</span>(LinMod<span class="fl">.3</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ day, data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -2.245 -0.993 -0.235  0.538  7.007 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   2.7715     0.1750   15.84   &lt;2e-16 ***</span>
<span class="co">#&gt; dayFri       -0.0367     0.3613   -0.10    0.919    </span>
<span class="co">#&gt; daySat        0.2217     0.2290    0.97    0.334    </span>
<span class="co">#&gt; daySun        0.4837     0.2358    2.05    0.041 *  </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 1.38 on 240 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.0205, Adjusted R-squared:  0.00823 </span>
<span class="co">#&gt; F-statistic: 1.67 on 3 and 240 DF,  p-value: 0.174</span></code></pre></div>
<p>sowie als Plot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotModel</span>(LinMod<span class="fl">.3</span>)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-18-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Eine Alternative zu <code>relevel()</code> zur Bestimmung der Referenzkategorie ist es, innerhalb von <code>factor()</code> die Option <code>levels=</code> direkt in der gewünschten Sortierung zu setzen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">day &lt;-<span class="st"> </span><span class="kw">factor</span>(tips$day, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;Thur&quot;</span>, <span class="st">&quot;Fri&quot;</span>, <span class="st">&quot;Sat&quot;</span>,  <span class="st">&quot;Sun&quot;</span>))</code></pre></div>
<p>Die (Punkt-)Prognose für die Trinkgeldhöhe, bspw. an einen Freitag kann dann berechnet werden</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">LinMod.3Fun &lt;-<span class="st"> </span><span class="kw">makeFun</span>(LinMod<span class="fl">.3</span>)
<span class="kw">LinMod.3Fun</span>(<span class="dt">day=</span><span class="st">&quot;Fri&quot;</span>)
<span class="co">#&gt;    1 </span>
<span class="co">#&gt; 2.73</span></code></pre></div>

<div class="rmdexercises">
<ol start="3" style="list-style-type: decimal">
<li>Wie verändert sich die Rechnungshöhe im Durchschnitt, wenn die Essenszeit Dinner statt Lunch ist?</li>
<li>Wie viel % der Variation der Rechnungshöhe können Sie durch die Essenszeit modellieren?</li>
</ol>
</div>
<p></p>
</div>
<div id="multiple-regression" class="section level3">
<h3><span class="header-section-number">6.1.3</span> Multiple Regression</h3>
<p>Aber wie wirken sich die Einflussgrößen <em>zusammen</em> auf das Trinkgeld aus?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">LinMod<span class="fl">.4</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(tip ~<span class="st"> </span>total_bill +<span class="st"> </span>size +<span class="st"> </span>sex  +<span class="st"> </span>smoker +<span class="st"> </span>day +<span class="st"> </span>time, <span class="dt">data=</span>tips)
<span class="kw">summary</span>(LinMod<span class="fl">.4</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ total_bill + size + sex + smoker + day + time, </span>
<span class="co">#&gt;     data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -2.848 -0.573 -0.103  0.476  4.108 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   0.6416     0.4976    1.29    0.199    </span>
<span class="co">#&gt; total_bill    0.0945     0.0096    9.84   &lt;2e-16 ***</span>
<span class="co">#&gt; size          0.1760     0.0895    1.97    0.051 .  </span>
<span class="co">#&gt; sexMale      -0.0324     0.1416   -0.23    0.819    </span>
<span class="co">#&gt; smokerYes    -0.0864     0.1466   -0.59    0.556    </span>
<span class="co">#&gt; dayFri        0.1623     0.3934    0.41    0.680    </span>
<span class="co">#&gt; daySat        0.0408     0.4706    0.09    0.931    </span>
<span class="co">#&gt; daySun        0.1368     0.4717    0.29    0.772    </span>
<span class="co">#&gt; timeLunch     0.0681     0.4446    0.15    0.878    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 1.02 on 235 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.47,   Adjusted R-squared:  0.452 </span>
<span class="co">#&gt; F-statistic: 26.1 on 8 and 235 DF,  p-value: &lt;2e-16</span></code></pre></div>
<p>Interessant sind die negativen Vorzeichen vor den Schätzwerten für <code>sexMale</code> und <code>smokerYes</code> – anscheinend geben Männer und Raucher weniger Trinkgeld, wenn alle anderen Faktoren konstant bleiben. Bei einer rein univariaten Betrachtung wäre etwas anderes herausgekommen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(tip ~<span class="st"> </span>sex, <span class="dt">data=</span>tips))
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ sex, data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -2.090 -1.090 -0.090  0.667  6.910 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)    2.833      0.148   19.14   &lt;2e-16 ***</span>
<span class="co">#&gt; sexMale        0.256      0.185    1.39     0.17    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 1.38 on 242 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.0079, Adjusted R-squared:  0.0038 </span>
<span class="co">#&gt; F-statistic: 1.93 on 1 and 242 DF,  p-value: 0.166</span>
<span class="kw">summary</span>(<span class="kw">lm</span>(tip ~<span class="st"> </span>smoker, <span class="dt">data=</span>tips))
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ smoker, data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -2.009 -0.994 -0.100  0.558  6.991 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   2.9919     0.1128   26.52   &lt;2e-16 ***</span>
<span class="co">#&gt; smokerYes     0.0169     0.1828    0.09     0.93    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 1.39 on 242 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  3.51e-05,   Adjusted R-squared:  -0.0041 </span>
<span class="co">#&gt; F-statistic: 0.00851 on 1 and 242 DF,  p-value: 0.927</span></code></pre></div>
<p>Diese <em>Umkehrung</em> des modellierten Effektes liegt daran, dass es auch einen positiven Zusammenhang zur Rechnungshöhe gibt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(total_bill ~<span class="st"> </span>sex, <span class="dt">data=</span>tips))
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = total_bill ~ sex, data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -14.99  -6.02  -1.94   3.99  30.07 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   18.057      0.946   19.08   &lt;2e-16 ***</span>
<span class="co">#&gt; sexMale        2.687      1.180    2.28    0.024 *  </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 8.83 on 242 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.021,  Adjusted R-squared:  0.0169 </span>
<span class="co">#&gt; F-statistic: 5.19 on 1 and 242 DF,  p-value: 0.0236</span>
<span class="kw">summary</span>(<span class="kw">lm</span>(total_bill ~<span class="st"> </span>smoker, <span class="dt">data=</span>tips))
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = total_bill ~ smoker, data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -17.69  -6.46  -1.89   4.58  30.05 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   19.188      0.723   26.53   &lt;2e-16 ***</span>
<span class="co">#&gt; smokerYes      1.568      1.172    1.34     0.18    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 8.89 on 242 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.00735,    Adjusted R-squared:  0.00325 </span>
<span class="co">#&gt; F-statistic: 1.79 on 1 and 242 DF,  p-value: 0.182</span></code></pre></div>
<p>Im vollem Modell <code>LinMod.4</code> sind alle unabhängigen Variablen berücksichtigt, die Koeffizienten beziehen sich dann immer auf: gegeben, die anderen Variablen bleiben konstant, d. h. ceteris paribus.</p>
<p>Vergleichen wir mal zwei Modelle:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">LinMod.5a &lt;-<span class="st"> </span><span class="kw">lm</span>(tip ~<span class="st">  </span>sex, <span class="dt">data=</span>tips)
<span class="kw">coef</span>(LinMod.5a) <span class="co"># Koeffizienten extrahieren</span>
<span class="co">#&gt; (Intercept)     sexMale </span>
<span class="co">#&gt;       2.833       0.256</span>
LinMod.5b &lt;-<span class="st"> </span><span class="kw">lm</span>(tip ~<span class="st">  </span>sex +<span class="st"> </span>total_bill, <span class="dt">data=</span>tips)
<span class="kw">coef</span>(LinMod.5b) <span class="co"># Koeffizienten extrahieren</span>
<span class="co">#&gt; (Intercept)     sexMale  total_bill </span>
<span class="co">#&gt;      0.9333     -0.0266      0.1052</span></code></pre></div>
<p>Ohne die Berücksichtigung der <strong>Kovariable/Störvariable</strong> Rechnungshöhe geben <code>Male</code> ein um im Durchschnitt 0.26$ <em>höheres</em> Trinkgeld, bei Kontrolle, d. h. gleicher Rechnungshöhe ein um 0.03$ <em>niedrigeres</em> Trinkgeld als die Referenzklasse <code>Female</code> (<code>levels(tips$sex)[1]</code>).</p>
</div>
<div id="inferenz-in-der-linearen-regression" class="section level3">
<h3><span class="header-section-number">6.1.4</span> Inferenz in der linearen Regression</h3>
<p>Kehren wir noch einmal zur multivariaten Regression (<code>LinMod.4</code>) zurück.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(LinMod<span class="fl">.4</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ total_bill + size + sex + smoker + day + time, </span>
<span class="co">#&gt;     data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -2.848 -0.573 -0.103  0.476  4.108 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   0.6416     0.4976    1.29    0.199    </span>
<span class="co">#&gt; total_bill    0.0945     0.0096    9.84   &lt;2e-16 ***</span>
<span class="co">#&gt; size          0.1760     0.0895    1.97    0.051 .  </span>
<span class="co">#&gt; sexMale      -0.0324     0.1416   -0.23    0.819    </span>
<span class="co">#&gt; smokerYes    -0.0864     0.1466   -0.59    0.556    </span>
<span class="co">#&gt; dayFri        0.1623     0.3934    0.41    0.680    </span>
<span class="co">#&gt; daySat        0.0408     0.4706    0.09    0.931    </span>
<span class="co">#&gt; daySun        0.1368     0.4717    0.29    0.772    </span>
<span class="co">#&gt; timeLunch     0.0681     0.4446    0.15    0.878    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 1.02 on 235 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.47,   Adjusted R-squared:  0.452 </span>
<span class="co">#&gt; F-statistic: 26.1 on 8 and 235 DF,  p-value: &lt;2e-16</span></code></pre></div>
<p>In der 4. Spalte der, mit Zeilennamen versehenen Tabelle <code>Coefficients</code> stehen die p-Werte der Nullhypothese, die unabhängige Variable hat, gegeben alle anderen Variablen im Modell, keinen linearen Einfluss auf die abhängige Variable: <span class="math inline">\(H_0: \beta_i=0\)</span>. Zur Bestimmung des p-Wertes wird der Schätzer (<code>Estimate</code>) durch den Standardfehler (<code>Std. Error</code>) dividiert. Der resultierende t-Wert (<code>t value</code>) wird dann, zusammen mit der Anzahl an Freiheitsgraden zur Berechnung des p-Wertes (<code>Pr(&gt;|t|)</code>) verwendet. Ein einfacher t-Test!</p>
<p>Zur schnelleren Übersicht finden sich dahinter “Sternchen” und “Punkte”, die die entsprechenden Signifikanzniveaus symbolisieren: <code>***</code> bedeutet eine Irrtumswahrscheinlichkeit, Wahrscheinlichkeit für Fehler 1. Art, von unter 0.001, d. h. unter 0,1%. <code>**</code> entsprechend 1%, <code>*</code> 5% und <code>.</code> 10%.</p>
<p>Zum Signifikanzniveau von 10% sind hier also zwei Faktoren und der Achsenabschnitt (<code>(Intercept)</code>) signifikant – nicht notwendigerweise relevant: Rechnungshöhe <code>total_bill</code> sowie Anzahl Personen <code>size</code>. Beides wirkt sich linear positiv auf die Trinkgeldhöhe aus: Mit jedem Dollar Rechnungshöhe steigt im Mittelwert die Trinkgeldhöhe um 0.09 Dollar, mit jeder Person um 0.18 Dollar – gegeben alle anderen Faktoren bleiben konstant. Das Bestimmtheitsmaß R² (<code>Multiple R-squared:</code>) liegt bei 0.47, also 47% der Variation des Trinkgeldes wird im Modell erklärt.</p>
<p>Außerdem wird getestet, ob alle Koeffizienten der unabhängigen Variablen gleich Null sind: <span class="math display">\[H_0: \beta_1=\beta_2=\cdots=\beta_k=0\]</span> Das Ergebnis des zugrundeliegenden F-Tests (vgl. Varianzanalyse) wird in der letzten Zeile angegeben (<code>F-Statistic</code>). Hier wird <span class="math inline">\(H_0\)</span> also verworfen.</p>
</div>
<div id="erweiterungen" class="section level3">
<h3><span class="header-section-number">6.1.5</span> Erweiterungen</h3>
<div id="modellwahl" class="section level4">
<h4><span class="header-section-number">6.1.5.1</span> Modellwahl</h4>
<p>Das Modell mit allen Variablen des Datensatzes, d. h., mit 6 unabhängigen (<code>LinMod.4</code>) erklärt 47.01% der Variation, das Modell <em>nur</em> mit der Rechnungshöhe als erklärende Variable (<code>LinMod.1</code>) schon 45.66%, der Erklärungszuwachs liegt also gerade einmal bei 1.35 Prozentpunkten. In der Statistik ist die Wahl des <em>richtigen</em> Modells eine der größten Herausforderungen, auch deshalb, weil das wahre Modell in der Regel nicht bekannt ist und es schwer ist, die richtige Balance zwischen Einfachheit und Komplexität zu finden. Aufgrund des Zufalls kann es immer passieren, dass das Modell sich zu sehr an die <em>zufälligen</em> Daten anpasst (Stichwort: Overfitting). Es gibt unzählige Modellwahlmethoden, und leider garantiert keine, dass immer das beste Modell gefunden wird. Eine Möglichkeit ist die sogenannte Schrittweise-Rückwärtsselektion auf Basis des Akaike-Informationskriteriums (AIC)<a href="#fn32" class="footnoteRef" id="fnref32"><sup>32</sup></a>. Diese ist nicht nur recht weit verbreitet - und liefert unter bestimmten Annahmen das “richtige” Modell - sondern in R durch den Befehl <code>step()</code> einfach umsetzbar:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">step</span>(LinMod<span class="fl">.4</span>)
<span class="co">#&gt; Start:  AIC=20.5</span>
<span class="co">#&gt; tip ~ total_bill + size + sex + smoker + day + time</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;              Df Sum of Sq RSS   AIC</span>
<span class="co">#&gt; - day         3       0.6 247  15.1</span>
<span class="co">#&gt; - time        1       0.0 247  18.5</span>
<span class="co">#&gt; - sex         1       0.1 247  18.6</span>
<span class="co">#&gt; - smoker      1       0.4 247  18.9</span>
<span class="co">#&gt; &lt;none&gt;                    247  20.5</span>
<span class="co">#&gt; - size        1       4.1 251  22.5</span>
<span class="co">#&gt; - total_bill  1     101.6 348 102.7</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Step:  AIC=15.1</span>
<span class="co">#&gt; tip ~ total_bill + size + sex + smoker + time</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;              Df Sum of Sq RSS  AIC</span>
<span class="co">#&gt; - time        1       0.0 247 13.1</span>
<span class="co">#&gt; - sex         1       0.0 247 13.2</span>
<span class="co">#&gt; - smoker      1       0.4 248 13.5</span>
<span class="co">#&gt; &lt;none&gt;                    247 15.1</span>
<span class="co">#&gt; - size        1       4.3 251 17.4</span>
<span class="co">#&gt; - total_bill  1     101.7 349 97.2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Step:  AIC=13.1</span>
<span class="co">#&gt; tip ~ total_bill + size + sex + smoker</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;              Df Sum of Sq RSS  AIC</span>
<span class="co">#&gt; - sex         1       0.0 247 11.2</span>
<span class="co">#&gt; - smoker      1       0.4 248 11.5</span>
<span class="co">#&gt; &lt;none&gt;                    247 13.1</span>
<span class="co">#&gt; - size        1       4.3 251 15.4</span>
<span class="co">#&gt; - total_bill  1     103.3 350 96.3</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Step:  AIC=11.2</span>
<span class="co">#&gt; tip ~ total_bill + size + smoker</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;              Df Sum of Sq RSS  AIC</span>
<span class="co">#&gt; - smoker      1       0.4 248  9.5</span>
<span class="co">#&gt; &lt;none&gt;                    247 11.2</span>
<span class="co">#&gt; - size        1       4.3 252 13.4</span>
<span class="co">#&gt; - total_bill  1     104.3 351 95.0</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Step:  AIC=9.53</span>
<span class="co">#&gt; tip ~ total_bill + size</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;              Df Sum of Sq RSS  AIC</span>
<span class="co">#&gt; &lt;none&gt;                    248  9.5</span>
<span class="co">#&gt; - size        1       5.2 253 12.6</span>
<span class="co">#&gt; - total_bill  1     106.3 354 94.7</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ total_bill + size, data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt; (Intercept)   total_bill         size  </span>
<span class="co">#&gt;      0.6689       0.0927       0.1926</span></code></pre></div>
<p>In den letzten Zeilen der Ausgabe steht das beste Modell, das diese Methode (schrittweise, rückwärts) mit diesem Kriterium (AIC) bei diesen Daten findet (Punktprognose, d. h. ohne Residuum):</p>
<p><code>tip =  0.66894 +  0.09271 * total_bill + 0.19260 * size</code></p>
<p>Der Ausgabe können Sie auch entnehmen, welche Variablen in welcher Reihenfolge <em>entfernt</em> wurden: Zunächst <code>day</code>, dann <code>time</code>, danach <code>sex</code> und schließlich <code>smoker</code>. Hier sind also dieselben Variablen noch im Modell, die auch in <code>LinMod.4</code> signifikant zum Niveau 10% waren, eine Auswahl der dort signifikanten Variablen hätte also dasselbe Modell ergeben. Das ist häufig so, aber nicht immer!</p>
</div>
<div id="interaktionen" class="section level4">
<h4><span class="header-section-number">6.1.5.2</span> Interaktionen</h4>
<p>Wir haben gesehen, dass es einen Zusammenhang zwischen der Trinkgeldhöhe und der Rechnungshöhe gibt. Vielleicht unterscheidet sich der Zusammenhang je nachdem, ob geraucht wurde, d. h., vielleicht gibt es eine Interaktion (Wechselwirkung). Die kann in <code>lm</code> einfach durch ein <code>*</code> zwischen den unabhängigen Variablen modelliert werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">LinMod<span class="fl">.6</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(tip ~<span class="st"> </span>smoker*total_bill, <span class="dt">data =</span> tips)
<span class="kw">summary</span>(LinMod<span class="fl">.6</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ smoker * total_bill, data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -2.679 -0.524 -0.120  0.475  4.900 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)           0.36007    0.20206    1.78  0.07601 .  </span>
<span class="co">#&gt; smokerYes             1.20420    0.31226    3.86  0.00015 ***</span>
<span class="co">#&gt; total_bill            0.13716    0.00968   14.17  &lt; 2e-16 ***</span>
<span class="co">#&gt; smokerYes:total_bill -0.06757    0.01419   -4.76  3.3e-06 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 0.979 on 240 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.506,  Adjusted R-squared:   0.5 </span>
<span class="co">#&gt; F-statistic: 81.9 on 3 and 240 DF,  p-value: &lt;2e-16</span></code></pre></div>
<p>Der Schätzwert für die Interaktion steht bei <code>:</code>. Hier also: Wenn geraucht wurde, ist die Steigung im Durchschnitt um 6,8 Cent geringer. Aber wenn geraucht wurde, ist die Rechnung im Achsenabschnitt erstmal um 1,20$ höher (Effekt, ceteris paribus). Wer will, kann ausrechnen, ab welcher Rechnungshöhe Rauchertische im Mittelwert lukrativer sind…</p>
<p>Das gleiche Bild (höhere Achsenabschnitt, geringere Steigung) ergibt sich übrigens bei getrennten Regressionen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(tip~total_bill, <span class="dt">data=</span>tips, <span class="dt">subset =</span> smoker==<span class="st">&quot;Yes&quot;</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ total_bill, data = tips, subset = smoker == </span>
<span class="co">#&gt;     &quot;Yes&quot;)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt; (Intercept)   total_bill  </span>
<span class="co">#&gt;      1.5643       0.0696</span>
<span class="kw">lm</span>(tip~total_bill, <span class="dt">data=</span>tips, <span class="dt">subset =</span> smoker==<span class="st">&quot;No&quot;</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ total_bill, data = tips, subset = smoker == </span>
<span class="co">#&gt;     &quot;No&quot;)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt; (Intercept)   total_bill  </span>
<span class="co">#&gt;       0.360        0.137</span></code></pre></div>
</div>
<div id="weitere-modellierungsmoglichkeiten" class="section level4">
<h4><span class="header-section-number">6.1.5.3</span> Weitere Modellierungsmöglichkeiten</h4>
<p>Über das Formelinterface <code>y~x</code> können auch direkt z. B. Polynome modelliert werden. Hier eine quadratische Funktion:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(tip~<span class="kw">I</span>(total_bill^<span class="dv">2</span>)+total_bill, <span class="dt">data=</span>tips))
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = tip ~ I(total_bill^2) + total_bill, data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -3.200 -0.559 -0.098  0.484  3.776 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                  Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)      8.91e-01   3.47e-01    2.57  0.01078 *  </span>
<span class="co">#&gt; I(total_bill^2) -5.71e-05   6.02e-04   -0.09  0.92457    </span>
<span class="co">#&gt; total_bill       1.08e-01   3.08e-02    3.51  0.00054 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 1.02 on 241 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.457,  Adjusted R-squared:  0.452 </span>
<span class="co">#&gt; F-statistic:  101 on 2 and 241 DF,  p-value: &lt;2e-16</span></code></pre></div>
<p>D. h., die geschätzte Funktion ist eine “umgedrehte Parabel” (negatives Vorzeichen bei <code>I(total_bill^2)</code>), bzw. die Funktion ist konkav, die Steigung nimmt ab. Allerdings ist der Effekt nicht signifikant. <strong>Hinweis:</strong> Um zu “rechnen” und nicht beispielsweise Interaktion zu modellieren, geben Sie die Variablen in der Formel in der Funktion <code>I()</code> (<em>As Is</em>) ein.</p>
</div>
<div id="prognoseintervalle" class="section level4">
<h4><span class="header-section-number">6.1.5.4</span> Prognoseintervalle</h4>
<p>Insgesamt haben wir viel “Unsicherheit” u. a. aufgrund von Variabilität in den Beobachtungen und in den Schätzungen. Wie wirken sich diese auf die Prognose aus?</p>
<p>Dazu können wir über die Funktion <code>predict.lm</code> Prognoseintervalle berechnen – hier für das einfache Modell <code>LinMod.1</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">total_bill =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">75</span>))
preddat &lt;-<span class="st"> </span><span class="kw">predict</span>(LinMod<span class="fl">.1</span>, <span class="dt">newdata =</span> newdat, <span class="dt">interval =</span> <span class="st">&quot;prediction&quot;</span>)
<span class="kw">head</span>(preddat)
<span class="co">#&gt;    fit    lwr  upr</span>
<span class="co">#&gt; 1 0.92 -1.117 2.96</span>
<span class="co">#&gt; 2 1.03 -1.010 3.06</span>
<span class="co">#&gt; 3 1.13 -0.903 3.16</span>
<span class="co">#&gt; 4 1.24 -0.797 3.27</span>
<span class="co">#&gt; 5 1.34 -0.690 3.37</span>
<span class="co">#&gt; 6 1.45 -0.583 3.47</span>
<span class="kw">tail</span>(preddat)
<span class="co">#&gt;     fit  lwr  upr</span>
<span class="co">#&gt; 71 8.27 6.13 10.4</span>
<span class="co">#&gt; 72 8.38 6.23 10.5</span>
<span class="co">#&gt; 73 8.48 6.33 10.6</span>
<span class="co">#&gt; 74 8.59 6.43 10.7</span>
<span class="co">#&gt; 75 8.69 6.53 10.9</span>
<span class="co">#&gt; 76 8.80 6.63 11.0</span>
<span class="kw">matplot</span>(newdat$total_bill, preddat, <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">type=</span><span class="st">&quot;l&quot;</span> )
<span class="kw">points</span>(<span class="dt">x=</span>tips$total_bill, <span class="dt">y=</span>tips$tip)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-30-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Sie sehen, dass 95% Prognoseintervall ist recht breit: über den gewählten Rechnungsbereich von <span class="math inline">\(0-75\)</span>$ im Mittelwert bei 4.11$.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">favstats</span>((preddat[,<span class="dv">3</span>]-preddat[,<span class="dv">2</span>]))
<span class="co">#&gt;   min   Q1 median   Q3  max mean     sd  n missing</span>
<span class="co">#&gt;  4.03 4.04   4.07 4.17 4.34 4.12 0.0904 76       0</span></code></pre></div>
<p>Zu den Rändern hin wird es breiter. Am schmalsten ist es übrigens beim Mittelwert der unabhängigen Beobachtungen, hier also bei 19.79$.</p>
<hr />
</div>
</div>
<div id="ubung-teaching-rating" class="section level3">
<h3><span class="header-section-number">6.1.6</span> Übung: Teaching Rating</h3>
<p>Dieser Datensatz analysiert u. a. den Zusammenhang zwischen Schönheit und Evaluierungsergebnis von Dozenten <span class="citation">(Hamermesh and Parker <a href="#ref-hamermesh2005beauty">2005</a>)</span>. Sie können ihn, sofern noch nicht geschehen, von <a href="https://goo.gl/6Y3KoK" class="uri">https://goo.gl/6Y3KoK</a> als <code>csv</code> herunterladen.</p>
<p>Versuchen Sie, das Evaluierungsergebnis als abhängige Variable anhand geeigneter Variablen des Datensatzes zu erklären. Wie groß ist der Einfluss der Schönheit? Sind die Modellannahmen erfüllt und wie beurteilen Sie die Modellgüte?</p>
</div>
<div id="literatur" class="section level3">
<h3><span class="header-section-number">6.1.7</span> Literatur</h3>
<ul>
<li>David M. Diez, Christopher D. Barr, Mine Çetinkaya-Rundel (2014): <em>Introductory Statistics with Randomization and Simulation</em>, <a href="https://www.openintro.org/stat/textbook.php?stat_book=isrs" class="uri">https://www.openintro.org/stat/textbook.php?stat_book=isrs</a>, Kapitel 5, 6.1-6.3</li>
<li>Nicholas J. Horton, Randall Pruim, Daniel T. Kaplan (2015): Project MOSAIC Little Books <em>A Student’s Guide to R</em>, <a href="https://github.com/ProjectMOSAIC/LittleBooks/raw/master/StudentGuide/MOSAIC-StudentGuide.pdf" class="uri">https://github.com/ProjectMOSAIC/LittleBooks/raw/master/StudentGuide/MOSAIC-StudentGuide.pdf</a>, Kapitel 5.4, 10.2</li>
<li>Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani (2013): <em>An Introduction to Statistical Learning – with Applications in R</em>, <a href="http://www-bcf.usc.edu/~gareth/ISL/" class="uri">http://www-bcf.usc.edu/~gareth/ISL/</a>, Kapitel 3</li>
<li>Maike Luhmann (2015): <em>R für Einsteiger</em>, Kapitel 16, 17.1-17.3</li>
<li>Andreas Quatember (2010): <em>Statistik ohne Angst vor Formeln</em>, Kapitel 3.11</li>
<li>Daniel Wollschläger (2014): <em>Grundlagen der Datenanalyse mit R</em>, Kapitel 6</li>
</ul>
<hr />
<p>Diese Übung basiert teilweise auf Übungen zum Buch <a href="https://www.openintro.org/stat/index.php?stat_book=isrs">OpenIntro</a> von Andrew Bray und Mine Çetinkaya-Rundel unter der Lizenz <a href="http://creativecommons.org/licenses/by-sa/3.0">Creative Commons Attribution-ShareAlike 3.0 Unported</a>.</p>
</div>
</div>
<div id="klassifizierende-regression" class="section level2">
<h2><span class="header-section-number">6.2</span> Klassifizierende Regression</h2>
<div id="vorbereitung" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Vorbereitung</h3>
<p>Hier werden wir den Datensatz <em>Aktienkauf</em> der Universität Zürich (<a href="http://www.methodenberatung.uzh.ch/de/datenanalyse/zusammenhaenge/lreg.html">Universität Zürich, Methodenberatung</a>) analysieren. Es handelt es sich hierbei um eine Befragung einer Bank im Zusammenhang mit den Fakten, die mit der Wahrscheinlichkeit, dass jemand Aktien erwirbt, zusammenhängen. Es wurden 700 Personen befragt. Folgende Daten wurden erhoben: Aktienkauf (0 = nein, 1 = ja), Jahreseinkommen (in Tausend CHF), Risikobereitschaft (Skala von 0 bis 25) und Interesse an der aktuellen Marktlage (Skala von 0 bis 45).</p>
<p>Den Datensatz können Sie in so als <code>csv</code>-Datei herunterladen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Aktien &lt;-<span class="st"> </span><span class="kw">read.csv2</span>(<span class="st">&quot;https://raw.githubusercontent.com/luebby/Datenanalyse-mit-R/master/Daten/Aktienkauf.csv&quot;</span>)</code></pre></div>
<p>Zur Unterstützung der Analyse wird (wieder) <code>mosaic</code> und <code>ggplot2</code> verwendet.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mosaic)
<span class="kw">library</span>(ggplot2)</code></pre></div>
</div>
<div id="problemstellung" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Problemstellung</h3>
<p>Können wir anhand der Risikobereitschaft abschätzen, ob die Wahrscheinlichkeit für einen Aktienkauf steigt? Schauen wir uns zunächst ein Streudiagramm an:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">xyplot</span>(Aktienkauf ~<span class="st"> </span>Risikobereitschaft, <span class="dt">data =</span> Aktien)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-34-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Der Zusammenhang scheint nicht sehr ausgeprägt zu sein. Lassen Sie uns dennoch ein lineare Regression durchführen und das Ergebnis auswerten und graphisch darstellen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm1 &lt;-<span class="st"> </span><span class="kw">lm</span>(Aktienkauf ~<span class="st"> </span>Risikobereitschaft, <span class="dt">data =</span> Aktien)
<span class="kw">summary</span>(lm1)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = Aktienkauf ~ Risikobereitschaft, data = Aktien)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -0.684 -0.243 -0.204  0.348  0.814 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                    Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)         0.18246    0.02001    9.12  &lt; 2e-16 ***</span>
<span class="co">#&gt; Risikobereitschaft  0.05083    0.00762    6.67  5.2e-11 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 0.427 on 698 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.0599, Adjusted R-squared:  0.0586 </span>
<span class="co">#&gt; F-statistic: 44.5 on 1 and 698 DF,  p-value: 5.25e-11</span>
<span class="kw">plotModel</span>(lm1)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-35-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Der Schätzer für die Steigung für <code>Risikobereitschaft</code> ist signifikant. Das Bestimmtheitsmaß R ist allerdings sehr niedrig, aber wir haben bisher ja auch nur eine unabhängige Variable für die Erklärung der abhängigen Variable herangezogen.</p>
<p>Doch was bedeutet es, dass die Wahrscheinlichkeit ab einer Risikobereitsschaft von ca. 16 über 1 liegt?</p>
<p>Wahrscheinlichkeiten müssen zwischen 0 und 1 liegen. Daher brauchen wir eine Funktion, die das Ergebnis einer linearen Regression in einen Bereich von 0 bis 1 bringt, die sogenannte <em>Linkfunktion</em>. Eine häufig dafür verwendete Funktion ist die logistische Funktion: <span class="math display">\[p(y=1)=\frac{e^\eta}{1+e^\eta}=\frac{1}{1+e^{-\eta}}\]</span></p>
<p><span class="math inline">\(\eta\)</span>, das sogenannte <em>Logit</em>, ist darin die Linearkombination der Einflussgrößen: <span class="math display">\[\eta=\beta_0+\beta_1\cdot x_1+\dots\]</span></p>
<p>Exemplarisch können wir die logistische Funktion für einen Bereich von <span class="math inline">\(\eta=-10\)</span> bis <span class="math inline">\(+10\)</span> darstellen:</p>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-36-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="die-idee-der-logistischen-regression" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Die Idee der logistischen Regression</h3>
<p>Die logistische Regression ist eine Anwendung des allgemeinen linearen Modells (<em>general linear model, GLM</em>). Die Modellgleichung lautet: <span class="math display">\[p(y_i=1)=L\bigl(\beta_0+\beta_1\cdot x_{i1}+\dots+\beta_K\cdot x_{ik}\bigr)+\epsilon_i\]</span></p>
<blockquote>
<p><span class="math inline">\(L\)</span> ist die Linkfunktion, in unserer Anwendung die logistische Funktion.<br />
<span class="math inline">\(x_{ik}\)</span> sind die beobachten Werte der unabhängigen Variablen <span class="math inline">\(X_k\)</span>.<br />
<span class="math inline">\(k\)</span> sind die unabhängigen Variablen <span class="math inline">\(1\)</span> bis <span class="math inline">\(K\)</span>.</p>
</blockquote>
<p>Die Funktion <code>glm</code> führt die logistische Regression durch. Wir schauen uns im Anschluss zunächst den Plot an.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm1 &lt;-<span class="st"> </span><span class="kw">glm</span>(Aktienkauf ~<span class="st"> </span>Risikobereitschaft, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="st">&quot;logit&quot;</span>),
            <span class="dt">data =</span> Aktien)
<span class="kw">plotModel</span>(glm1)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-37-1.png" width="70%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Es werden ein Streudiagramm der beobachten Werte sowie die <em>Regressionslinie</em> ausgegeben. Wir können so z. B. ablesen, dass ab einer Risikobereitschaft von etwa 7 die Wahrscheinlichkeit für einen Aktienkauf nach unserem Modell bei mehr als 50 % liegt.</p>
</blockquote>
<p>Die Zusammenfassung des Modells zeigt folgendes:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(glm1)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = Aktienkauf ~ Risikobereitschaft, family = binomial(&quot;logit&quot;), </span>
<span class="co">#&gt;     data = Aktien)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -1.653  -0.738  -0.677   0.825   1.823  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)         -1.4689     0.1184   -12.4  &lt; 2e-16 ***</span>
<span class="co">#&gt; Risikobereitschaft   0.2573     0.0468     5.5  3.8e-08 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 804.36  on 699  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 765.86  on 698  degrees of freedom</span>
<span class="co">#&gt; AIC: 769.9</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></code></pre></div>
<p>Der Achsenabschnitt (<code>intercept</code>) des logits <span class="math inline">\(\eta\)</span> wird mit -1.47 geschätzt, die Steigung in Richtung <code>Risikobereitschaft</code> mit 0.26. Die (Punkt-)Prognose für die Wahrscheinlickeit eines Aktienkaufs <span class="math inline">\(p(y=1)\)</span> benötigt anders als in der linearen Regression noch die Linkfunktion und ergibt sich somit zu: <span class="math display">\[p(\texttt{Aktienkauf}=1)=\frac{1}{1+e^{-(-1.47 + 0.26 \cdot \texttt{Risikobereitschaft})}}\]</span></p>
<p>Die p-Werte der Koeffizienten können in der Spalte <code>Pr(&gt;|z|)</code> abgelesen werden. Hier wird ein <em>Wald</em>-Test durchgeführt, nicht wie bei der linearen Regression ein t-Test, ebenfalls mit der <span class="math inline">\(H_0:\beta_i=0\)</span>. Die Teststastistik (<code>z value</code>) wird wie in der linearen Regression durch Divisions des Schätzers (<code>Estimate</code>) durch den Standardfehler (<code>Std. Error</code>) ermittelt. Im <em>Wald</em>-Test ist die Teststatistik allerdings <span class="math inline">\(\chi^2\)</span>-verteilt mit einem Freiheitsgrad.</p>
</div>
<div id="welche-unterschiede-zur-linearen-regression-gibt-es-in-der-ausgabe" class="section level3">
<h3><span class="header-section-number">6.2.4</span> Welche Unterschiede zur linearen Regression gibt es in der Ausgabe?</h3>
<p>Es gibt kein R im Sinne einer erklärten Streuung der <span class="math inline">\(y\)</span>-Werte, da die beobachteten <span class="math inline">\(y\)</span>-Werte nur <span class="math inline">\(0\)</span> oder <span class="math inline">\(1\)</span> annehmen können. Das Gütemaß bei der logistischen Regression ist das <em>Akaike Information Criterion</em> (<em>AIC</em>). Hier gilt allerdings: je <strong>kleiner</strong>, desto <strong>besser</strong>. (Anmerkung: es kann ein Pseudo-R berechnet werden – kommt später.)</p>
<p>Es gibt keine F-Statistik (oder ANOVA) mit der Frage, ob das Modell als Ganzes signifikant ist. (Anmerkung: es kann aber ein vergleichbarer Test durchgeführt werden – kommt später.)</p>
</div>
<div id="interpretation-der-koeffizienten" class="section level3">
<h3><span class="header-section-number">6.2.5</span> Interpretation der Koeffizienten</h3>
<div id="y-achsenabschnitt-intercept-beta_0" class="section level4">
<h4><span class="header-section-number">6.2.5.1</span> y-Achsenabschnitt (<code>Intercept</code>) <span class="math inline">\(\beta_0\)</span></h4>
<p>Für <span class="math inline">\(\beta_0&gt;0\)</span> gilt, dass selbst wenn alle anderen unabhängigen Variablen <span class="math inline">\(0\)</span> sind, es eine Wahrscheinlichkeit von mehr als 50% gibt, dass das modellierte Ereignis eintritt. Für <span class="math inline">\(\beta_0&lt;0\)</span> gilt entsprechend das Umgekehrte.</p>
</div>
<div id="steigung-beta_i-mit-i12...k" class="section level4">
<h4><span class="header-section-number">6.2.5.2</span> Steigung <span class="math inline">\(\beta_i\)</span> mit <span class="math inline">\(i=1,2,...,K\)</span></h4>
<p>Für <span class="math inline">\(\beta_i&gt;0\)</span> gilt, dass mit zunehmenden <span class="math inline">\(x_i\)</span> die Wahrscheinlichkeit für das modellierte Ereignis steigt. Bei <span class="math inline">\(\beta_i&lt;0\)</span> nimmt die Wahrscheinlichkeit entsprechend ab.</p>
<p>Eine Abschätzung der Änderung der Wahrscheinlichkeit (<em>relatives Risiko</em>, <em>relative risk</em> <span class="math inline">\(RR\)</span>) kann über das Chancenverhältnis (<em>Odds Ratio</em> <span class="math inline">\(OR\)</span>) gemacht werden.<a href="#fn33" class="footnoteRef" id="fnref33"><sup>33</sup></a> Es ergibt sich vereinfacht <span class="math inline">\(e^{\beta_i}\)</span>. Die Wahrscheinlichkeit ändert sich näherungsweise um diesen Faktor, wenn sich <span class="math inline">\(x_i\)</span> um eine Einheit erhöht. <strong>Hinweis:</strong> <span class="math inline">\(RR\approx OR\)</span> gilt nur, wenn der Anteil des modellierten Ereignisses in den beobachteten Daten sehr klein (<span class="math inline">\(&lt;5\%\)</span>) oder sehr groß ist (<span class="math inline">\(&gt;95\%\)</span>).</p>
<p><em>Übung</em>: Berechnen Sie das relative Risiko für unser Beispielmodell, wenn sich die <code>Risikobereitschaft</code> um 1 erhöht (Funktion <code>exp()</code>). Vergleichen Sie das Ergebnis mit der Punktprognose für <code>Risikobereitschaft</code><span class="math inline">\(=7\)</span> im Vergleich zu <code>Risikobereitschaft</code><span class="math inline">\(=8\)</span>. Zur Erinnerung: Sie können <code>makeFun(model)</code> verwenden.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># aus Koeffizient abgeschätzt</span>
<span class="kw">exp</span>(<span class="kw">coef</span>(glm1)[<span class="dv">2</span>])
<span class="co">#&gt; Risikobereitschaft </span>
<span class="co">#&gt;               1.29</span>
<span class="co"># mit dem vollständigen Modell berechnet</span>
fun1 &lt;-<span class="st"> </span><span class="kw">makeFun</span>(glm1)
<span class="kw">fun1</span>(<span class="dt">Risikobereitschaft =</span> <span class="dv">7</span>)
<span class="co">#&gt;     1 </span>
<span class="co">#&gt; 0.582</span>
<span class="kw">fun1</span>(<span class="dt">Risikobereitschaft =</span> <span class="dv">8</span>)
<span class="co">#&gt;     1 </span>
<span class="co">#&gt; 0.643</span>
<span class="co"># als Faktor ausgeben</span>
<span class="kw">fun1</span>(<span class="dt">Risikobereitschaft =</span> <span class="dv">8</span>)/<span class="kw">fun1</span>(<span class="dt">Risikobereitschaft =</span> <span class="dv">7</span>)
<span class="co">#&gt;   1 </span>
<span class="co">#&gt; 1.1</span></code></pre></div>
<p>Sie sehen also, die ungefähr abgeschätzte Änderung der Wahrscheinlichkeit weicht hier doch deutlich von der genau berechneten Änderung ab. Der Anteil der Datensätze mit <code>Risikobereitschaft</code><span class="math inline">\(=1\)</span> liegt allerdings auch bei 0.26.</p>
</div>
</div>
<div id="kategoriale-variablen" class="section level3">
<h3><span class="header-section-number">6.2.6</span> Kategoriale Variablen</h3>
<p>Wie schon in der linearen Regression können auch in der logistschen Regression kategoriale Variablen als unabhängige Variablen genutzt werden. Als Beispiel nehmen wir den Datensatz <code>tips</code> und versuchen abzuschätzen, ob sich die Wahrscheinlichkeit dafür, dass ein Raucher bezahlt hat (<code>smoker == yes</code>), in Abhängigkeit vom Wochentag ändert.</p>
<p>Sofern noch nicht geschehen, können Sie so als <code>csv</code>-Datei herunterladen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tips &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;https://sebastiansauer.github.io/data/tips.csv&quot;</span>)</code></pre></div>
<p>Zunächst ein Plot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">xyplot</span>(<span class="kw">jitter</span>(<span class="kw">as.numeric</span>(smoker)) ~<span class="st"> </span>day, <span class="dt">data =</span> tips)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-41-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p><strong>Hinweis:</strong> Um zu sehen, ob es an manchen Tagen mehr Raucher gibt, sollten Sie zumindest eine Variable “verrauschen” (“<em>jittern</em>”). Da die Variable <code>smoker</code> eine nominale Variable ist und die Funktion <code>jitter()</code> nur mit numerischen Variablen arbeitet, muss sie mit <code>as.numeric()</code> in eine numerische Variable umgewandelt werden.</p>
<p>Die relativen Häufigkeiten zeigt folgende Tabelle:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(tab_smoke &lt;-<span class="st"> </span><span class="kw">tally</span>(smoker ~<span class="st"> </span>day, <span class="dt">data =</span> tips, <span class="dt">format =</span> <span class="st">&quot;proportion&quot;</span>))
<span class="co">#&gt;       day</span>
<span class="co">#&gt; smoker   Fri   Sat   Sun  Thur</span>
<span class="co">#&gt;    No  0.211 0.517 0.750 0.726</span>
<span class="co">#&gt;    Yes 0.789 0.483 0.250 0.274</span></code></pre></div>
<p>Hinweis: Durch die Klammerung wird das Objekt <code>tab_smoke</code> direkt ausgegeben.</p>
<p>Probieren wir die logistische Regression aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glmtips &lt;-<span class="st"> </span><span class="kw">glm</span>(smoker ~<span class="st"> </span>day, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="st">&quot;logit&quot;</span>),<span class="dt">data =</span> tips)
<span class="kw">summary</span>(glmtips)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = smoker ~ day, family = binomial(&quot;logit&quot;), data = tips)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -1.765  -0.801  -0.758   1.207   1.665  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)    1.322      0.563    2.35  0.01883 *  </span>
<span class="co">#&gt; daySat        -1.391      0.602   -2.31  0.02093 *  </span>
<span class="co">#&gt; daySun        -2.420      0.622   -3.89    1e-04 ***</span>
<span class="co">#&gt; dayThur       -2.295      0.631   -3.64  0.00027 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 324.34  on 243  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 298.37  on 240  degrees of freedom</span>
<span class="co">#&gt; AIC: 306.4</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></code></pre></div>
<p>Auch hier können wir die Koeffizienten in Relation zur Referenzkategorie (hier: Freitag) interpretieren. Die Wahrscheinlichkeit ist an einem Samstag niedriger, der Wert für <code>daySat</code> ist negativ. Eine Abschätzung erhalten wir wieder mit <span class="math inline">\(e^{\beta_i}\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(glmtips)[<span class="dv">2</span>])
<span class="co">#&gt; daySat </span>
<span class="co">#&gt;  0.249</span></code></pre></div>
<p>Daher ist das Chancenverhältnis (<em>Odds Ratio</em>), dass am Samstag ein Raucher am Tisch sitzt, näherungsweise um den Faktor 0.25 niedriger als am Freitag:</p>
<p><span class="math display">\[
{
OR=\frac{\frac{P(Raucher|Samstag)}{1-P(Raucher|Samstag)}}
{\frac{P(Raucher|Freitag)}{1-P(Raucher|Freitag)}}
=\frac{\frac{0.483}{0.517}}
{\frac{0.79}{0.21}}
\approx 0.249}\]</span></p>
</div>
<div id="multiple-logistische-regression" class="section level3">
<h3><span class="header-section-number">6.2.7</span> Multiple logistische Regression</h3>
<p>Wir kehren wieder zurück zu dem Datensatz <em>Aktienkauf</em>. Können wir unser Model <code>glm1</code> mit nur einer erklärenden Variable verbessern, indem weitere unabhängige Variablen hinzugefügt werden?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm2 &lt;-<span class="st"> </span><span class="kw">glm</span>(Aktienkauf ~<span class="st"> </span>Risikobereitschaft +<span class="st"> </span>Einkommen +<span class="st"> </span>Interesse, 
            <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="st">&quot;logit&quot;</span>),<span class="dt">data =</span> Aktien)
<span class="kw">plotModel</span>(glm2)
<span class="kw">summary</span>(glm2)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = Aktienkauf ~ Risikobereitschaft + Einkommen + Interesse, </span>
<span class="co">#&gt;     family = binomial(&quot;logit&quot;), data = Aktien)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -2.130  -0.715  -0.539   0.518   3.214  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)        -1.66791    0.27903   -5.98  2.3e-09 ***</span>
<span class="co">#&gt; Risikobereitschaft  0.34781    0.08822    3.94  8.1e-05 ***</span>
<span class="co">#&gt; Einkommen          -0.02157    0.00564   -3.83  0.00013 ***</span>
<span class="co">#&gt; Interesse           0.08520    0.01775    4.80  1.6e-06 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 804.36  on 699  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 679.01  on 696  degrees of freedom</span>
<span class="co">#&gt; AIC: 687</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-45-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Alle Schätzer sind signifkant zum 0.1 %-Niveau (<code>***</code> in der Ausgabe). Zunehmende Risikobereitschaft (der Einfluss ist im Vergleich zum einfachen Modell stärker geworden) und zunehmendes Interesse erhöhen die Wahrscheinlichkeit für einen Aktienkauf. Steigendes Einkommen hingegen senkt die Wahrscheinlichkeit.</p>
<p>Ist das Modell besser als das einfache? Ja, da der AIC-Wert von 769.86 auf 687.01 gesunken ist.</p>
<p>Die Graphik zeigt die Verläufe in Abhängigkeit von den verschiedenen Variablen und den Kombinationen der Variablen.</p>
</div>
<div id="erweiterungen-1" class="section level3">
<h3><span class="header-section-number">6.2.8</span> Erweiterungen</h3>
<div id="klassifikationsgute" class="section level4">
<h4><span class="header-section-number">6.2.8.1</span> Klassifikationsgüte</h4>
<p>Logistische Regressionsmodelle werden häufig zur Klassifikation verwendet, z. B. ob der Kredit für einen Neukunden ein “guter” Kredit ist oder nicht. Daher sind die Klassifikationseigenschaften bei logistischen Modellen wichtige Kriterien.</p>
<p>Hierzu werden die aus dem Modell ermittelten Wahrscheinlichkeiten ab einem Schwellenwert (<em>cutpoint</em>), häufig <span class="math inline">\(0.5\)</span>, einer geschätzten <span class="math inline">\(1\)</span> zugeordnet, unterhalb des Schwellenwertes einer <span class="math inline">\(0\)</span>. Diese aus dem Modell ermittelten Häufigkeiten werden dann in einer sogenannten Konfusionsmatrix (<em>confusion matrix</em>) mit den beobachteten Häufigkeiten verglichen.</p>
<p>Daher sind wichtige Kriterien eines Modells, wie gut diese Zuordnung erfolgt. Dazu werden die Sensitivität (<em>True Positive Rate, TPR</em>), also der Anteil der mit <span class="math inline">\(1\)</span> geschätzten an allen mit <span class="math inline">\(1\)</span> beobachten Werten, und die Spezifität (<em>True Negative Rate</em>) berechnet. Ziel ist es, dass beide Werte möglichst hoch sind.</p>
<p>Sie können die Konfusionsmatrix “zu Fuß” berechnen, in dem Sie eine neue Variable einfügen, die ab dem cutpoint <span class="math inline">\(1\)</span> und sonst <span class="math inline">\(0\)</span> ist und mit dem Befehl <code>tally()</code> ausgeben. Alternativ können Sie das Paket <code>SDMTools</code> verwenden mit der Funktion <code>confusion.matrix()</code>. Ein Parameter ist <code>cutpoint</code>, der standardmäßig auf <span class="math inline">\(0.5\)</span> steht.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Konfusionsmatrix &quot;zu Fuß&quot; berechnen</span>
<span class="co"># cutpoint = 0.5 setzen</span>
<span class="co"># neue Variable predicted anlegen mit 1, wenn modellierte Wahrscheinlichkeit &gt; 1 ist</span>
cutpoint =<span class="st"> </span><span class="fl">0.5</span>
Aktien$predicted &lt;-<span class="st"> </span>((glm1$fitted.values) &gt;<span class="st"> </span>cutpoint)*<span class="dv">1</span>
<span class="co"># Kreuztabelle berechnen</span>
(cm &lt;-<span class="st"> </span><span class="kw">tally</span>(~predicted+Aktienkauf, <span class="dt">data =</span> Aktien))
<span class="co">#&gt;          Aktienkauf</span>
<span class="co">#&gt; predicted   0   1</span>
<span class="co">#&gt;         0 509 163</span>
<span class="co">#&gt;         1   8  20</span>
<span class="co"># Sensitivität (TPR)</span>
cm[<span class="dv">2</span>,<span class="dv">2</span>]/<span class="kw">sum</span>(cm[,<span class="dv">2</span>])
<span class="co">#&gt; [1] 0.109</span>
<span class="co"># Spezifität (TNR)</span>
cm[<span class="dv">1</span>,<span class="dv">1</span>]/<span class="kw">sum</span>(cm[,<span class="dv">1</span>])
<span class="co">#&gt; [1] 0.985</span>

<span class="co"># mit Hilfe des Pakets SDMTools</span>
<span class="co"># ggf. install.packages(&quot;SDMTools&quot;)</span>
<span class="kw">library</span>(SDMTools)
<span class="co"># optional noch Parameter cutpoint = 0.5  angeben</span>
(cm &lt;-<span class="st"> </span><span class="kw">confusion.matrix</span>(Aktien$Aktienkauf, glm1$fitted.values)) 
<span class="co">#&gt;     obs</span>
<span class="co">#&gt; pred   0   1</span>
<span class="co">#&gt;    0 509 163</span>
<span class="co">#&gt;    1   8  20</span>
<span class="co">#&gt; attr(,&quot;class&quot;)</span>
<span class="co">#&gt; [1] &quot;confusion.matrix&quot;</span>
<span class="kw">sensitivity</span>(cm)
<span class="co">#&gt; [1] 0.109</span>
<span class="kw">specificity</span>(cm)
<span class="co">#&gt; [1] 0.985</span></code></pre></div>
<p>Wenn die Anteile der <span class="math inline">\(1\)</span> in den beobachteten Daten sehr gering sind (z. B. bei einem medizinischem Test auf eine seltene Krankheit, Klicks auf einen Werbebanner oder Kreditausfall), kommt eine Schwäche der logistischen Regression zum Tragen: Das Modell wird so optimiert, dass die Wahrscheinlichkeiten <span class="math inline">\(p(y=1)\)</span> alle unter <span class="math inline">\(0.5\)</span> liegen. Das würde zu einer Sensitität von <span class="math inline">\(0\)</span> und einer Spezifiät von <span class="math inline">\(1\)</span> führen. Daher kann es sinnvoll sein, den Cutpoint zu varieren. Daraus ergibt sich ein verallgemeinertes Gütemaß, die <em>ROC</em>-Kurve (<em>Return Operating Characteristic</em>) und den daraus abgeleiteten <em>AUC</em>-Wert (<em>Area Under Curve</em>).</p>
<p>Hierzu wird der Cutpoint zwischen 0 und 1 variiert und die Sensitivität gegen <span class="math inline">\(1-\)</span>Spezifität (welche Werte sind als <span class="math inline">\(1\)</span> modelliert worden unter den beobachten <span class="math inline">\(0\)</span>, <em>False Positive Rate, FPR</em>). Um diese Werte auszugeben, benötigen Sie das Paket <code>ROCR</code> und die Funktion <code>performance()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># ggf. install.packages(&quot;ROCR&quot;)</span>
<span class="kw">library</span>(ROCR)
<span class="co"># Ein für die Auswertung notwendiges prediction Objekt anlegen</span>
pred &lt;-<span class="st"> </span><span class="kw">prediction</span>(glm1$fitted.values, Aktien$Aktienkauf)
<span class="co"># ROC Kurve</span>
perf &lt;-<span class="st"> </span><span class="kw">performance</span>(pred,<span class="st">&quot;tpr&quot;</span>,<span class="st">&quot;fpr&quot;</span>)
<span class="kw">plot</span>(perf)
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;grey&quot;</span>)
<span class="co"># Area under curve (ROC-Wert)</span>
<span class="kw">performance</span>(pred,<span class="st">&quot;auc&quot;</span>)@y.values
<span class="co">#&gt; [[1]]</span>
<span class="co">#&gt; [1] 0.636</span></code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-47-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>AUC liegt zwischen <span class="math inline">\(0.5\)</span>, wenn das Modell gar nichts erklärt (im Plot die graue Linie) und <span class="math inline">\(1\)</span>. Hier ist der Wert also recht gering. Akzeptable Werte liegen bei <span class="math inline">\(0.7\)</span> und größer, gute Werte sind es ab <span class="math inline">\(0.8\)</span>.<a href="#fn34" class="footnoteRef" id="fnref34"><sup>34</sup></a></p>
</div>
<div id="modellschatzung" class="section level4">
<h4><span class="header-section-number">6.2.8.2</span> Modellschätzung</h4>
<p>Das Modell wird nicht wie bei der lineare Regression über die Methode der kleinsten Quadrate (OLS) geschätzt, sondern über die <em>Maximum Likelihood</em> Methode. Die Koeffizienten werden so gewählt, dass die beobachteten Daten am wahrscheinlichsten (<em>Maximum Likelihood</em>) werden.</p>
<p>Das ist ein iteratives Verfahren (OLS erfolgt rein analytisch), daher wird in der letzten Zeile der Ausgabe auch die Anzahl der Iterationen (<code>Fisher Scoring Iterations</code>) ausgegeben.</p>
<p>Die Devianz des Modells (<code>Residual deviance</code>) ist <span class="math inline">\(-2\)</span> mal die logarithmierte Likelihood. Die Nulldevianz (<code>Null deviance</code>) ist die Devianz eines Nullmodells, d. h., alle <span class="math inline">\(\beta\)</span> außer der Konstanten sind 0.</p>
</div>
<div id="likelihood-quotienten-test" class="section level4">
<h4><span class="header-section-number">6.2.8.3</span> Likelihood Quotienten Test</h4>
<p>Der Likelihood Quotienten Test (<em>Likelihood Ratio Test, LR-Test</em>) vergleicht die Likelihood <span class="math inline">\(L_0\)</span> des Nullmodels mit der Likelihood <span class="math inline">\(L_{\beta}\)</span> des geschätzten Modells. Die Prüfgröße des LR-Tests ergibt sich aus: <span class="math display">\[{T=-2\cdot ln\left( \frac{L_0}{L_{\beta}}\right)}\]</span> <span class="math inline">\(T\)</span> ist näherungsweise <span class="math inline">\(\chi ^2\)</span>-verteilt mit <span class="math inline">\(k\)</span> Freiheitsgraden.</p>
<p>In R können Sie den Test mit <code>lrtest()</code> aufrufen. Sie benötigen dazu das Paket <code>lmtest</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lmtest)
<span class="kw">lrtest</span>(glm2)
<span class="co">#&gt; Likelihood ratio test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Model 1: Aktienkauf ~ Risikobereitschaft + Einkommen + Interesse</span>
<span class="co">#&gt; Model 2: Aktienkauf ~ 1</span>
<span class="co">#&gt;   #Df LogLik Df Chisq Pr(&gt;Chisq)    </span>
<span class="co">#&gt; 1   4   -340                        </span>
<span class="co">#&gt; 2   1   -402 -3   125     &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></code></pre></div>
<p>Das Modell <code>glm2</code> ist als Ganzes signifikant, der p-Wert ist sehr klein.</p>
<p>Den Likelihood Quotienten Test können Sie auch verwenden, um zwei Modelle miteinander zu vergleichen, z. B., wenn Sie eine weitere Variable hinzugenommen haben und wissen wollen, ob die Verbesserung auch signifikant war.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lrtest</span>(glm1, glm2)
<span class="co">#&gt; Likelihood ratio test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Model 1: Aktienkauf ~ Risikobereitschaft</span>
<span class="co">#&gt; Model 2: Aktienkauf ~ Risikobereitschaft + Einkommen + Interesse</span>
<span class="co">#&gt;   #Df LogLik Df Chisq Pr(&gt;Chisq)    </span>
<span class="co">#&gt; 1   2   -383                        </span>
<span class="co">#&gt; 2   4   -340  2  86.9     &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></code></pre></div>
<p>Ja, die Modelle <code>glm1</code> (mit einer erklärenden Variable) und <code>glm2</code> unterscheiden sich signifikant voneinander.</p>
</div>
<div id="pseudo-r" class="section level4">
<h4><span class="header-section-number">6.2.8.4</span> Pseudo-R</h4>
<p>Verschiedene Statistiker haben versucht, aus der Likelihood eine Größe abzuleiten, die dem R der linearen Regression entspricht. Exemplarisch sei hier McFaddens R gezeigt: <span class="math display">\[{R^2=1-\frac{ln(L_{\beta})}{ln(L_0)}}\]</span> Wie bei bei dem R der linearen Regression liegt der Wertebereich zwischen 0 und 1. Ab einem Wert von 0,4 kann die Modellanpassung als gut eingestuft werden. Wo liegen R der beiden Modelle <code>glm1</code> und <code>glm2</code>? Sie können es direkt berechnen oder das Paket <code>BaylorEdPsych</code> verwenden.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># direkte Berechnung</span>
<span class="dv">1</span> -<span class="st"> </span>glm1$deviance/glm1$null.deviance
<span class="co">#&gt; [1] 0.0479</span>
<span class="dv">1</span> -<span class="st"> </span>glm2$deviance/glm2$null.deviance
<span class="co">#&gt; [1] 0.156</span>
<span class="co"># ggf. install.packages(&quot;BaylorEdPsych&quot;)</span>
<span class="kw">library</span>(BaylorEdPsych)
<span class="kw">PseudoR2</span>(glm1)
<span class="co">#&gt;         McFadden     Adj.McFadden        Cox.Snell       Nagelkerke </span>
<span class="co">#&gt;           0.0479           0.0404           0.0535           0.0783 </span>
<span class="co">#&gt; McKelvey.Zavoina           Effron            Count        Adj.Count </span>
<span class="co">#&gt;           0.0826           0.0584           0.7557           0.0656 </span>
<span class="co">#&gt;              AIC    Corrected.AIC </span>
<span class="co">#&gt;         769.8624         769.8796</span>
<span class="kw">PseudoR2</span>(glm2)
<span class="co">#&gt;         McFadden     Adj.McFadden        Cox.Snell       Nagelkerke </span>
<span class="co">#&gt;           0.1558           0.1434           0.1640           0.2400 </span>
<span class="co">#&gt; McKelvey.Zavoina           Effron            Count        Adj.Count </span>
<span class="co">#&gt;           0.2828           0.1845           0.7614           0.0874 </span>
<span class="co">#&gt;              AIC    Corrected.AIC </span>
<span class="co">#&gt;         687.0068         687.0644</span></code></pre></div>
<p>Insgesamt ist die Modellanpassung, auch mit allen Variablen, als schlecht zu bezeichnen. <strong>Hinweis:</strong> Die Funktion <code>PseudoR2(model)</code> zeigt verschiedene Pseudo-R Statistiken, die jeweils unter bestimmten Bedingungen vorteilhaft einzusetzen sind. Für weitere Erläuterungen sei auf die Literatur verwiesen.</p>
</div>
</div>
<div id="ubung-rot--oder-weiwein" class="section level3">
<h3><span class="header-section-number">6.2.9</span> Übung: Rot- oder Weißwein?</h3>
<p>Der Datensatz untersucht den Zusammenhang zwischen der Qualität und physiochemischen Eigenschaften von portugisieschen Rot- und Weißweinen.</p>
<p><em>P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.</em></p>
<p>Sie können in <a href="https://goo.gl/Dkd7nK">hier</a>). Die Originaldaten finden Sie im UCI <a href="http://archive.ics.uci.edu/ml/datasets/Wine+Quality">Machine Learning Repository</a>.</p>
<p>Versuchen Sie anhand geeigneter Variablen, Rot- und Weißweine zu klassifizieren.<a href="#fn35" class="footnoteRef" id="fnref35"><sup>35</sup></a></p>
<p><strong>Zusatzaufgabe:</strong> Die Originaldaten bestehen aus einem Datensatz für Weißweine und einem für Rotweine. Laden Sie diese, beachten Sie die Fehlermeldung und beheben die damit verbundenen Fehler und fassen beide Datensätze zu einem gemeinsamen Datensatz zusammen, in dem eine zusätzliche Variable <code>color</code> aufgenommen wird (Rot = 0, Weiß = 1).</p>
</div>
<div id="literatur-1" class="section level3">
<h3><span class="header-section-number">6.2.10</span> Literatur</h3>
<ul>
<li>David M. Diez, Christopher D. Barr, Mine Çetinkaya-Rundel (2014): <em>Introductory Statistics with Randomization and Simulation</em>, <a href="https://www.openintro.org/stat/textbook.php?stat_book=isrs" class="uri">https://www.openintro.org/stat/textbook.php?stat_book=isrs</a>, Kapitel 6.4</li>
<li>Nicholas J. Horton, Randall Pruim, Daniel T. Kaplan (2015): Project MOSAIC Little Books <em>A Student’s Guide to R</em>, <a href="https://github.com/ProjectMOSAIC/LittleBooks/raw/master/StudentGuide/MOSAIC-StudentGuide.pdf" class="uri">https://github.com/ProjectMOSAIC/LittleBooks/raw/master/StudentGuide/MOSAIC-StudentGuide.pdf</a>, Kapitel 8</li>
<li>Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani (2013): <em>An Introduction to Statistical Learning – with Applications in R</em>, <a href="http://www-bcf.usc.edu/~gareth/ISL/" class="uri">http://www-bcf.usc.edu/~gareth/ISL/</a>, Kapitel 4.1-4.3</li>
<li>Maike Luhmann (2015): <em>R für Einsteiger</em>, Kapitel 17.5</li>
<li>Daniel Wollschläger (2014): <em>Grundlagen der Datenanalyse mit R</em>, Kapitel 8.1</li>
</ul>
</div>
</div>
<div id="baumbasierte-verfahren" class="section level2">
<h2><span class="header-section-number">6.3</span> Baumbasierte Verfahren</h2>
<div id="konjunturanalyse" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Konjunturanalyse</h3>
<p>Der B3 Datensatz <em>Heilemann, U. and Münch, H.J. (1996): West German Business Cycles 1963-1994: A Multivariate Discriminant Analysis. CIRET–Conference in Singapore, CIRET–Studien 50.</em> enthält Quartalsweise Konjunkturdaten aus (West-)Deutschland.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B3 &lt;-<span class="st"> </span><span class="kw">read.csv2</span>(<span class="st">&quot;https://goo.gl/0YCEHf&quot;</span>)
<span class="kw">str</span>(B3) <span class="co"># Datenstruktur</span>
<span class="co">#&gt; &#39;data.frame&#39;:    157 obs. of  14 variables:</span>
<span class="co">#&gt;  $ PHASEN  : int  2 2 3 3 3 3 3 3 3 3 ...</span>
<span class="co">#&gt;  $ BSP91JW : num  10.53 10.6 9.21 5.17 4.93 ...</span>
<span class="co">#&gt;  $ CP91JW  : num  9.31 12.66 6.55 7.87 8.6 ...</span>
<span class="co">#&gt;  $ DEFRATE : num  0.05 0.06 0.05 0.05 0.04 0.04 0.04 0.03 0.03 0 ...</span>
<span class="co">#&gt;  $ EWAJW   : num  5.7 5.2 4.8 3.3 2.1 3.2 2.5 2.7 3 0.3 ...</span>
<span class="co">#&gt;  $ EXIMRATE: num  3.08 1.96 2.82 3.74 4.16 2.9 3.65 4.57 4.37 2.89 ...</span>
<span class="co">#&gt;  $ GM1JW   : num  11.15 11.03 10.04 8.33 7.69 ...</span>
<span class="co">#&gt;  $ IAU91JW : num  23.56 12.72 11.52 0.85 -2.08 ...</span>
<span class="co">#&gt;  $ IB91JW  : num  14.69 24.95 14.9 7.55 3.23 ...</span>
<span class="co">#&gt;  $ LSTKJW  : num  3 2.36 3.39 5.3 6.91 1.03 3.73 6.2 4.12 7.94 ...</span>
<span class="co">#&gt;  $ PBSPJW  : num  2.89 2.59 3.01 3.03 3.46 1.95 3.18 3.98 3.29 5.63 ...</span>
<span class="co">#&gt;  $ PCPJW   : num  1.91 2.2 3.09 2.08 1.48 1.65 1.47 3.29 3.59 4.19 ...</span>
<span class="co">#&gt;  $ ZINSK   : num  6.27 4.6 6.19 6.71 7.1 4.96 5.21 4.83 4.5 3.83 ...</span>
<span class="co">#&gt;  $ ZINSLR  : num  3.21 3.54 3.22 3.37 3.14 4.95 3.82 3.09 3.91 1.47 ...</span>
<span class="kw">head</span>(B3); <span class="kw">tail</span>(B3)
<span class="co">#&gt;   PHASEN BSP91JW CP91JW DEFRATE EWAJW EXIMRATE GM1JW IAU91JW IB91JW LSTKJW</span>
<span class="co">#&gt; 1      2   10.53   9.31    0.05   5.7     3.08 11.15   23.56  14.69   3.00</span>
<span class="co">#&gt; 2      2   10.60  12.66    0.06   5.2     1.96 11.03   12.72  24.95   2.36</span>
<span class="co">#&gt; 3      3    9.21   6.55    0.05   4.8     2.82 10.04   11.52  14.90   3.39</span>
<span class="co">#&gt; 4      3    5.17   7.87    0.05   3.3     3.74  8.33    0.85   7.55   5.30</span>
<span class="co">#&gt; 5      3    4.93   8.60    0.04   2.1     4.16  7.69   -2.08   3.23   6.91</span>
<span class="co">#&gt; 6      3    8.39   5.62    0.04   3.2     2.90  6.62   -3.76  14.58   1.03</span>
<span class="co">#&gt;   PBSPJW PCPJW ZINSK ZINSLR</span>
<span class="co">#&gt; 1   2.89  1.91  6.27   3.21</span>
<span class="co">#&gt; 2   2.59  2.20  4.60   3.54</span>
<span class="co">#&gt; 3   3.01  3.09  6.19   3.22</span>
<span class="co">#&gt; 4   3.03  2.08  6.71   3.37</span>
<span class="co">#&gt; 5   3.46  1.48  7.10   3.14</span>
<span class="co">#&gt; 6   1.95  1.65  4.96   4.95</span>
<span class="co">#&gt;     PHASEN BSP91JW CP91JW DEFRATE EWAJW EXIMRATE GM1JW IAU91JW IB91JW</span>
<span class="co">#&gt; 152      3   -1.27   1.29   -4.87 -1.97     6.03  9.79  -18.29   1.73</span>
<span class="co">#&gt; 153      3   -2.13  -0.57   -2.98 -2.05     7.59  0.72  -15.82  -3.23</span>
<span class="co">#&gt; 154      3    1.39   2.33   -2.86 -1.84     7.49 11.33  -10.59   4.62</span>
<span class="co">#&gt; 155      4    1.63   0.64    1.20 -1.58     7.75 11.38   -4.90   3.62</span>
<span class="co">#&gt; 156      1    1.40   0.57   -3.56 -1.34     5.58  9.53   -0.76   2.19</span>
<span class="co">#&gt; 157      1    1.83  -0.08   -2.22 -0.93     7.50 15.20    2.75   6.12</span>
<span class="co">#&gt;     LSTKJW PBSPJW PCPJW ZINSK ZINSLR</span>
<span class="co">#&gt; 152   1.08   2.73  2.98  6.83   3.55</span>
<span class="co">#&gt; 153   1.67   2.67  3.31  6.35   3.05</span>
<span class="co">#&gt; 154  -0.12   2.66  2.94  5.88   3.17</span>
<span class="co">#&gt; 155  -1.81   1.77  2.58  5.29   4.82</span>
<span class="co">#&gt; 156  -1.54   1.85  2.60  5.01   5.27</span>
<span class="co">#&gt; 157  -0.92   1.79  2.49  5.28   5.62</span></code></pre></div>
<p>Dabei sind folgende Variablen enthalten:</p>
<ul>
<li>Bruttosozialprodukt (real): <code>BSP91JW</code></li>
<li>Privater Verbrauch (real): <code>CP91JW</code></li>
<li>Anteil Staatsdefizit am Bruttosozialprodukt (%): <code>DEFRATE</code></li>
<li>Abhängig Erwerbstätige: <code>EWAJW</code></li>
<li>Anteil Außenbeitrag am Bruttosozialprodukt (%): <code>EXIMRATE</code></li>
<li>Geldmenge M1: <code>GM1JW</code></li>
<li>Investitionen in Ausrüstungsgüter (real): <code>IAU91JW</code></li>
<li>Investitionen in Bauten (real): <code>IB91JW</code></li>
<li>Lohnstückkosten: <code>LSTKJW</code></li>
<li>Preisindex des Bruttosozialprodukts: <code>PBSPJW</code></li>
<li>Preisindex des privaten Verbrauchs: <code>PCPJW</code></li>
<li>Kurzfristiger Zinssatz (nominal): <code>ZINSK</code></li>
<li>Langfristiger Zinssatz (real): <code>ZINSLR</code></li>
<li>Konjunkturphase: 1. Aufschwung, 2. Oberer Wendepunkt, 3. Abschwung,4. Unterer Wendepunkt: <code>PHASEN</code></li>
</ul>
<p>Variablen mit der Endung <em>JW</em> beziehen sich auf die jährliche Veränderung.</p>
</div>
<div id="regressionsbaume" class="section level3">
<h3><span class="header-section-number">6.3.2</span> Regressionsbäume</h3>
<p>Um einen Regressionsbaum zu erzeugen, muss zunächst das Zusatzpaket <code>rpart</code> geladen werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rpart)</code></pre></div>
<p>Um z. B. die Veränderung des Bruttosozialprodukt als Funktion von Privater Verbrauch, Investitionen in Ausrüstungsgüter, Investitionen in Bauten und Geldmenge M1 als Regressionsbaum zu modellieren reicht der Befehl</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regbaum &lt;-<span class="st"> </span><span class="kw">rpart</span>(BSP91JW ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>B3)</code></pre></div>
<p>Um das Ergebnis auszugeben genügt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regbaum
<span class="co">#&gt; n= 157 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; node), split, n, deviance, yval</span>
<span class="co">#&gt;       * denotes terminal node</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  1) root 157 1380.0  3.5000  </span>
<span class="co">#&gt;    2) CP91JW&lt; 3.71 79  380.0  1.5200  </span>
<span class="co">#&gt;      4) IAU91JW&lt; -0.365 38  120.0 -0.0379  </span>
<span class="co">#&gt;        8) IB91JW&lt; -2.22 20   45.1 -0.9020 *</span>
<span class="co">#&gt;        9) IB91JW&gt;=-2.22 18   43.9  0.9220 *</span>
<span class="co">#&gt;      5) IAU91JW&gt;=-0.365 41   81.6  2.9600  </span>
<span class="co">#&gt;       10) IB91JW&lt; 2.42 22   29.5  2.2100 *</span>
<span class="co">#&gt;       11) IB91JW&gt;=2.42 19   25.0  3.8400 *</span>
<span class="co">#&gt;    3) CP91JW&gt;=3.71 78  378.0  5.5000  </span>
<span class="co">#&gt;      6) IAU91JW&lt; 11.3 50  142.0  4.5700  </span>
<span class="co">#&gt;       12) IB91JW&lt; 3.2 22   40.0  3.5500 *</span>
<span class="co">#&gt;       13) IB91JW&gt;=3.2 28   61.3  5.3700 *</span>
<span class="co">#&gt;      7) IAU91JW&gt;=11.3 28  114.0  7.1700  </span>
<span class="co">#&gt;       14) IB91JW&lt; 7.55 17   51.2  6.2200 *</span>
<span class="co">#&gt;       15) IB91JW&gt;=7.55 11   23.7  8.6400 *</span></code></pre></div>
<p><em>Lesebeispiel:</em> Wenn CP91JW&gt;=3.705 und IAU91JW&gt;=11.335 und IB91JW&gt;=7.55 liegt, dann liegt die durchschnittliche Veränderung des BSP91JW bei 8.639. 11 Beobachtungen erfüllen die Kriterien der unabhängigen Variablen</p>
<p>Bzw. um den Baum zu zeichnen</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">xpd =</span> <span class="ot">TRUE</span>) <span class="co"># Grafikparameter der sicherstellt, dass alles ins Bild passt</span>
<span class="kw">plot</span>(regbaum, <span class="dt">compress =</span> <span class="ot">TRUE</span>) <span class="co"># Baum zeichnen</span>
<span class="kw">text</span>(regbaum) <span class="co"># Baum beschriften</span></code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-55-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Eine deutlich schönere Ausgabe erhält man z. B. mit dem Zusatzpaket <code>rpart.plot</code>, welches man <em>einmalig</em> über</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;rpart.plot&quot;</span>)</code></pre></div>
<p>installieren muss und dann benutzen kann.</p>
<p>Zunächst laden</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rpart.plot)</code></pre></div>
<p>und dann zeichnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rpart.plot</span>(regbaum)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-58-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div id="kreuzvalidierung" class="section level4">
<h4><span class="header-section-number">6.3.2.1</span> Kreuzvalidierung</h4>
<div id="anpassungsgute" class="section level5">
<h5><span class="header-section-number">6.3.2.1.1</span> Anpassungsgüte</h5>
<p>Wie gut ist das Modell? Über <code>predict</code> können die Punktprognosen berechnet werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">predict</span>(regbaum))
<span class="co">#&gt;    1    2    3    4    5    6 </span>
<span class="co">#&gt; 8.64 8.64 8.64 5.37 5.37 5.37</span></code></pre></div>
<p>Diese werden mit den beobachteten Werten verglichen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(B3$BSP91JW)
<span class="co">#&gt; [1] 10.53 10.60  9.21  5.17  4.93  8.39</span></code></pre></div>
<p>Der <strong>Mean Squared Error</strong> ist dann</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">baummse &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(regbaum) -<span class="st"> </span>B3$BSP91JW)^<span class="dv">2</span> )
baummse
<span class="co">#&gt; [1] 2.04</span></code></pre></div>
<p>Vergleichen wir das Ergebnis mit dem einer linearen Regression</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reglm &lt;-<span class="st"> </span><span class="kw">lm</span>(BSP91JW ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>B3)
<span class="kw">summary</span>(reglm)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = BSP91JW ~ CP91JW + IAU91JW + IB91JW + GM1JW, data = B3)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -3.048 -0.880 -0.057  0.801  3.674 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)  1.22442    0.26280    4.66  6.9e-06 ***</span>
<span class="co">#&gt; CP91JW       0.38729    0.05846    6.63  5.7e-10 ***</span>
<span class="co">#&gt; IAU91JW      0.12752    0.01634    7.80  9.0e-13 ***</span>
<span class="co">#&gt; IB91JW       0.13880    0.01719    8.08  1.9e-13 ***</span>
<span class="co">#&gt; GM1JW       -0.00996    0.02676   -0.37     0.71    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 1.37 on 152 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.792,  Adjusted R-squared:  0.786 </span>
<span class="co">#&gt; F-statistic:  145 on 4 and 152 DF,  p-value: &lt;2e-16</span></code></pre></div>
<p>Der MSE der Linearen Regression liegt bei</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmmse &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(reglm) -<span class="st"> </span>B3$BSP91JW)^<span class="dv">2</span> )
lmmse
<span class="co">#&gt; [1] 1.83</span></code></pre></div>
<p>Der Baum ist einfacher und weniger flexibel, aber auch schlechter im Bezug auf die Anpassungsgüte.</p>
</div>
<div id="prognosegute" class="section level5">
<h5><span class="header-section-number">6.3.2.1.2</span> Prognosegüte</h5>
<p>Für eine k=3 fache Kreuzvalidierung müssen 3 Testdatensätze erzeugt werden.</p>
<p>Zunächst wird dafür ein Aufteilungsvektor gebildet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aufteilung &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>:<span class="dv">3</span>, <span class="dt">length.out=</span><span class="kw">nrow</span>(B3))</code></pre></div>
<p>und dann wird aufgeteilt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test1 &lt;-<span class="st"> </span>B3[aufteilung==<span class="dv">1</span>,]
train1 &lt;-<span class="st"> </span>B3[aufteilung!=<span class="dv">1</span>,]

test2 &lt;-<span class="st"> </span>B3[aufteilung==<span class="dv">2</span>,]
train2 &lt;-<span class="st"> </span>B3[aufteilung!=<span class="dv">2</span>,]

test3 &lt;-<span class="st"> </span>B3[aufteilung==<span class="dv">3</span>,]
train3 &lt;-<span class="st"> </span>B3[aufteilung!=<span class="dv">3</span>,]</code></pre></div>
<p>Anschließend werden die Modelle auf den Trainingsdaten geschätzt, und auf den Testdaten überprüft:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Runde 1</span>
b1 &lt;-<span class="st"> </span><span class="kw">rpart</span>(BSP91JW ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train1)
l1 &lt;-<span class="st"> </span><span class="kw">lm</span>(BSP91JW ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train1)
mseb1 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(b1, <span class="dt">newdata =</span> test1) -<span class="st"> </span>test1$BSP91JW)^<span class="dv">2</span> )
msel1 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(l1, <span class="dt">newdata =</span> test1) -<span class="st"> </span>test1$BSP91JW)^<span class="dv">2</span> )

<span class="co"># Runde 2</span>
b2 &lt;-<span class="st"> </span><span class="kw">rpart</span>(BSP91JW ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train2)
l2 &lt;-<span class="st"> </span><span class="kw">lm</span>(BSP91JW ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train2)
mseb2 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(b2, <span class="dt">newdata =</span> test2) -<span class="st"> </span>test2$BSP91JW)^<span class="dv">2</span> )
msel2 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(l2, <span class="dt">newdata =</span> test2) -<span class="st"> </span>test2$BSP91JW)^<span class="dv">2</span> )

<span class="co"># Runde 3</span>
b3 &lt;-<span class="st"> </span><span class="kw">rpart</span>(BSP91JW ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train3)
l3 &lt;-<span class="st"> </span><span class="kw">lm</span>(BSP91JW ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train3)
mseb3 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(b3, <span class="dt">newdata =</span> test3) -<span class="st"> </span>test3$BSP91JW)^<span class="dv">2</span> )
msel3 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(l3, <span class="dt">newdata =</span> test3) -<span class="st"> </span>test3$BSP91JW)^<span class="dv">2</span> )

<span class="co"># Ergebnisse zusammenfassen</span>
msecvb &lt;-<span class="st"> </span><span class="kw">c</span>(mseb1, mseb2, mseb3)
msecvl &lt;-<span class="st"> </span><span class="kw">c</span>(msel1, msel2, msel3)

<span class="co"># Mittelwert des Prognose MSE</span>
<span class="kw">mean</span>(msecvb)
<span class="co">#&gt; [1] 3.62</span>
<span class="kw">mean</span>(msecvl)
<span class="co">#&gt; [1] 1.99</span></code></pre></div>
<p>Bei den vorliegenden Daten ist also ein <em>lineares</em> Modell dem Baummodell im Bezug auf den <em>MSE</em> überlegen.</p>
<p><strong>Hinweis:</strong> In der Praxis führt man die Aufteilung nicht manuell sondern innerhalb von Schleifen durch.</p>
</div>
</div>
</div>
<div id="klassifikationbaume" class="section level3">
<h3><span class="header-section-number">6.3.3</span> Klassifikationbäume</h3>
<p>Untersuchen wir, ob makroökonomische Kennzahlen geeignet sind, die Konjunkturphasen zu unterscheiden. Zunächst stellen wir fest, dass die eigentlich kategorielle Variable <code>PHASEN</code> hier numerisch kodiert wurde, was aber schnell verwirren würde.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">typeof</span>(B3$PHASEN)
<span class="co">#&gt; [1] &quot;integer&quot;</span></code></pre></div>
<p>Typänderung zu <code>factor</code> geht einfach:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B3$PHASEN &lt;-<span class="st"> </span><span class="kw">as.factor</span>(B3$PHASEN)</code></pre></div>
<p>Wenn wir die einzelnen <code>levels</code> des Faktors als numerische Werte verwenden wollen würde man den Befehl <code>as.numeric()</code> verwenden. Aber sicherheitshalber vorher über <code>levels()</code> gucken, ob die Reihenfolge auch stimmt.</p>
<p>Um die Interpretation zu erleichtern können wir hier einfach die Faktorstufe umbenennen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">levels</span>(B3$PHASEN) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Aufschwung&quot;</span>, <span class="st">&quot;Oberer Wendepunkt&quot;</span>, 
                       <span class="st">&quot;Abschwung&quot;</span>, <span class="st">&quot;Unterer Wendepunkt&quot;</span>)</code></pre></div>
<p>Um z. B. die Konjunkturphase als Funktion von Privater Verbrauch, Investitionen in Ausrüstungsgüter, Investitionen in Bauten und Geldmenge M1 als Regressionsbaum zu modellieren reicht jetzt der Befehl</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">klassbaum &lt;-<span class="st"> </span><span class="kw">rpart</span>(PHASEN ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>B3)</code></pre></div>
<p>Um das Ergebnis auszugeben genügt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">klassbaum
<span class="co">#&gt; n= 157 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; node), split, n, loss, yval, (yprob)</span>
<span class="co">#&gt;       * denotes terminal node</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  1) root 157 98 Aufschwung (0.3758 0.1529 0.2994 0.1720)  </span>
<span class="co">#&gt;    2) IAU91JW&gt;=-0.09 109 55 Aufschwung (0.4954 0.2110 0.2110 0.0826)  </span>
<span class="co">#&gt;      4) CP91JW&lt; 5.19 68 20 Aufschwung (0.7059 0.1029 0.1324 0.0588)  </span>
<span class="co">#&gt;        8) IB91JW&gt;=3.32 29  7 Aufschwung (0.7586 0.2069 0.0345 0.0000) *</span>
<span class="co">#&gt;        9) IB91JW&lt; 3.32 39 13 Aufschwung (0.6667 0.0256 0.2051 0.1026)  </span>
<span class="co">#&gt;         18) GM1JW&lt; 11 32  7 Aufschwung (0.7813 0.0312 0.1250 0.0625)  </span>
<span class="co">#&gt;           36) IAU91JW&gt;=3.25 25  3 Aufschwung (0.8800 0.0400 0.0000 0.0800) *</span>
<span class="co">#&gt;           37) IAU91JW&lt; 3.25 7  3 Abschwung (0.4286 0.0000 0.5714 0.0000) *</span>
<span class="co">#&gt;         19) GM1JW&gt;=11 7  3 Abschwung (0.1429 0.0000 0.5714 0.2857) *</span>
<span class="co">#&gt;      5) CP91JW&gt;=5.19 41 25 Oberer Wendepunkt (0.1463 0.3902 0.3415 0.1220)  </span>
<span class="co">#&gt;       10) IAU91JW&gt;=7.49 31 15 Oberer Wendepunkt (0.1613 0.5161 0.2581 0.0645)  </span>
<span class="co">#&gt;         20) CP91JW&gt;=7.69 10  2 Oberer Wendepunkt (0.1000 0.8000 0.1000 0.0000) *</span>
<span class="co">#&gt;         21) CP91JW&lt; 7.69 21 13 Oberer Wendepunkt (0.1905 0.3810 0.3333 0.0952)  </span>
<span class="co">#&gt;           42) CP91JW&lt; 6.2 8  3 Oberer Wendepunkt (0.2500 0.6250 0.1250 0.0000) *</span>
<span class="co">#&gt;           43) CP91JW&gt;=6.2 13  7 Abschwung (0.1538 0.2308 0.4615 0.1538) *</span>
<span class="co">#&gt;       11) IAU91JW&lt; 7.49 10  4 Abschwung (0.1000 0.0000 0.6000 0.3000) *</span>
<span class="co">#&gt;    3) IAU91JW&lt; -0.09 48 24 Abschwung (0.1042 0.0208 0.5000 0.3750)  </span>
<span class="co">#&gt;      6) GM1JW&lt; 11.4 38 14 Abschwung (0.0789 0.0000 0.6316 0.2895)  </span>
<span class="co">#&gt;       12) IB91JW&gt;=-4.08 23  5 Abschwung (0.1304 0.0000 0.7826 0.0870) *</span>
<span class="co">#&gt;       13) IB91JW&lt; -4.08 15  6 Unterer Wendepunkt (0.0000 0.0000 0.4000 0.6000) *</span>
<span class="co">#&gt;      7) GM1JW&gt;=11.4 10  3 Unterer Wendepunkt (0.2000 0.1000 0.0000 0.7000) *</span></code></pre></div>
<p><em>Lesebeispiel:</em> Wenn IAU91JW&lt; -0.09 und GM1JW&gt;=11.355 liegt, dann ist der Untere Wendepunkt die häufigste Merkmalsausprägung von PHASEN (relative Häufigkeit von PHASEN=4 hier: 0.7) 10 Beobachtungen erfüllen die Kriterien der unabhängigen Variablen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">xpd =</span> <span class="ot">TRUE</span>) <span class="co"># Grafikparameter der sicherstellt, dass alles ins Bild passt</span>
<span class="kw">plot</span>(klassbaum, <span class="dt">compress =</span> <span class="ot">TRUE</span>) <span class="co"># Baum zeichnen</span>
<span class="kw">text</span>(klassbaum) <span class="co"># Baum beschriften</span></code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-72-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Bzw. “schöner”:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rpart.plot</span>(klassbaum)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-73-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div id="kreuzvalidierung-1" class="section level4">
<h4><span class="header-section-number">6.3.3.1</span> Kreuzvalidierung</h4>
<p>Wie gut ist das Modell? Auch hier können über <code>predict</code> die Punktprognosen bestimmt werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">predict</span>(klassbaum, <span class="dt">type=</span><span class="st">&quot;class&quot;</span>))
<span class="co">#&gt;                 1                 2                 3                 4 </span>
<span class="co">#&gt; Oberer Wendepunkt Oberer Wendepunkt         Abschwung         Abschwung </span>
<span class="co">#&gt;                 5                 6 </span>
<span class="co">#&gt;         Abschwung         Abschwung </span>
<span class="co">#&gt; Levels: Aufschwung Oberer Wendepunkt Abschwung Unterer Wendepunkt</span></code></pre></div>
<p>Diese werden mit den beobachteten Werten verglichen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(B3$PHASEN)
<span class="co">#&gt; [1] Oberer Wendepunkt Oberer Wendepunkt Abschwung         Abschwung        </span>
<span class="co">#&gt; [5] Abschwung         Abschwung        </span>
<span class="co">#&gt; Levels: Aufschwung Oberer Wendepunkt Abschwung Unterer Wendepunkt</span></code></pre></div>
<p>Die <strong>Fehlklassifikationsrate</strong> ist dann</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">baumer &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(klassbaum, <span class="dt">type=</span><span class="st">&quot;class&quot;</span>) !=<span class="st"> </span>B3$PHASEN) )
baumer
<span class="co">#&gt; [1] 0.293</span></code></pre></div>
<p>also knapp 30%.</p>
<p>Vergleichen kann man den Klassifikationsbaum z. B. mit der <em>Linearen Diskriminanzanalyse</em>. Diese ist im Paket <code>MASS</code> implementiert.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">klasslda &lt;-<span class="st"> </span><span class="kw">lda</span>(PHASEN ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>B3)
klasslda
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lda(PHASEN ~ CP91JW + IAU91JW + IB91JW + GM1JW, data = B3)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Prior probabilities of groups:</span>
<span class="co">#&gt;         Aufschwung  Oberer Wendepunkt          Abschwung </span>
<span class="co">#&gt;              0.376              0.153              0.299 </span>
<span class="co">#&gt; Unterer Wendepunkt </span>
<span class="co">#&gt;              0.172 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Group means:</span>
<span class="co">#&gt;                    CP91JW IAU91JW IB91JW GM1JW</span>
<span class="co">#&gt; Aufschwung           3.55  6.8936   3.40  8.61</span>
<span class="co">#&gt; Oberer Wendepunkt    6.43 11.3604   6.83 11.02</span>
<span class="co">#&gt; Abschwung            3.66 -0.0034   1.67  6.84</span>
<span class="co">#&gt; Unterer Wendepunkt   2.62 -1.9393  -1.49  9.61</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients of linear discriminants:</span>
<span class="co">#&gt;             LD1      LD2     LD3</span>
<span class="co">#&gt; CP91JW   0.1583 -0.52094  0.0758</span>
<span class="co">#&gt; IAU91JW -0.1409  0.06865 -0.0275</span>
<span class="co">#&gt; IB91JW  -0.0478  0.00242 -0.0457</span>
<span class="co">#&gt; GM1JW   -0.0203  0.08559  0.2245</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Proportion of trace:</span>
<span class="co">#&gt;   LD1   LD2   LD3 </span>
<span class="co">#&gt; 0.645 0.230 0.125</span>

ldaer &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(klasslda)$class !=<span class="st"> </span>B3$PHASEN) )
ldaer
<span class="co">#&gt; [1] 0.414</span></code></pre></div>
<p>Im Bezug auf die <em>Klassifikation</em> scheint der Baum in der Anpassungsgüte besser als die Lineare Diskriminanzanalyse zu sein. Aber wie sieht es kreuzvalidiert, d. h. in der Prognose aus?</p>
<p>Zunächst wird wieder dafür ein Aufteilungsvektor gebildet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aufteilung &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>:<span class="dv">3</span>, <span class="dt">length.out=</span><span class="kw">nrow</span>(B3))</code></pre></div>
<p>und dann wird aufgeteilt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test1 &lt;-<span class="st"> </span>B3[aufteilung==<span class="dv">1</span>,]
train1 &lt;-<span class="st"> </span>B3[aufteilung!=<span class="dv">1</span>,]

test2 &lt;-<span class="st"> </span>B3[aufteilung==<span class="dv">2</span>,]
train2 &lt;-<span class="st"> </span>B3[aufteilung!=<span class="dv">2</span>,]

test3 &lt;-<span class="st"> </span>B3[aufteilung==<span class="dv">3</span>,]
train3 &lt;-<span class="st"> </span>B3[aufteilung!=<span class="dv">3</span>,]</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Runde 1</span>
b1 &lt;-<span class="st"> </span><span class="kw">rpart</span>(PHASEN  ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train1)
l1 &lt;-<span class="st"> </span><span class="kw">lda</span>(PHASEN ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train1)
erb1 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(b1, <span class="dt">newdata =</span> test1, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>) !=<span class="st"> </span>test1$PHASEN) )
erl1 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(l1, <span class="dt">newdata =</span> test1)$class  !=<span class="st"> </span>test1$PHASEN) )

<span class="co"># Runde 2</span>
b2 &lt;-<span class="st"> </span><span class="kw">rpart</span>(PHASEN  ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train2)
l2 &lt;-<span class="st"> </span><span class="kw">lda</span>(PHASEN ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train2)
erb2 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(b2, <span class="dt">newdata =</span> test2, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>) !=<span class="st"> </span>test2$PHASEN) )
erl2 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(l2, <span class="dt">newdata =</span> test2)$class  !=<span class="st"> </span>test2$PHASEN) )

<span class="co"># Runde 3</span>
b3 &lt;-<span class="st"> </span><span class="kw">rpart</span>(PHASEN  ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train3)
l3 &lt;-<span class="st"> </span><span class="kw">lda</span>(PHASEN ~<span class="st"> </span>CP91JW +<span class="st"> </span>IAU91JW +<span class="st"> </span>IB91JW +<span class="st"> </span>GM1JW, <span class="dt">data=</span>train3)
erb3 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(b3, <span class="dt">newdata =</span> test3, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>) !=<span class="st"> </span>test3$PHASEN) )
erl3 &lt;-<span class="st"> </span><span class="kw">mean</span>( (<span class="kw">predict</span>(l3, <span class="dt">newdata =</span> test3)$class  !=<span class="st"> </span>test3$PHASEN) )

<span class="co"># Ergebnisse zusammenfassen</span>
ercvb &lt;-<span class="st"> </span><span class="kw">c</span>(erb1, erb2, erb3)
ercvl &lt;-<span class="st"> </span><span class="kw">c</span>(erl1, erl2, erl3)

<span class="co"># Mittelwert des Prognose MSE</span>
<span class="kw">mean</span>(ercvb)
<span class="co">#&gt; [1] 0.49</span>
<span class="kw">mean</span>(ercvl)
<span class="co">#&gt; [1] 0.44</span></code></pre></div>
<p>In der <em>Prognosegüte</em> ist hier – anders als in der Anpassungsgüte – die Lineare Diskriminanzanalyse besser.</p>
</div>
</div>
<div id="parameter-rpart" class="section level3">
<h3><span class="header-section-number">6.3.4</span> Parameter <code>rpart</code></h3>
<p>Neben dem Splitkrierium können verschiedene Parameter des Algorithmus eingestellt werden (siehe <code>?rpart.control</code>), u. a.:</p>
<ul>
<li>minsplit: Minimale Anzahl Beobachtungen im Knoten damit Aufteilung versucht wird</li>
<li>minbucket: Minimale Anzahl Beobachtungen im Blatt</li>
<li>cp: Komplexitätsparameter (pruning)</li>
<li>xval: Anzahl Kreuzvaliderungen (pruning)</li>
<li>maxdepth: Maximale Tiefe eines Blattes</li>
</ul>
<p>Diese können mit der Funktion <code>train</code> aus dem Paket <a href="https://topepo.github.io/caret/index.html"><code>caret</code></a> automatisch optimiert werden.</p>
<p>Alternativen/ Ergänzungen zu <code>rpart</code>:</p>
<ul>
<li><a href="https://cran.r-project.org/web/packages/tree/"><code>tree</code></a></li>
<li><a href="http://partykit.r-forge.r-project.org/partykit/"><code>partykit</code></a></li>
<li>Erweiterung: Viele Bäume: <a href="https://cran.r-project.org/web/packages/randomForest/"><code>randomForest</code></a></li>
</ul>
</div>
</div>
<div id="ausblick" class="section level2">
<h2><span class="header-section-number">6.4</span> Ausblick</h2>
</div>
<div id="fallstudie-uberleben-auf-der-titanic" class="section level2">
<h2><span class="header-section-number">6.5</span> Fallstudie: Überleben auf der Titanic</h2>
<p>In dieser YACSDA (Yet-another-case-study-on-data-analysis) geht es um die beispielhafte Analyse nominaler Daten anhand des “klassischen” Falls zum Untergang der Titanic. Eine Frage, die sich hier aufdrängt, lautet: Kann (konnte) man sich vom Tod freikaufen, etwas polemisch formuliert. Oder neutraler: Hängt die Überlebensquote von der Klasse, in der derPassagiers reist, ab?</p>
<div id="daten-und-pakete-laden" class="section level3">
<h3><span class="header-section-number">6.5.1</span> Daten und Pakete laden</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;titanic&quot;)</span>
<span class="kw">library</span>(<span class="st">&quot;titanic&quot;</span>)
<span class="kw">data</span>(titanic_train)</code></pre></div>
<p>Man beachte, dass ein Paket nur <em>einmalig</em> zu installieren ist (wie jede Software). Dann aber muss das Paket bei jedem Starten von R wieder von neuem gestartet werden. Außerdem ist es wichtig zu wissen, dass das Laden eines Pakets nicht automatisch die Datensätze aus dem Paket lädt. Man muss das oder die gewünschten Pakete selber (mit <code>data(...)</code>) laden. Und: Der Name eines Pakets (z.B. <code>titanic</code>) muss nicht identisch sein mit dem oder den Datensätzen des Pakets (z.B. <code>titanic_train</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)</code></pre></div>
</div>
<div id="erster-blick" class="section level3">
<h3><span class="header-section-number">6.5.2</span> Erster Blick</h3>
<p>Werfen wir einen ersten Blick in die Daten:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;dplyr&quot;, dependencies = TRUE) # ggf. vorher installieren</span>
<span class="kw">glimpse</span>(titanic_train)
<span class="co">#&gt; Observations: 891</span>
<span class="co">#&gt; Variables: 12</span>
<span class="co">#&gt; $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,...</span>
<span class="co">#&gt; $ Survived    &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,...</span>
<span class="co">#&gt; $ Pclass      &lt;int&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3,...</span>
<span class="co">#&gt; $ Name        &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bra...</span>
<span class="co">#&gt; $ Sex         &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;mal...</span>
<span class="co">#&gt; $ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, ...</span>
<span class="co">#&gt; $ SibSp       &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4,...</span>
<span class="co">#&gt; $ Parch       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1,...</span>
<span class="co">#&gt; $ Ticket      &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;1138...</span>
<span class="co">#&gt; $ Fare        &lt;dbl&gt; 7.25, 71.28, 7.92, 53.10, 8.05, 8.46, 51.86, 21.07...</span>
<span class="co">#&gt; $ Cabin       &lt;chr&gt; &quot;&quot;, &quot;C85&quot;, &quot;&quot;, &quot;C123&quot;, &quot;&quot;, &quot;&quot;, &quot;E46&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, ...</span>
<span class="co">#&gt; $ Embarked    &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;Q&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, ...</span></code></pre></div>
</div>
<div id="welche-variablen-sind-interessant" class="section level3">
<h3><span class="header-section-number">6.5.3</span> Welche Variablen sind interessant?</h3>
<p>Von 12 Variablen des Datensatzes interessieren uns offenbar <code>Pclass</code> und <code>Survived</code>; Hilfe zum Datensatz kann man übrigens mit <code>help(titanic_train)</code> bekommen. Diese beiden Variablen sind kategorial (nicht-metrisch), wobei sie in der Tabelle mit Zahlen kodiert sind. Natürlich ändert die Art der Codierung (hier als Zahl) nichts am eigentlichen Skalenniveau. Genauso könnte man “Mann” mit <code>1</code> und “Frau” mit <code>2</code> kodieren; ein Mittelwert bliebe genauso (wenig) aussagekräftig. Zu beachten ist hier nur, dass sich manche R-Befehle verunsichern lassen, wenn nominale Variablen mit Zahlen kodiert sind. Daher ist es oft besser, nominale Variablen mit Text-Werten zu benennen (wie “survived” vs. “drowned” etc.). Wir kommen später auf diesen Punkt zurück.</p>
</div>
<div id="univariate-haufigkeiten" class="section level3">
<h3><span class="header-section-number">6.5.4</span> Univariate Häufigkeiten</h3>
<p>Bevor wir uns in kompliziertere Fragestellungen stürzen, halten wir fest: Wir untersuchen zwei nominale Variablen. Sprich: wir werden Häufigkeiten auszählen. Häufigkeiten (und relative Häufigkeiten, also Anteile oder Quoten) sind das, was uns hier beschäftigt.</p>
<p>Zählen wir zuerst die univariaten Häufigkeiten aus: Wie viele Passagiere gab es pro Klasse? Wie viele Passagiere gab es pro Wert von <code>Survived</code> (also die überlebten bzw. nicht überlebten)?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c1 &lt;-<span class="st"> </span>dplyr::<span class="kw">count</span>(titanic_train, Pclass)
c1
<span class="co">#&gt; # A tibble: 3 × 2</span>
<span class="co">#&gt;   Pclass     n</span>
<span class="co">#&gt;    &lt;int&gt; &lt;int&gt;</span>
<span class="co">#&gt; 1      1   216</span>
<span class="co">#&gt; 2      2   184</span>
<span class="co">#&gt; 3      3   491</span></code></pre></div>

<div class="rmdcaution">
<p>Achtung - Namenskollision! Sowohl im Paket <code>mosaic</code> als auch im Paket <code>dplyr</code> gibt es einen Befehl <code>count</code>. Für <code>select</code> gilt das gleiche. Das arme R weiß nicht, welchen von beiden wir meinen und entscheidet sich im Zweifel für den falschen. Da hilft, zu sagen, aus welchem Paket wir den Befehl beziehen wollen. Das macht der Operator <code>::</code>.</p>
</div>
<p></p>
<p>Aha. Zur besseren Anschaulichkeit können wir das auch plotten (ein Diagramm dazu malen).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;ggplot2&quot;, dependencies = TRUE)</span>
<span class="kw">library</span>(ggplot2)
<span class="kw">qplot</span>(<span class="dt">x =</span> Pclass, <span class="dt">y =</span> n, <span class="dt">data =</span> c1)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-86-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Der Befehl <code>qplot</code> zeichnet automatisch Punkte, wenn auf beiden Achsen “Zahlen-Variablen” stehen (also Variablen, die keinen “Text”, sondern nur Zahlen beinhalten. In R sind das Variablen vom Typ <code>int</code> (integer), also Ganze Zahlen oder vom Typ <code>num</code> (numeric), also reelle Zahlen).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
c2 &lt;-<span class="st"> </span>dplyr::<span class="kw">count</span>(titanic_train, Survived)
c2
<span class="co">#&gt; # A tibble: 2 × 2</span>
<span class="co">#&gt;   Survived     n</span>
<span class="co">#&gt;      &lt;int&gt; &lt;int&gt;</span>
<span class="co">#&gt; 1        0   549</span>
<span class="co">#&gt; 2        1   342</span></code></pre></div>
<p>Man beachte, dass der Befehl <code>count</code> stehts eine Tabelle (data.frame bzw. <code>tibble</code>) verlangt und zurückliefert.</p>
</div>
<div id="bivariate-haufigkeiten" class="section level3">
<h3><span class="header-section-number">6.5.5</span> Bivariate Häufigkeiten</h3>
<p>OK, gut. Jetzt wissen wir die Häufigkeiten pro Wert von <code>Survived</code> (dasselbe gilt für <code>Pclass</code>). Eigentlich interessiert uns aber die Frage, ob sich die relativen Häufigkeiten der Stufen von <code>Pclass</code> innerhalb der Stufen von <code>Survived</code> unterscheiden. Einfacher gesagt: Ist der Anteil der Überlebenden in der 1. Klasse größer als in der 3. Klasse?</p>
<p>Zählen wir zuerst die Häufigkeiten für alle Kombinationen von <code>Survived</code> und <code>Pclass</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c3 &lt;-<span class="st"> </span>dplyr::<span class="kw">count</span>(titanic_train, Survived, Pclass)
c3
<span class="co">#&gt; Source: local data frame [6 x 3]</span>
<span class="co">#&gt; Groups: Survived [?]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   Survived Pclass     n</span>
<span class="co">#&gt;      &lt;int&gt;  &lt;int&gt; &lt;int&gt;</span>
<span class="co">#&gt; 1        0      1    80</span>
<span class="co">#&gt; 2        0      2    97</span>
<span class="co">#&gt; 3        0      3   372</span>
<span class="co">#&gt; 4        1      1   136</span>
<span class="co">#&gt; 5        1      2    87</span>
<span class="co">#&gt; 6        1      3   119</span></code></pre></div>
<p>Da <code>Pclass</code> 3 Stufen hat (1., 2. und 3. Klasse) und innerhalb jeder dieser 3 Klassen es die Gruppe der Überlebenden und der Nicht-Überlebenden gibt, haben wir insgesamt 3*2=6 Gruppen.</p>
<p>Es ist hilfreich, sich diese Häufigkeiten wiederum zu plotten; wir nehmen den gleichen Befehl wie oben.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(<span class="dt">x =</span> Pclass, <span class="dt">y =</span> n, <span class="dt">data =</span> c3)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-89-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Hm, nicht so hilfreich. Schöner wäre, wenn wir (farblich) erkennen könnten, welcher Punkt für “Überlebt” und welcher Punkt für “Nicht-Überlebt” steht. Mit <code>qplot</code> geht das recht einfach: Wir sagen der Funktion <code>qplot</code>, dass die Farbe (<code>color</code>) der Punkte den Stufen von <code>Survived</code> zugeordnet werden sollen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(<span class="dt">x =</span> Pclass, <span class="dt">y =</span> n, <span class="dt">color =</span> Survived, <span class="dt">data =</span> c3)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-90-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Viel besser. Was noch stört, ist, dass <code>Survived</code> als metrische Variable verstanden wird. Das Farbschema lässt Nuancen, feine Farbschattierungen, zu. Für nominale Variablen macht das keinen Sinn; es gibt da keine Zwischentöne. Tot ist tot, lebendig ist lebendig. Wir sollten daher der Funktion sagen, dass es sich um nominale Variablen handelt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(<span class="dt">x =</span> <span class="kw">factor</span>(Pclass), <span class="dt">y =</span> n, <span class="dt">color =</span> <span class="kw">factor</span>(Survived), <span class="dt">data =</span> c3)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-91-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Viel besser. Jetzt noch ein bisschen Schnickschnack:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(<span class="dt">x =</span> <span class="kw">factor</span>(Pclass), <span class="dt">y =</span> n, <span class="dt">color =</span> <span class="kw">factor</span>(Survived), <span class="dt">data =</span> c3) +<span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Klasse&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Überleben auf der Titanic&quot;</span>,
       <span class="dt">colour =</span> <span class="st">&quot;Überlebt?&quot;</span>)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-92-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="signifikanztest" class="section level3">
<h3><span class="header-section-number">6.5.6</span> Signifikanztest</h3>
<p>Manche Leute mögen Signifikanztests. Ich persönlich stehe ihnen kritisch gegenüber, da ein p-Wert eine Funktion der Stichprobengröße ist und außerdem zumeist missverstanden wird (er gibt <em>nicht</em> die Wahrscheinlichkeit der getesteten Hypothese an, was die Frage aufwirft, warum er mich dann interessieren sollte). Aber seisdrum, berechnen wir mal einen p-Wert. Es gibt mehrere statistische Tests, die sich hier potenziell anböten (was die Frage nach der Objektivität von statistischen Tests in ein ungünstiges Licht rückt). Nehmen wir den <span class="math inline">\(\chi^2\)</span>-Test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(titanic_train$Survived, titanic_train$Pclass)
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pearson&#39;s Chi-squared test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  titanic_train$Survived and titanic_train$Pclass</span>
<span class="co">#&gt; X-squared = 100, df = 2, p-value &lt;2e-16</span></code></pre></div>
<p>Der p-Wert ist kleiner als 5%, daher entscheiden wir uns, entsprechend der üblichen Gepflogenheit, gegen die H0 und für die H1: “Es gibt einen Zusammenhang von Überlebensrate und Passagierklasse”.</p>
</div>
<div id="effektstarke" class="section level3">
<h3><span class="header-section-number">6.5.7</span> Effektstärke</h3>
<p>Abgesehen von der Signifikanz, und interessanter, ist die Frage, wie sehr die Variablen zusammenhängen. Für Häufigkeitsanalysen mit 2*2-Feldern bietet sich das “Odds Ratio” (OR), das Chancenverhältnis an. Das Chancen-Verhältnis beantwortet die Frage: “Um welchen Faktor ist die Überlebenschance in der einen Klasse größer als in der anderen Klasse?”. Eine interessante Frage, als schauen wir es uns an.</p>
<p>Das OR ist nur definiert für 2*2-Häufigkeitstabellen, daher müssen wir die Anzahl der Passagierklassen von 3 auf 2 verringern. Nehmen wir nur 1. und 3. Klasse, um den vermuteten Effekt deutlich herauszuschälen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t2 &lt;-<span class="st"> </span><span class="kw">filter</span>(titanic_train, Pclass !=<span class="st"> </span><span class="dv">2</span>)  <span class="co"># &quot;!=&quot; heißt &quot;nicht&quot;</span></code></pre></div>
<p>Alternativ (synonym) könnten wir auch schreiben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t2 &lt;-<span class="st"> </span><span class="kw">filter</span>(titanic_train, Pclass ==<span class="st"> </span><span class="dv">1</span> |<span class="st"> </span>Pclass ==<span class="st"> </span><span class="dv">3</span>)  <span class="co"># &quot;|&quot; heißt &quot;oder&quot;</span></code></pre></div>
<p>Und dann zählen wir wieder die Häufigkeiten aus pro Gruppe:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c4 &lt;-<span class="st"> </span>dplyr::<span class="kw">count</span>(t2, Pclass)
c4
<span class="co">#&gt; # A tibble: 2 × 2</span>
<span class="co">#&gt;   Pclass     n</span>
<span class="co">#&gt;    &lt;int&gt; &lt;int&gt;</span>
<span class="co">#&gt; 1      1   216</span>
<span class="co">#&gt; 2      3   491</span></code></pre></div>
<p>Schauen wir nochmal den p-Wert an, da wir jetzt ja mit einer veränderten Datentabelle operieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(t2$Survived, t2$Pclass)
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  t2$Survived and t2$Pclass</span>
<span class="co">#&gt; X-squared = 100, df = 1, p-value &lt;2e-16</span></code></pre></div>
<p>Ein <span class="math inline">\(\chi^2\)</span>-Wert von ~96 bei einem <em>n</em> von 707.</p>
<p>Dann berechnen wir die Effektstärke (OR) mit dem Paket <code>compute.es</code> (muss ebenfalls installiert sein).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">library</span>(compute.es)
<span class="kw">chies</span>(<span class="dt">chi.sq =</span> <span class="dv">96</span>, <span class="dt">n =</span> <span class="dv">707</span>)
<span class="co">#&gt; Mean Differences ES: </span>
<span class="co">#&gt;  </span>
<span class="co">#&gt;  d [ 95 %CI] = 0.79 [ 0.63 , 0.95 ] </span>
<span class="co">#&gt;   var(d) = 0.01 </span>
<span class="co">#&gt;   p-value(d) = 0 </span>
<span class="co">#&gt;   U3(d) = 78.6 % </span>
<span class="co">#&gt;   CLES(d) = 71.2 % </span>
<span class="co">#&gt;   Cliff&#39;s Delta = 0.42 </span>
<span class="co">#&gt;  </span>
<span class="co">#&gt;  g [ 95 %CI] = 0.79 [ 0.63 , 0.95 ] </span>
<span class="co">#&gt;   var(g) = 0.01 </span>
<span class="co">#&gt;   p-value(g) = 0 </span>
<span class="co">#&gt;   U3(g) = 78.6 % </span>
<span class="co">#&gt;   CLES(g) = 71.2 % </span>
<span class="co">#&gt;  </span>
<span class="co">#&gt;  Correlation ES: </span>
<span class="co">#&gt;  </span>
<span class="co">#&gt;  r [ 95 %CI] = 0.37 [ 0.3 , 0.43 ] </span>
<span class="co">#&gt;   var(r) = 0 </span>
<span class="co">#&gt;   p-value(r) = 0 </span>
<span class="co">#&gt;  </span>
<span class="co">#&gt;  z [ 95 %CI] = 0.39 [ 0.31 , 0.46 ] </span>
<span class="co">#&gt;   var(z) = 0 </span>
<span class="co">#&gt;   p-value(z) = 0 </span>
<span class="co">#&gt;  </span>
<span class="co">#&gt;  Odds Ratio ES: </span>
<span class="co">#&gt;  </span>
<span class="co">#&gt;  OR [ 95 %CI] = 4.21 [ 3.15 , 5.61 ] </span>
<span class="co">#&gt;   p-value(OR) = 0 </span>
<span class="co">#&gt;  </span>
<span class="co">#&gt;  Log OR [ 95 %CI] = 1.44 [ 1.15 , 1.73 ] </span>
<span class="co">#&gt;   var(lOR) = 0.02 </span>
<span class="co">#&gt;   p-value(Log OR) = 0 </span>
<span class="co">#&gt;  </span>
<span class="co">#&gt;  Other: </span>
<span class="co">#&gt;  </span>
<span class="co">#&gt;  NNT = 3.57 </span>
<span class="co">#&gt;  Total N = 707</span></code></pre></div>
<p>Die Chance zu überleben ist also in der 1. Klasse mehr als 4 mal so hoch wie in der 3. Klasse. Es scheint: Money buys you live…</p>
</div>
<div id="logististische-regression" class="section level3">
<h3><span class="header-section-number">6.5.8</span> Logististische Regression</h3>
<p>Berechnen wir noch das Odds Ratio mit Hilfe der logistischen Regression. Zum Einstieg: Ignorieren Sie die folgende Syntax und schauen Sie sich das Diagramm an. Hier sehen wir die (geschätzten) Überlebens-Wahrscheinlichkeiten für Passagiere der 1. Klasse vs. Passagiere der 3. Klasse.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic2 &lt;-<span class="st"> </span>titanic_train %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(Pclass %in%<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Pclass =</span> <span class="kw">factor</span>(Pclass))

glm1 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">data =</span> titanic2, 
            <span class="dt">formula =</span> Survived ~<span class="st"> </span>Pclass, 
            <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)

<span class="kw">exp</span>(<span class="kw">coef</span>(glm1))
<span class="co">#&gt; (Intercept)     Pclass3 </span>
<span class="co">#&gt;       1.700       0.188</span>

titanic2$pred_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(glm1, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-100-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Wir sehen, dass die Überlebens-Wahrscheinlichkeit in der 1. Klasse höher ist als in der 3. Klasse. Optisch grob geschätzt, ~60% in der 1. Klasse und ~25% in der 3. Klasse.</p>
<p>Schauen wir uns die logistische Regression an: Zuerst haben wir den Datensatz auf die Zeilen beschränkt, in denen Personen aus der 1. und 3. Klasse vermerkt sind (zwecks Vergleichbarkeit zu oben). Dann haben wir mit <code>glm</code> und <code>family = &quot;binomial&quot;</code> eine <em>logistische</em> Regression angefordert. Man beachte, dass der Befehl sehr ähnlich zur normalen Regression (<code>lm(...)</code>) ist.</p>
<p>Da die Koeffizienten in der Logit-Form zurückgegeben werden, haben wir sie mit der Exponential-Funktion in die “normale” Odds-Form gebracht (delogarithmiert, boa). Wir sehen, dass die Überlebens-<em>Chance</em> (Odds) 1.7 zu 1 betrug - bei der <em>ersten</em> Stufe von <code>Pclass</code> (<code>1</code>)<a href="#fn36" class="footnoteRef" id="fnref36"><sup>36</sup></a>; von 27 Menschen überlebten in dieser Gruppe also 17 (17/27 = .63 Überlebens-<em>Wahrscheinlichkeit</em>); s. <code>Intercept</code>; der Achsenabschnitt gibt den Odds an, wenn die Prädiktor-Variable(n) den Wert “Null” hat/ haben, bzw. die erste Ausprägung, hier 1.</p>
<p>Im Vergleich dazu wird die Überlebens-Chance deutlich schlechter, wenn man die nächste Gruppe von <code>Pclass</code> (3) betrachtet. Die Odds verändern sich um den Faktor ~0.2. Da der Faktor <em>kleiner</em> als 1 ist, ist das kein gutes Zeichen. Die Überlebens-Chance <em>sinkt</em>; etwas genauer auf: 1.7 * 0.2 ≈ 0.34. Das heißt, die Überlebens-Chance ist in der 3. Klasse nur noch ca. 1 zu 3 (Überlebens-Wahrscheinlichkeit: ~25%).</p>
<p>Komfortabler können wir uns die Überlebens-<em>Wahrscheinlichkeiten</em> mit der Funktion <code>predict</code> ausgeben lassen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(glm1, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">Pclass =</span> <span class="kw">factor</span>(<span class="st">&quot;1&quot;</span>)), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
<span class="co">#&gt;    1 </span>
<span class="co">#&gt; 0.63</span>
<span class="kw">predict</span>(glm1, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">Pclass =</span> <span class="kw">factor</span>(<span class="st">&quot;3&quot;</span>)), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
<span class="co">#&gt;     1 </span>
<span class="co">#&gt; 0.242</span></code></pre></div>
<p>Alternativ kann man die Häufigkeiten auch noch “per Hand” bestimmen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic_train %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(Pclass %in%<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)) %&gt;%<span class="st"> </span>
<span class="st">  </span>dplyr::<span class="kw">select</span>(Survived, Pclass) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Pclass, Survived) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">n =</span> <span class="kw">n</span>() ) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Anteil =</span> n /<span class="st"> </span><span class="kw">sum</span>(n))
<span class="co">#&gt; Source: local data frame [4 x 4]</span>
<span class="co">#&gt; Groups: Pclass [2]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   Pclass Survived     n Anteil</span>
<span class="co">#&gt;    &lt;int&gt;    &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;</span>
<span class="co">#&gt; 1      1        0    80  0.370</span>
<span class="co">#&gt; 2      1        1   136  0.630</span>
<span class="co">#&gt; 3      3        0   372  0.758</span>
<span class="co">#&gt; 4      3        1   119  0.242</span></code></pre></div>
</div>
<div id="effektstarken-visualieren" class="section level3">
<h3><span class="header-section-number">6.5.9</span> Effektstärken visualieren</h3>
<p>Zum Abschluss schauen wir uns die Stärke des Zusammenhangs noch einmal graphisch an. Wir berechnen dafür die relativen Häufigkeiten pro Gruppe (im Datensatz ohne 2. Klasse, der Einfachheit halber).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c5 &lt;-<span class="st"> </span>dplyr::<span class="kw">count</span>(t2, Pclass, Survived)
c5$prop &lt;-<span class="st"> </span>c5$n /<span class="st"> </span><span class="dv">707</span>
c5
<span class="co">#&gt; Source: local data frame [4 x 4]</span>
<span class="co">#&gt; Groups: Pclass [?]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   Pclass Survived     n  prop</span>
<span class="co">#&gt;    &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;dbl&gt;</span>
<span class="co">#&gt; 1      1        0    80 0.113</span>
<span class="co">#&gt; 2      1        1   136 0.192</span>
<span class="co">#&gt; 3      3        0   372 0.526</span>
<span class="co">#&gt; 4      3        1   119 0.168</span></code></pre></div>
<p>Genauer gesagt haben die Häufigkeiten pro Gruppe in Bezug auf die Gesamtzahl aller Passagiere berechnet; die vier Anteile addieren sich also zu 1 auf.</p>
<p>Das visualisieren wir wieder</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(<span class="dt">x =</span> <span class="kw">factor</span>(Pclass), <span class="dt">y =</span> prop, <span class="dt">fill =</span> <span class="kw">factor</span>(Survived), <span class="dt">data =</span> c5, <span class="dt">geom =</span> <span class="st">&quot;col&quot;</span>)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-104-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Das <code>geom = &quot;col&quot;</code> heißt, dass als “geometrisches Objekt” dieses Mal keine Punkte, sondern Säulen (columns) verwendet werden sollen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(<span class="dt">x =</span> <span class="kw">factor</span>(Pclass), <span class="dt">y =</span> prop, <span class="dt">fill =</span> <span class="kw">factor</span>(Survived), <span class="dt">data =</span> c5, <span class="dt">geom =</span> <span class="st">&quot;col&quot;</span>)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-105-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Ganz nett, aber die Häufigkeitsunterscheide von <code>Survived</code> zwischen den beiden Werten von <code>Pclass</code> stechen noch nicht so ins Auge. Wir sollten es anders darstellen.</p>
<p>Hier kommt der Punkt, wo wir von <code>qplot</code> auf seinen großen Bruder, <code>ggplot</code> wechseln sollten. <code>qplot</code> ist in Wirklichkeit nur eine vereinfachte Form von <code>ggplot</code>; die Einfachheit wird mit geringeren Möglichkeiten bezahlt. Satteln wir zum Schluss dieser Fallstudie also um:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> c5) +
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(Pclass), <span class="dt">y =</span> n, <span class="dt">fill =</span> <span class="kw">factor</span>(Survived)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">position =</span> <span class="st">&quot;fill&quot;</span>) +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Passagierklasse&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;Überlebt?&quot;</span>, <span class="dt">caption =</span> <span class="st">&quot;Nur Passagiere, keine Besatzung&quot;</span>)</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-106-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Jeden sehen wir die Häufigkeiten des Überlebens bedingt auf die Passagierklasse besser. Wir sehen auf den ersten Blick, dass sich die Überlebensraten deutlich unterscheiden: Im linken Balken überleben die meisten; im rechten Balken ertrinken die meisten.</p>
<p>Diese letzte Analyse zeigt deutlich die Kraft von (Daten-)Visualisierungen auf. Der zu untersuchende Effekt tritt hier am stärken zu Tage; außerdem ist die Analyse relativ einfach.</p>
<p>Eine alternative Darstellung ist diese:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c5 %&gt;%<span class="st"> </span>
<span class="st">  </span>ggplot +
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(Pclass), <span class="dt">y =</span> <span class="kw">factor</span>(Survived), <span class="dt">fill =</span> n) +
<span class="st">  </span><span class="kw">geom_tile</span>()</code></pre></div>
<p><img src="070_geleitetes_Modellieren_files/figure-html/unnamed-chunk-107-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Hier werden die vier “Fliesen” gleich groß dargestellt; die Fallzahl wird durch die Füllfarbe besorgt.</p>
</div>
<div id="fazit" class="section level3">
<h3><span class="header-section-number">6.5.10</span> Fazit</h3>
<p>In der Datenanalyse (mit R) kommt man mit wenigen Befehlen schon sehr weit; <code>dplyr</code> und <code>ggplot2</code> zählen (zu Recht) zu den am häufigsten verwendeten Paketen. Beide sind flexibel, konsistent und spielen gerne miteinander. Die besten Einblicke haben wir aus deskriptiver bzw. explorativer Analyse (Diagramme) gewonnen. Signifikanztests oder komplizierte Modelle waren nicht zentral. In vielen Studien/Projekten der Datenanalyse gilt ähnliches: Daten umformen und verstehen bzw. “veranschaulichen” sind zentrale Punkte, die häufig viel Zeit und Wissen fordern. Bei der Analyse von nominalskalierten sind Häufigkeitsauswertungen ideal.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-bryant1995practical">
<p>Bryant, PG, and MA Smith. 1995. “Practical Data Analysis: Case Studies in Business Statistics, Homewood, Il: Richard d.” Irwin Publishing.</p>
</div>
<div id="ref-hamermesh2005beauty">
<p>Hamermesh, Daniel S, and Amy Parker. 2005. “Beauty in the Classroom: Instructors’ Pulchritude and Putative Pedagogical Productivity.” <em>Economics of Education Review</em> 24 (4). Elsevier: 369–76.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="31">
<li id="fn31"><p><a href="http://www.omegahat.net/Rstem/stemming.pdf" class="uri">http://www.omegahat.net/Rstem/stemming.pdf</a><a href="geleitetes-modellieren.html#fnref31">↩</a></p></li>
<li id="fn32"><p>siehe z. B. Rob J Hyndman &amp; George Athanasopoulos, Forecasting: principles and practice, Kapitel 5.3: Selecting predictors, <a href="https://www.otexts.org/fpp/5/3" class="uri">https://www.otexts.org/fpp/5/3</a><a href="geleitetes-modellieren.html#fnref32">↩</a></p></li>
<li id="fn33"><p>Wahrscheinlichkeit vs. Chance: Die Wahrscheinlichkeit bei einem fairen Würfel, eine 6 zu würfeln, ist <span class="math inline">\(1/6\)</span>. Die Chance (<em>Odd</em>), eine 6 zu würfeln, ist die Wahrscheinlichkeit dividiert durch die Gegenwahrscheinlichkeit, also <span class="math inline">\(\frac{1/6}{5/6}=1/5\)</span>.<a href="geleitetes-modellieren.html#fnref33">↩</a></p></li>
<li id="fn34"><p>Hosmer/Lemeshow, Applied Logistic Regression, 3rd Ed. (2013), S. 164<a href="geleitetes-modellieren.html#fnref34">↩</a></p></li>
<li id="fn35"><p>Anregungen zu dieser Übung stammen von <a href="https://www.inwt-statistics.de/blog-artikel-lesen/Logistische_Regression_Beispiel_mit_R.html">INTW Statistics</a><a href="geleitetes-modellieren.html#fnref35">↩</a></p></li>
<li id="fn36"><p><a href="https://www.alternativefuer.de/wp-content/uploads/sites/7/2016/05/2016-06-27_afd-grundsatzprogramm_web-version.pdf" class="uri">https://www.alternativefuer.de/wp-content/uploads/sites/7/2016/05/2016-06-27_afd-grundsatzprogramm_web-version.pdf</a><a href="geleitetes-modellieren.html#fnref36">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="statistisches-modellieren.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ungeleitetes-modellieren.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
